{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5JqrpJWoNaB"
   },
   "source": [
    "# CRAFT fine-tuning and inference interactive demo\n",
    "\n",
    "This example notebook shows how to fine-tune a pretrained CRAFT conversational model for the task of forecasting conversational derailment, as shown in the \"Trouble on the Horizon\" paper (note however that due to nondeterminism in the training process, the results will not exactly reproduce the ones shown in the paper; if you need the exact inference results from the paper, see our [online demo](https://colab.research.google.com/drive/1GvICZN0VwZQSWw3pJaEVY-EQGoO-L5lH) that does inference only using the saved already-fine-tuned model from the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "RHkNojY7tzAh",
    "outputId": "a9d10e05-c6db-401f-a651-20bb60a3c095"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries, including convokit\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import unicodedata\n",
    "import itertools\n",
    "from convokit import download, Corpus\n",
    "\n",
    "# import all configuration variables\n",
    "from model.config import *\n",
    "# import data preprocessing functions\n",
    "from model.data import *\n",
    "# import our custom PyTorch modules\n",
    "from model.model import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Given a ConvoKit conversation, preprocess each utterance's text by tokenizing and truncating.\n",
    "# Returns the processed dialog entry where text has been replaced with a list of\n",
    "# tokens, each no longer than MAX_LENGTH - 1 (to leave space for the EOS token)\n",
    "def processDialog(voc, dialog):\n",
    "    processed = []\n",
    "    C_b_a = dialog.meta['mean_C_b_a']\n",
    "    C_a_b = dialog.meta['mean_C_a_b']\n",
    "    LSM = dialog.meta['mean_LSM']\n",
    "    for utterance in dialog.iter_utterances():\n",
    "        # skip the section header, which does not contain conversational content\n",
    "        if utterance.meta['is_section_header']:\n",
    "            continue\n",
    "        tokens = tokenize(utterance.text)\n",
    "        # replace out-of-vocabulary tokens\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] not in voc.word2index:\n",
    "                tokens[i] = \"UNK\"\n",
    "        processed.append({\"tokens\": tokens, \n",
    "                          \"is_attack\": int(utterance.meta['comment_has_personal_attack']), \n",
    "                          \"id\": utterance.id,\n",
    "                          'C_b_a' : C_b_a,\n",
    "                          'C_a_b' : C_a_b,\n",
    "                          'LSM' : LSM})\n",
    "        \n",
    "    return processed\n",
    "\n",
    "# Load context-reply pairs from the Corpus, optionally filtering to only conversations\n",
    "# from the specified split (train, val, or test).\n",
    "# Each conversation, which has N comments (not including the section header) will\n",
    "# get converted into N-1 comment-reply pairs, one pair for each reply \n",
    "# (the first comment does not reply to anything).\n",
    "# Each comment-reply pair is a tuple consisting of the conversational context\n",
    "# (that is, all comments prior to the reply), the reply itself, the label (that\n",
    "# is, whether the reply contained a derailment event), and the comment ID of the\n",
    "# reply (for later use in re-joining with the ConvoKit corpus).\n",
    "# The function returns a list of such pairs.\n",
    "def loadPairs(voc, corpus, split=None, last_only=False):\n",
    "    pairs = []\n",
    "    for convo in corpus.iter_conversations():\n",
    "        # consider only conversations in the specified split of the data\n",
    "        if split is None or convo.meta['split'] == split:\n",
    "            dialog = processDialog(voc, convo)\n",
    "            iter_range = range(1, len(dialog)) if not last_only else [len(dialog)-1]\n",
    "            for idx in iter_range:\n",
    "                reply = dialog[idx][\"tokens\"][:(MAX_LENGTH-1)]\n",
    "                label = dialog[idx][\"is_attack\"]\n",
    "                comment_id = dialog[idx][\"id\"]\n",
    "                # gather as context all utterances preceding the reply\n",
    "                context = [u[\"tokens\"][:(MAX_LENGTH-1)] for u in dialog[:idx]]\n",
    "\n",
    "                C_b_a = dialog[idx]['C_b_a']\n",
    "                C_a_b = dialog[idx]['C_a_b']\n",
    "                LSM = dialog[idx]['LSM']\n",
    "\n",
    "                if C_b_a == None:\n",
    "                    continue\n",
    "                else:\n",
    "                    pairs.append((context, reply, label, comment_id, C_b_a, C_a_b, LSM))\n",
    "    return pairs\n",
    "\n",
    "if corpus_name == \"wikiconv\":\n",
    "    # corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))\n",
    "    corpus = Corpus(filename=r'C:\\Users\\ewais\\Documents\\GitHub\\LSA-online-arguments\\preprocessed corpus\\preprocessed_wikipedia_corpus')\n",
    "elif corpus_name == \"cmv\":\n",
    "    # corpus = Corpus(filename=download(\"conversations-gone-awry-cmv-corpus\"))\n",
    "    corpus = Corpus(filename=r'C:\\Users\\ewais\\Documents\\GitHub\\LSA-online-arguments\\preprocessed corpus\\preprocessed_reddit_corpus')\n",
    "\n",
    "# First, we need to build the vocabulary so that we know how to map tokens to tensor indicies.\n",
    "# For the sake of replicating the paper results, we will load the pre-computed vocabulary objects used in the paper.\n",
    "voc = loadPrecomputedVoc(corpus_name, word2index_path, index2word_path)\n",
    "\n",
    "# Convert the test set data into a list of input/label pairs. Each input will represent the conversation as a list of lists of tokens.\n",
    "train_pairs = loadPairs(voc, corpus, \"train\", last_only=True)\n",
    "val_pairs = loadPairs(voc, corpus, \"val\", last_only=True)\n",
    "test_pairs = loadPairs(voc, corpus, \"test\")\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    \"\"\"This helper module encapsulates the CRAFT pipeline, defining the logic of passing an input through each consecutive sub-module.\"\"\"\n",
    "    def __init__(self, encoder, context_encoder, classifier):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.context_encoder = context_encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length, C_b_a, C_a_b, LSM):\n",
    "        # Forward input through encoder model\n",
    "        _, utt_encoder_hidden = self.encoder(input_batch, utt_lengths)\n",
    "        \n",
    "        # Convert utterance encoder final states to batched dialogs for use by context encoder\n",
    "        context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)\n",
    "        \n",
    "        # Forward pass through context encoder\n",
    "        context_encoder_outputs, context_encoder_hidden = self.context_encoder(context_encoder_input, dialog_lengths)\n",
    "        \n",
    "        # Forward pass through classifier to get prediction logits\n",
    "        logits = self.classifier(context_encoder_outputs, dialog_lengths, C_b_a, C_a_b, LSM)\n",
    "        \n",
    "        # Apply sigmoid activation\n",
    "        predictions = F.sigmoid(logits)\n",
    "        return predictions\n",
    "\n",
    "def train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments\n",
    "          encoder, context_encoder, attack_clf,                                                                    # network arguments\n",
    "          encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments\n",
    "          batch_size, clip,                                                                                        # misc arguments\n",
    "          C_b_a = None, C_a_b = None, LSM = None, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    context_encoder_optimizer.zero_grad()\n",
    "    attack_clf_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    dialog_lengths = dialog_lengths.to(device)\n",
    "    utt_lengths = utt_lengths.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "\n",
    "    # Forward pass through utterance encoder\n",
    "    _, utt_encoder_hidden = encoder(input_variable, utt_lengths)\n",
    "    \n",
    "    # Convert utterance encoder final states to batched dialogs for use by context encoder\n",
    "    context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)\n",
    "    \n",
    "    # Forward pass through context encoder\n",
    "    context_encoder_outputs, _ = context_encoder(context_encoder_input, dialog_lengths)\n",
    "\n",
    "    # Forward pass through classifier to get prediction logits\n",
    "    logits = attack_clf(context_encoder_outputs, dialog_lengths, C_b_a, C_a_b, LSM)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(context_encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(attack_clf.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    context_encoder_optimizer.step()\n",
    "    attack_clf_optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluateBatch(encoder, context_encoder, predictor, voc, input_batch, dialog_lengths, \n",
    "                  dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, device,                      C_b_a = None, C_a_b = None, LSM = None, max_length=MAX_LENGTH):\n",
    "    # Set device options\n",
    "    input_batch = input_batch.to(device)\n",
    "    dialog_lengths = dialog_lengths.to(device)\n",
    "    utt_lengths = utt_lengths.to(device)\n",
    "    # Predict future attack using predictor\n",
    "    scores = predictor(input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length, C_b_a, C_a_b, LSM)\n",
    "    predictions = (scores > 0.5).float()\n",
    "    return predictions, scores\n",
    "\n",
    "def validate(dataset, encoder, context_encoder, predictor, voc, batch_size, device):\n",
    "    # create a batch iterator for the given data\n",
    "    batch_iterator = batchIterator(voc, dataset, batch_size, shuffle=False)\n",
    "    # find out how many iterations we will need to cover the whole dataset\n",
    "    n_iters = len(dataset) // batch_size + int(len(dataset) % batch_size > 0)\n",
    "    # containers for full prediction results so we can compute accuracy at the end\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for iteration in range(1, n_iters+1):\n",
    "        batch, batch_dialogs, _, true_batch_size, C_b_a, C_a_b, LSM = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len = batch\n",
    "        dialog_lengths_list = [len(x) for x in batch_dialogs]\n",
    "        # run the model\n",
    "        predictions, scores = evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,\n",
    "                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, true_batch_size, device, C_b_a, C_a_b, LSM)\n",
    "        # aggregate results for computing accuracy at the end\n",
    "        all_preds += [p.item() for p in predictions]\n",
    "        all_labels += [l.item() for l in labels]\n",
    "        print(\"Iteration: {}; Percent complete: {:.1f}%\".format(iteration, iteration / n_iters * 100))\n",
    "\n",
    "    # compute and return the accuracy\n",
    "    return (np.asarray(all_preds) == np.asarray(all_labels)).mean()\n",
    "\n",
    "def trainIters(voc, pairs, val_pairs, encoder, context_encoder, attack_clf,\n",
    "               encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,\n",
    "               n_iteration, batch_size, print_every, validate_every, clip):\n",
    "    \n",
    "    # create a batch iterator for training data\n",
    "    batch_iterator = batchIterator(voc, pairs, batch_size)\n",
    "    \n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    # keep track of best validation accuracy - only save when we have a model that beats the current best\n",
    "    best_acc = 0\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch, training_dialogs, _, true_batch_size, C_b_a, C_a_b, LSM = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, _, target_variable, mask, max_target_len = training_batch\n",
    "        dialog_lengths_list = [len(x) for x in training_dialogs]\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments\n",
    "                     encoder, context_encoder, attack_clf,                                                                    # network arguments\n",
    "                     encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments\n",
    "                     true_batch_size, clip,                                                                                   # misc arguments\n",
    "                     C_b_a, C_a_b, LSM)\n",
    "        print_loss += loss\n",
    "        \n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        if (iteration % validate_every == 0):\n",
    "            print(\"Validating!\")\n",
    "            # put the network components into evaluation mode\n",
    "            encoder.eval()\n",
    "            context_encoder.eval()\n",
    "            attack_clf.eval()\n",
    "            \n",
    "            predictor = Predictor(encoder, context_encoder, attack_clf)\n",
    "            accuracy = validate(val_pairs, encoder, context_encoder, predictor, voc, batch_size, device)\n",
    "            print(\"Validation set accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "            # keep track of our best model so far\n",
    "            if accuracy > best_acc:\n",
    "                print(\"Validation accuracy better than current best; saving model...\")\n",
    "                best_acc = accuracy\n",
    "                torch.save({\n",
    "                    'iteration': iteration,\n",
    "                    'en': encoder.state_dict(),\n",
    "                    'ctx': context_encoder.state_dict(),\n",
    "                    'atk_clf': attack_clf.state_dict(),\n",
    "                    'en_opt': encoder_optimizer.state_dict(),\n",
    "                    'ctx_opt': context_encoder_optimizer.state_dict(),\n",
    "                    'atk_clf_opt': attack_clf_optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    'voc_dict': voc.__dict__,\n",
    "                    'embedding': embedding.state_dict()\n",
    "                }, os.path.join(save_dir, \"finetuned_model.tar\"))\n",
    "            \n",
    "            # put the network components back into training mode\n",
    "            encoder.train()\n",
    "            context_encoder.train()\n",
    "            attack_clf.train()\n",
    "\n",
    "def evaluateDataset(dataset, encoder, context_encoder, predictor, voc, batch_size, device):\n",
    "    # create a batch iterator for the given data\n",
    "    batch_iterator = batchIterator(voc, dataset, batch_size, shuffle=False)\n",
    "    # find out how many iterations we will need to cover the whole dataset\n",
    "    n_iters = len(dataset) // batch_size + int(len(dataset) % batch_size > 0)\n",
    "    output_df = {\n",
    "        \"id\": [],\n",
    "        \"prediction\": [],\n",
    "        \"score\": []\n",
    "    }\n",
    "    for iteration in range(1, n_iters+1):\n",
    "        batch, batch_dialogs, _, true_batch_size = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len = batch\n",
    "        dialog_lengths_list = [len(x) for x in batch_dialogs]\n",
    "        # run the model\n",
    "        predictions, scores = evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,\n",
    "                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices,\n",
    "                                            true_batch_size, device)\n",
    "\n",
    "        # format the output as a dataframe (which we can later re-join with the corpus)\n",
    "        for i in range(true_batch_size):\n",
    "            convo_id = convo_ids[i]\n",
    "            pred = predictions[i].item()\n",
    "            score = scores[i].item()\n",
    "            output_df[\"id\"].append(convo_id)\n",
    "            output_df[\"prediction\"].append(pred)\n",
    "            output_df[\"score\"].append(score)\n",
    "                \n",
    "        print(\"Iteration: {}; Percent complete: {:.1f}%\".format(iteration, iteration / n_iters * 100))\n",
    "\n",
    "    return pd.DataFrame(output_df).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4QRinW10Oo_G",
    "outputId": "99df8b29-f6cb-4fab-80db-611e73ab3869",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n",
      "Building optimizers...\n",
      "Starting Training!\n",
      "Will train for 150 iterations\n",
      "Initializing ...\n",
      "Training...\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%C:\\Users\\ewais\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n",
      "Validation set accuracy: 43.59%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 10; Percent complete: 6.7%; Average loss: 0.6975\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Iteration: 20; Percent complete: 13.3%; Average loss: 0.6951\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Iteration: 30; Percent complete: 20.0%; Average loss: 0.6942\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Iteration: 40; Percent complete: 26.7%; Average loss: 0.6946\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Iteration: 50; Percent complete: 33.3%; Average loss: 0.6934\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Iteration: 60; Percent complete: 40.0%; Average loss: 0.6921\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 44.44%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 44.44%\n",
      "Iteration: 70; Percent complete: 46.7%; Average loss: 0.6918\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 43.59%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 45.30%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 80; Percent complete: 53.3%; Average loss: 0.6905\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 46.15%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 49.57%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 90; Percent complete: 60.0%; Average loss: 0.6895\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 51.28%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 52.99%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 100; Percent complete: 66.7%; Average loss: 0.6890\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 56.41%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 62.39%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Iteration: 110; Percent complete: 73.3%; Average loss: 0.6878\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 64.96%\n",
      "Validation accuracy better than current best; saving model...\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 64.10%\n",
      "Iteration: 120; Percent complete: 80.0%; Average loss: 0.6858\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 63.25%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 61.54%\n",
      "Iteration: 130; Percent complete: 86.7%; Average loss: 0.6846\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 64.10%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 64.10%\n",
      "Iteration: 140; Percent complete: 93.3%; Average loss: 0.6829\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 61.54%\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 60.68%\n",
      "Iteration: 150; Percent complete: 100.0%; Average loss: 0.6820\n",
      "Validating!\n",
      "Iteration: 1; Percent complete: 50.0%\n",
      "Iteration: 2; Percent complete: 100.0%\n",
      "Validation set accuracy: 59.83%\n"
     ]
    }
   ],
   "source": [
    "# Fix random state (affect native Python code only, does not affect PyTorch and hence does not guarantee reproducibility)\n",
    "random.seed(2019)\n",
    "\n",
    "# Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print(\"Loading saved parameters...\")\n",
    "if not os.path.isfile(os.path.join(save_dir, \"model.tar\")):\n",
    "    raise RuntimeError(\"Pretrained model not found. Have you run pretraining using train_generative_model.py?\")\n",
    "checkpoint = torch.load(os.path.join(save_dir, \"model.tar\"))\n",
    "# If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.\n",
    "# To do so, replace the previous line with the following:\n",
    "#checkpoint = torch.load(\"model.tar\", map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "context_sd = checkpoint['ctx']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoders, decoder, and classifier...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# Initialize utterance and context encoders\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "context_encoder = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_encoder.load_state_dict(context_sd)\n",
    "# Initialize classifier\n",
    "attack_clf = SingleTargetClf(hidden_size, dropout)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "context_encoder = context_encoder.to(device)\n",
    "attack_clf = attack_clf.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "# Compute the number of training iterations we will need in order to achieve the number of epochs specified in the settings at the start of the notebook\n",
    "n_iter_per_epoch = len(train_pairs) // batch_size + int(len(train_pairs) % batch_size == 1)\n",
    "n_iteration = n_iter_per_epoch * finetune_epochs\n",
    "\n",
    "# Put dropout layers in train mode\n",
    "encoder.train()\n",
    "context_encoder.train()\n",
    "attack_clf.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=labeled_learning_rate)\n",
    "context_encoder_optimizer = optim.Adam(context_encoder.parameters(), lr=labeled_learning_rate)\n",
    "attack_clf_optimizer = optim.Adam(attack_clf.parameters(), lr=labeled_learning_rate)\n",
    "\n",
    "# Run training iterations, validating after every epoch\n",
    "print(\"Starting Training!\")\n",
    "print(\"Will train for {} iterations\".format(n_iteration))\n",
    "trainIters(voc, train_pairs, val_pairs, encoder, context_encoder, attack_clf,\n",
    "           encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,\n",
    "           n_iteration, batch_size, print_every, n_iter_per_epoch, clip)"
   ]
  },
  {
   "source": [
    "## Notes on training\n",
    "\n",
    "trainIters is the main training loop\n",
    "\n",
    "It looks like this will need to be implemented in LuongAttnDecoderRNN\n",
    "\n",
    "## In ~\\data\\batchIterator:\n",
    "\n",
    "- source_data\\[ i \\] = i'th training tuple, containing\n",
    "    - context\n",
    "    - reply\n",
    "    - label\n",
    "    - ID\n",
    "- batch_dialogs\n",
    "\n",
    "To preprocess our data:\n",
    "\n",
    "Create source_data structure from only the conversations we can use for training data. Include an extra parameter in source_data for linguistic accommodation. Pass this to train() which will then be used in conjuction with the context_encoder output in the final MLP in order to train. Can adjust SingleTargetClf to implement this.\n",
    "\n",
    "We can start by creating a custom corpus, with linguistic accommodation noted. This can be extracted using load_pairs() defined above. Then, extract it as a feature and pipe it down to the final MLP.\n",
    "\n",
    "In order to do this efficiently, modify processDialog in data.py, so that the \"processed\" list it returns includes a key-value pair of linguistic accommodation features.\n",
    "\n",
    "## Strategy to integrate\n",
    "Start by running through the corpus itself via conversations, and for each conversation, figure out whether it includes valid input for our test. If it does, set a key-value pair \"LSA_valid : True\" and otherwise \"LSA_valid : False\". Once this is established for the whole corpus, iterate through it again and append to the conversations with \"LSA_valid = True\" the accommodation from speaker a to b, the accommodation from speaker b to a, and the symmetric style accommodation.\n",
    "\n",
    "There is a function defined above called \"load_pairs,\" this can be modified to return specific values for the accommodation with each pair. Take care to modify \"iter_pair"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na5gjZGE-KA0"
   },
   "source": [
    "## Part 7: run test set evaluation\n",
    "\n",
    "Now that we have successfully fine-tuned the model, we run it on the test set so that we can evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2551GR65-Wm5",
    "outputId": "154d7581-37a7-48e7-c203-9d3a97c472ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n",
      "Iteration: 1; Percent complete: 1.4%\n",
      "Iteration: 2; Percent complete: 2.9%\n",
      "Iteration: 3; Percent complete: 4.3%\n",
      "Iteration: 4; Percent complete: 5.8%\n",
      "Iteration: 5; Percent complete: 7.2%\n",
      "Iteration: 6; Percent complete: 8.7%\n",
      "Iteration: 7; Percent complete: 10.1%\n",
      "Iteration: 8; Percent complete: 11.6%\n",
      "Iteration: 9; Percent complete: 13.0%\n",
      "Iteration: 10; Percent complete: 14.5%\n",
      "Iteration: 11; Percent complete: 15.9%\n",
      "Iteration: 12; Percent complete: 17.4%\n",
      "Iteration: 13; Percent complete: 18.8%\n",
      "Iteration: 14; Percent complete: 20.3%\n",
      "Iteration: 15; Percent complete: 21.7%\n",
      "Iteration: 16; Percent complete: 23.2%\n",
      "Iteration: 17; Percent complete: 24.6%\n",
      "Iteration: 18; Percent complete: 26.1%\n",
      "Iteration: 19; Percent complete: 27.5%\n",
      "Iteration: 20; Percent complete: 29.0%\n",
      "Iteration: 21; Percent complete: 30.4%\n",
      "Iteration: 22; Percent complete: 31.9%\n",
      "Iteration: 23; Percent complete: 33.3%\n",
      "Iteration: 24; Percent complete: 34.8%\n",
      "Iteration: 25; Percent complete: 36.2%\n",
      "Iteration: 26; Percent complete: 37.7%\n",
      "Iteration: 27; Percent complete: 39.1%\n",
      "Iteration: 28; Percent complete: 40.6%\n",
      "Iteration: 29; Percent complete: 42.0%\n",
      "Iteration: 30; Percent complete: 43.5%\n",
      "Iteration: 31; Percent complete: 44.9%\n",
      "Iteration: 32; Percent complete: 46.4%\n",
      "Iteration: 33; Percent complete: 47.8%\n",
      "Iteration: 34; Percent complete: 49.3%\n",
      "Iteration: 35; Percent complete: 50.7%\n",
      "Iteration: 36; Percent complete: 52.2%\n",
      "Iteration: 37; Percent complete: 53.6%\n",
      "Iteration: 38; Percent complete: 55.1%\n",
      "Iteration: 39; Percent complete: 56.5%\n",
      "Iteration: 40; Percent complete: 58.0%\n",
      "Iteration: 41; Percent complete: 59.4%\n",
      "Iteration: 42; Percent complete: 60.9%\n",
      "Iteration: 43; Percent complete: 62.3%\n",
      "Iteration: 44; Percent complete: 63.8%\n",
      "Iteration: 45; Percent complete: 65.2%\n",
      "Iteration: 46; Percent complete: 66.7%\n",
      "Iteration: 47; Percent complete: 68.1%\n",
      "Iteration: 48; Percent complete: 69.6%\n",
      "Iteration: 49; Percent complete: 71.0%\n",
      "Iteration: 50; Percent complete: 72.5%\n",
      "Iteration: 51; Percent complete: 73.9%\n",
      "Iteration: 52; Percent complete: 75.4%\n",
      "Iteration: 53; Percent complete: 76.8%\n",
      "Iteration: 54; Percent complete: 78.3%\n",
      "Iteration: 55; Percent complete: 79.7%\n",
      "Iteration: 56; Percent complete: 81.2%\n",
      "Iteration: 57; Percent complete: 82.6%\n",
      "Iteration: 58; Percent complete: 84.1%\n",
      "Iteration: 59; Percent complete: 85.5%\n",
      "Iteration: 60; Percent complete: 87.0%\n",
      "Iteration: 61; Percent complete: 88.4%\n",
      "Iteration: 62; Percent complete: 89.9%\n",
      "Iteration: 63; Percent complete: 91.3%\n",
      "Iteration: 64; Percent complete: 92.8%\n",
      "Iteration: 65; Percent complete: 94.2%\n",
      "Iteration: 66; Percent complete: 95.7%\n",
      "Iteration: 67; Percent complete: 97.1%\n",
      "Iteration: 68; Percent complete: 98.6%\n",
      "Iteration: 69; Percent complete: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Fix random state for reproducibility\n",
    "random.seed(2019)\n",
    "\n",
    "# Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print(\"Loading saved parameters...\")\n",
    "checkpoint = torch.load(os.path.join(save_dir, \"finetuned_model.tar\"))\n",
    "# If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.\n",
    "# To do so, replace the previous line with the following:\n",
    "#checkpoint = torch.load(\"model.tar\", map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "context_sd = checkpoint['ctx']\n",
    "attack_clf_sd = checkpoint['atk_clf']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoders, decoder, and classifier...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# Initialize utterance and context encoders\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "context_encoder = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_encoder.load_state_dict(context_sd)\n",
    "# Initialize classifier\n",
    "attack_clf = SingleTargetClf(hidden_size, dropout)\n",
    "attack_clf.load_state_dict(attack_clf_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "context_encoder = context_encoder.to(device)\n",
    "attack_clf = attack_clf.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "context_encoder.eval()\n",
    "attack_clf.eval()\n",
    "\n",
    "# Initialize the pipeline\n",
    "predictor = Predictor(encoder, context_encoder, attack_clf)\n",
    "\n",
    "# Run the pipeline!\n",
    "forecasts_df = evaluateDataset(test_pairs, encoder, context_encoder, predictor, voc, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "lVK-1NWHEy7l",
    "outputId": "8b208593-4f96-444f-ad6c-cb84c0ffd88b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191681310.17214.17214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193088419.20001.20001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.654389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191149920.17102.17102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192892110.19259.19259</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.597574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190192199.17060.17060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192890095.19227.19227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190192005.17004.17004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192885632.19156.19156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190191827.16918.16918</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192882222.19129.19129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190191097.16843.16843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192642615.19074.19074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190190570.16705.16705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203899060.13359.13359</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869198.3976.3976</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192640416.19036.19036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190189346.16645.16645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203898053.13222.13222</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390066809.29445.29445</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434001261.9906.9906</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.761429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prediction     score\n",
       "id                                         \n",
       "191681310.17214.17214         0.0  0.397591\n",
       "193088419.20001.20001         1.0  0.654389\n",
       "191149920.17102.17102         0.0  0.239742\n",
       "192892110.19259.19259         1.0  0.597574\n",
       "190192199.17060.17060         0.0  0.170675\n",
       "192890095.19227.19227         1.0  0.646455\n",
       "190192005.17004.17004         0.0  0.146115\n",
       "192885632.19156.19156         0.0  0.453823\n",
       "190191827.16918.16918         0.0  0.201450\n",
       "192882222.19129.19129         0.0  0.370547\n",
       "190191097.16843.16843         0.0  0.260660\n",
       "192642615.19074.19074         0.0  0.444873\n",
       "190190570.16705.16705         0.0  0.417208\n",
       "203899060.13359.13359         1.0  0.939331\n",
       "15869198.3976.3976            1.0  0.651795\n",
       "192640416.19036.19036         0.0  0.353072\n",
       "190189346.16645.16645         0.0  0.276299\n",
       "203898053.13222.13222         1.0  0.926877\n",
       "390066809.29445.29445         1.0  0.670856\n",
       "434001261.9906.9906           1.0  0.761429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some of the outputs as a sanity-check\n",
    "forecasts_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_EMZ7-SKtEP"
   },
   "source": [
    "## Part 8: merge predictions back into corpus and evaluate\n",
    "\n",
    "Now that the hard part is done, all that is left to do is to evaluate the predictions. Since the predictions are in no particular order, we will first merge each prediction back into the source corpus, and then evaluate each conversation according to the order of utterances within that conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Vnjmtu-QLDVo"
   },
   "outputs": [],
   "source": [
    "# We will add a metadata entry to each test-set utterance signifying whether it was FORECAST to be a derailment.\n",
    "# Note that there is an important subtlety in how this metadata field is to be interpreted - the forecast for a given\n",
    "# utterance is made BEFORE the model actually sees the utterance. That is, the forecast does not mean \"the model thinks\n",
    "# this utterance *is* a derailment\" but rather that \"based on the context of all preceding utterances, the model predicted,\n",
    "# prior to actually seeing this utterance, that this utterance *would be* a derailment\".\n",
    "for convo in corpus.iter_conversations():\n",
    "    # only consider test set conversations (we did not make predictions for the other ones)\n",
    "    if convo.meta['split'] == \"test\":\n",
    "        for utt in convo.iter_utterances():\n",
    "            if utt.id in forecasts_df.index:\n",
    "                utt.meta['forecast_score'] = forecasts_df.loc[utt.id].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FYxW_AuWszqX",
    "outputId": "d478288b-55ae-4bc9-cb8c-f294a80f3174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6488095238095238\n"
     ]
    }
   ],
   "source": [
    "# Finally, we can use the forecast-annotated corpus to compute the forecast accuracy.\n",
    "# Though we have an individual forecast per utterance, ground truth is at the conversation level:\n",
    "# either a conversation derails or it does not. Thus, forecast accuracy is computed as follows:\n",
    "#   - True positives are cases that actually derail, for which the model made at least one positive forecast ANYTIME prior to derailment\n",
    "#   - False positives are cases that don't derail but for which the model made at least one positive forecast\n",
    "#   - False negatives are cases that derail but for which the model made no positive forecasts prior to derailment\n",
    "#   - True negatives are cases that don't derail, for which the model made no positive forecasts\n",
    "# Note that by construction, the last comment of each conversation is the one marked as derailment, and that our earlier code was therefore\n",
    "# set up to not look at the last comment, meaning that all forecasts we obtained are forecasts made prior to derailment. This simplifies\n",
    "# the computation of forecast accuracy as we now do not need to explicitly consider when a forecast was made.\n",
    "\n",
    "conversational_forecasts_df = {\n",
    "    \"convo_id\": [],\n",
    "    \"label\": [],\n",
    "    \"score\": [],\n",
    "    \"prediction\": []\n",
    "}\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == \"test\":\n",
    "        conversational_forecasts_df['convo_id'].append(convo.id)\n",
    "        conversational_forecasts_df['label'].append(int(convo.meta[label_metadata]))\n",
    "        forecast_scores = [utt.meta['forecast_score'] for utt in convo.iter_utterances() if 'forecast_score' in utt.meta]\n",
    "        conversational_forecasts_df['score'] = np.max(forecast_scores)\n",
    "        conversational_forecasts_df['prediction'].append(int(np.max(forecast_scores) > forecast_thresh))\n",
    "\n",
    "conversational_forecasts_df = pd.DataFrame(conversational_forecasts_df).set_index(\"convo_id\")\n",
    "print((conversational_forecasts_df.label == conversational_forecasts_df.prediction).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "_49Yaz2FIo9S",
    "outputId": "d1ae7b87-6973-41a1-e7aa-806d57990c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.6233, recall = 0.7524\n",
      "False positive rate = 0.45476190476190476\n",
      "F1 = 0.6817691477885652\n"
     ]
    }
   ],
   "source": [
    "# in addition to accuracy, we can also consider applying other metrics at the conversation level, such as precision/recall\n",
    "def get_pr_stats(preds, labels):\n",
    "    tp = ((labels==1)&(preds==1)).sum()\n",
    "    fp = ((labels==0)&(preds==1)).sum()\n",
    "    tn = ((labels==0)&(preds==0)).sum()\n",
    "    fn = ((labels==1)&(preds==0)).sum()\n",
    "    print(\"Precision = {0:.4f}, recall = {1:.4f}\".format(tp / (tp + fp), tp / (tp + fn)))\n",
    "    print(\"False positive rate =\", fp / (fp + tn))\n",
    "    print(\"F1 =\", 2 / (((tp + fp) / tp) + ((tp + fn) / tp)))\n",
    "\n",
    "get_pr_stats(conversational_forecasts_df.prediction, conversational_forecasts_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzBiI0dsW7WZ"
   },
   "source": [
    "## Part 9: model analysis: how early is early warning?\n",
    "\n",
    "The goal of CRAFT is to forecast outcomes in advance, but how far in advance does it typically make its prediction? Following the paper, we measure this in two ways: the number of *comments* between the first prediction and the actual derailment, and how much *elapsed time* that gap actually translates to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8Qfvl9k8Xesh"
   },
   "outputs": [],
   "source": [
    "comments_until_derail = {} # store the \"number of comments until derailment\" metric for each conversation\n",
    "time_until_derail = {} # store the \"time until derailment\" metric for each conversation\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == \"test\" and convo.meta[label_metadata]:\n",
    "        # filter out the section header as usual\n",
    "        utts = [utt for utt in convo.iter_utterances() if not utt.meta['is_section_header']]\n",
    "        # by construction, the last comment is the one with the personal attack\n",
    "        derail_idx = len(utts) - 1\n",
    "        # now scan the utterances in order until we find the first derailment prediction (if any)\n",
    "        for idx in range(1, len(utts)):\n",
    "            if utts[idx].meta['forecast_score'] > forecast_thresh:\n",
    "                # recall that the forecast_score meta field specifies what CRAFT thought this comment would look like BEFORE it\n",
    "                # saw this comment. So the actual CRAFT forecast is made during the previous comment; we account for this by \n",
    "                # subtracting 1 from idx\n",
    "                comments_until_derail[convo.id] = derail_idx - (idx-1)\n",
    "                time_until_derail[convo.id] = utts[derail_idx].timestamp - utts[(idx-1)].timestamp\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IFXn4LrMhJ8W",
    "outputId": "26611644-8c44-4380-8897-b0de6eece0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 12 3.0 3.4082278481012658\n"
     ]
    }
   ],
   "source": [
    "# compute some quick statistics about the distribution of the \"number of comments until derailment\" metric\n",
    "comments_until_derail_vals = np.asarray(list(comments_until_derail.values()))\n",
    "print(np.min(comments_until_derail_vals), np.max(comments_until_derail_vals), np.median(comments_until_derail_vals), np.mean(comments_until_derail_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7cTdzAuLhuHF",
    "outputId": "85df20c5-62e1-4d2c-8736-8432a65f55ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 25575.071111111112 3.539861111111111 241.3298628691983\n"
     ]
    }
   ],
   "source": [
    "# compute some quick statistics about the distribution of the \"time until derailment\" metric\n",
    "# note that since timestamps are in seconds, we convert to hours by dividing by 3600, to make it more human readable\n",
    "time_until_derail_vals = np.asarray(list(time_until_derail.values())) / 3600\n",
    "print(np.min(time_until_derail_vals), np.max(time_until_derail_vals), np.median(time_until_derail_vals), np.mean(time_until_derail_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "_w3l6UxDiDAz",
    "outputId": "7de51fb0-dbb9-42f2-8d5f-18fcda28ab00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the distribution of \"number of comments until derailment\" as a histogram (reproducing Figure 4 from the paper)\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.hist(comments_until_derail_vals, bins=range(1, np.max(comments_until_derail_vals)), density=True)\n",
    "plt.xlim(1,10)\n",
    "plt.xticks(np.arange(1,10)+0.5, np.arange(1,10))\n",
    "plt.yticks(np.arange(0,0.25,0.05), np.arange(0,25,5))\n",
    "plt.xlabel(\"Number of comments elapsed\")\n",
    "plt.ylabel(\"% of conversations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CRAFT fine-tuning demo using ConvoKit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python386jvsc74a57bd01131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}