{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5JqrpJWoNaB"
   },
   "source": [
    "# CRAFT fine-tuning and inference interactive demo\n",
    "\n",
    "This example notebook shows how to fine-tune a pretrained CRAFT conversational model for the task of forecasting conversational derailment, as shown in the \"Trouble on the Horizon\" paper (note however that due to nondeterminism in the training process, the results will not exactly reproduce the ones shown in the paper; if you need the exact inference results from the paper, see our [online demo](https://colab.research.google.com/drive/1GvICZN0VwZQSWw3pJaEVY-EQGoO-L5lH) that does inference only using the saved already-fine-tuned model from the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "RHkNojY7tzAh",
    "outputId": "a9d10e05-c6db-401f-a651-20bb60a3c095"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries, including convokit\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import unicodedata\n",
    "import itertools\n",
    "from convokit import download, Corpus\n",
    "\n",
    "# import all configuration variables\n",
    "from model.config import *\n",
    "# import data preprocessing functions\n",
    "from model.data import *\n",
    "# import our custom PyTorch modules\n",
    "from model.model import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_w8yFiXuCpg"
   },
   "source": [
    "## Part 1: set up data preprocessing utilities\n",
    "\n",
    "We begin by setting up some helper functions for preprocessing the ConvoKit Utterance data for use with CRAFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0SazSyux7KFS"
   },
   "outputs": [],
   "source": [
    "# Given a ConvoKit conversation, preprocess each utterance's text by tokenizing and truncating.\n",
    "# Returns the processed dialog entry where text has been replaced with a list of\n",
    "# tokens, each no longer than MAX_LENGTH - 1 (to leave space for the EOS token)\n",
    "def processDialog(voc, dialog):\n",
    "    processed = []\n",
    "    for utterance in dialog.iter_utterances():\n",
    "        # skip the section header, which does not contain conversational content\n",
    "        if utterance.meta['is_section_header']:\n",
    "            continue\n",
    "        tokens = tokenize(utterance.text)\n",
    "        # replace out-of-vocabulary tokens\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] not in voc.word2index:\n",
    "                tokens[i] = \"UNK\"\n",
    "        processed.append({\"tokens\": tokens, \"is_attack\": int(utterance.meta['comment_has_personal_attack']), \"id\": utterance.id})\n",
    "    return processed\n",
    "\n",
    "# Load context-reply pairs from the Corpus, optionally filtering to only conversations\n",
    "# from the specified split (train, val, or test).\n",
    "# Each conversation, which has N comments (not including the section header) will\n",
    "# get converted into N-1 comment-reply pairs, one pair for each reply \n",
    "# (the first comment does not reply to anything).\n",
    "# Each comment-reply pair is a tuple consisting of the conversational context\n",
    "# (that is, all comments prior to the reply), the reply itself, the label (that\n",
    "# is, whether the reply contained a derailment event), and the comment ID of the\n",
    "# reply (for later use in re-joining with the ConvoKit corpus).\n",
    "# The function returns a list of such pairs.\n",
    "def loadPairs(voc, corpus, split=None, last_only=False):\n",
    "    pairs = []\n",
    "    for convo in corpus.iter_conversations():\n",
    "        # consider only conversations in the specified split of the data\n",
    "        if split is None or convo.meta['split'] == split:\n",
    "            dialog = processDialog(voc, convo)\n",
    "            iter_range = range(1, len(dialog)) if not last_only else [len(dialog)-1]\n",
    "            for idx in iter_range:\n",
    "                reply = dialog[idx][\"tokens\"][:(MAX_LENGTH-1)]\n",
    "                label = dialog[idx][\"is_attack\"]\n",
    "                comment_id = dialog[idx][\"id\"]\n",
    "                # gather as context all utterances preceding the reply\n",
    "                context = [u[\"tokens\"][:(MAX_LENGTH-1)] for u in dialog[:idx]]\n",
    "                pairs.append((context, reply, label, comment_id))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_ev-7g-xsGQ"
   },
   "source": [
    "## Part 2: load the data\n",
    "\n",
    "Now we load the labeled corpus (Wikiconv or Reddit CMV) from ConvoKit, and run some transformations to prepare it for use with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Y96SXcp4x1yj",
    "outputId": "64557a00-453c-44c0-f334-b5ae83508231"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset already exists at C:\\Users\\ewais\\.convokit\\downloads\\conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "if corpus_name == \"wikiconv\":\n",
    "    corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))\n",
    "elif corpus_name == \"cmv\":\n",
    "    corpus = Corpus(filename=download(\"conversations-gone-awry-cmv-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "fPySt5a4yLId",
    "outputId": "18931f88-572d-4c39-e5da-df3eca9c078c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "30021\n8069\n4188\n"
     ]
    }
   ],
   "source": [
    "# let's check some quick stats to verify that the corpus loaded correctly\n",
    "print(len(corpus.get_utterance_ids()))\n",
    "print(len(corpus.get_speaker_ids()))\n",
    "print(len(corpus.get_conversation_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "eeNfs0A-yosu",
    "outputId": "61b9f041-d59f-4f5a-a65b-ce9631c02336"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'obj_type': 'conversation', '_owner': <convokit.model.corpus.Corpus object at 0x00000264A2877E20>, 'meta': {'page_title': 'User talk:2005', 'page_id': 1003212, 'pair_id': '143890867.11926.11926', 'conversation_has_personal_attack': False, 'verified': True, 'pair_verified': True, 'annotation_year': '2018', 'split': 'train'}, '_id': '146743638.12652.12652', 'vectors': [], '_utterance_ids': ['146743638.12652.12652', '146743638.12667.12652', '146842219.12874.12874', '146860774.13072.13072'], '_speaker_ids': None, 'tree': None}\nUtterance(id: '146743638.12652.12652', conversation_id: 146743638.12652.12652, reply-to: None, speaker: Speaker(id: Sirex98, vectors: [], meta: {}), timestamp: 1185295934.0, text: '== [WIKI_LINK: WP:COMMONNAME] ==\\n', vectors: [], meta: {'is_section_header': True, 'comment_has_personal_attack': False, 'toxicity': 0, 'parsed': [{'rt': 3, 'toks': [{'tok': '=', 'tag': 'NFP', 'dep': 'punct', 'up': 3, 'dn': []}, {'tok': '=', 'tag': 'LS', 'dep': 'punct', 'up': 3, 'dn': []}, {'tok': '[', 'tag': '-LRB-', 'dep': 'punct', 'up': 3, 'dn': []}, {'tok': 'WIKI_LINK', 'tag': 'JJ', 'dep': 'ROOT', 'dn': [0, 1, 2, 4]}, {'tok': ':', 'tag': ':', 'dep': 'punct', 'up': 3, 'dn': []}]}, {'rt': 0, 'toks': [{'tok': 'WP', 'tag': 'NNP', 'dep': 'ROOT', 'dn': [1, 2, 5]}, {'tok': ':', 'tag': ':', 'dep': 'punct', 'up': 0, 'dn': []}, {'tok': 'COMMONNAME', 'tag': 'NNPS', 'dep': 'appos', 'up': 0, 'dn': [3]}, {'tok': ']', 'tag': '-RRB-', 'dep': 'punct', 'up': 2, 'dn': []}, {'tok': '=', 'tag': 'SYM', 'dep': 'punct', 'up': 5, 'dn': []}, {'tok': '=', 'tag': 'SYM', 'dep': 'punct', 'up': 0, 'dn': [4, 6]}, {'tok': '\\n', 'tag': '', 'dep': '', 'up': 5, 'dn': []}]}]})\n"
     ]
    }
   ],
   "source": [
    "# Let's also take a look at some example data to see what kinds of information/metadata are available to us\n",
    "print(list(corpus.iter_conversations())[0].__dict__)\n",
    "print(list(corpus.iter_utterances())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3QIoTtbzOfY"
   },
   "source": [
    "Now we can use the utilities defined in Part 1 to convert the ConvoKit conversational data into a tokenized form that can be straightforwardly turned into Tensors later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WlpbT72FxK8W"
   },
   "outputs": [],
   "source": [
    "# First, we need to build the vocabulary so that we know how to map tokens to tensor indicies.\n",
    "# For the sake of replicating the paper results, we will load the pre-computed vocabulary objects used in the paper.\n",
    "voc = loadPrecomputedVoc(corpus_name, word2index_path, index2word_path)"
   ]
  },
  {
   "source": [
    "Voc attributes:\n",
    "- name: wikiconv or cmv\n",
    "- trimmed: not sure\n",
    "- word2index: dictionary of words to indices\n",
    "- index2word: dictionary of indices to words\n",
    "- num_words: not sure\n",
    "\n",
    "Voc functions:\n",
    "- addSentence: adds words in sentence to word2index and index2word\n",
    "- addWord: adds word to word2index and index2word\n",
    "- trim: removes from word2index and index2word words below min_count\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "eRSAVrgSxhmD",
    "outputId": "a682ac56-5ec9-4a88-fdce-fc9fb08aa104"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50004\n[('UNK', 3), ('.', 4), ('the', 5), (\"'\", 6), (',', 7), ('to', 8), ('i', 9), ('of', 10), ('a', 11), ('and', 12)]\n[('0', 'PAD'), ('1', 'SOS'), ('2', 'EOS'), ('3', 'UNK'), ('4', '.'), ('5', 'the'), ('6', \"'\"), ('7', ','), ('8', 'to'), ('9', 'i')]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the Voc object to make sure it loaded correctly\n",
    "print(voc.num_words) # expected vocab size is 50004: it was built using a fixed vocab size of 50k plus 4 spots for special tokens PAD, SOS, EOS, and UNK.\n",
    "print(list(voc.word2index.items())[:10])\n",
    "print(list(voc.index2word.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pmaWfn7vyTjy"
   },
   "outputs": [],
   "source": [
    "# Convert the test set data into a list of input/label pairs. Each input will represent the conversation as a list of lists of tokens.\n",
    "train_pairs = loadPairs(voc, corpus, \"train\", last_only=True)\n",
    "val_pairs = loadPairs(voc, corpus, \"val\", last_only=True)\n",
    "test_pairs = loadPairs(voc, corpus, \"test\")"
   ]
  },
  {
   "source": [
    "### loadPairs\n",
    "\n",
    "Returns a list of pairs in the format (context, reply label)\n",
    "- context: The context of the reply, list of tokenized utterances preceding reply\n",
    "- reply: tokenized reply\n",
    "- label: 0 if it doesn't lead to attack, 1 if it does"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "RIiQNvg4zBEi",
    "outputId": "11d7b50b-bc00-4080-d4ce-9294b3988194"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2508\n840\n4365\n([['i', 'notice', 'that', 'UNK', 'that', 'moved', 'UNK', 'to', 'bill', 'chen', 'citing', 'UNK', ',', 'then', 'you', 'reverted', 'this', 'change', ',', 'bill', 'chen', 'doesn', \"'\", 't', 'commonly', 'go', 'by', 'william', ',', 'his', 'book', 'is', 'even', 'penned', 'as', 'bill', 'chen', '.', 'from', 'what', 'i', 'read', 'in', 'wp', ':', 'commonname', 'UNK', 'seems', 'to', 'be', 'correct', ',', 'examples', 'given', 'are', 'names', 'such', 'as', ':', '*', 'UNK', '(', 'not', 'UNK', ')', '*', 'UNK', '(', 'not', 'UNK', ')', 'i', 'think', 'this', 'revert', 'may', 'have', 'been', 'a'], ['chen', 'was', 'known', 'in', 'the', 'poker', 'world', 'as', '\"', 'william', '\"', 'for', 'years', 'before', 'he', 'became', 'commonly', 'known', 'as', '\"', 'bill', '\"', '.', 'i', 'changed', 'it', 'back', 'because', 'incidences', 'online', 'including', 'usenet', 'are', 'roughly', 'equal', ',', 'nothing', 'at', 'all', 'like', 'bill', 'clinton', 'and', 'william', 'clinton', ',', 'and', 'in', 'equal', 'cases', 'using', 'the', 'real', 'name', 'seems', 'the', 'best', 'choice', '.', '(', 'the', 'UNK', 'page', 'is', 'especially', 'UNK', '.', '.', '.', 'UNK', 'in', 'the', 'page', 'title', ',', 'bill', 'in', 'the', 'page']], ['i', 'see', 'what', 'you', 'saying', 'i', 'just', 'read', 'his', 'UNK', 'profile', ',', 'it', 'struck', 'me', 'when', 'i', 'saw', 'the', 'change', 'because', 'i', 'remember', 'him', 'being', 'called', 'bill', 'when', 'i', 'watched', 'the', 'last', 'season', 'of', 'high', 'stakes', 'poker', ',', 'but', 'you', 'seem', 'to', 'have', 'many', 'more', 'years', 'experience', 'in', 'the', 'poker', '/', 'gambling', 'world', 'then', 'i', 'do', '(', 'i', \"'\", 'm', 'still', 'a', 'bit', 'of', 'a', 'newbie', ')', ',', 'so', 'i', 'wanted', 'to', 'check', 'with', 'you', 'first', '.', 'btw', 'as'], 0, '146860774.13072.13072')\n([['no', 'more', 'than', 'two', 'editors', 'advocated', 'deletion', '.', 'UNK', 'and', 'maybe', 'UNK', '.', 'that', \"'\", 's', 'not', 'a', 'clear', 'consensus', 'for', 'deletion', '.', 'cheers', ','], ['in', 'the', 'future', 'please', 'don', \"'\", 't', 'close', 'afds', 'when', 'you', 'don', \"'\", 't', 'have', 'the', 'courtesy', 'of', 'reading', 'the', 'comments', '.', 'all', 'comments', 'favored', 'deletion', 'except', 'two', '.', 'please', 'don', \"'\", 't', 'be', 'so', 'careless', 'in', 'the', 'future', '.'], ['that', 'simply', 'isn', \"'\", 't', 'true', '.', 'if', 'you', 'read', 'the', 'comments', ',', 'you', \"'\", 'll', 'find', 'it', \"'\", 's', 'actually', '2', 'keep', ',', '4', 'transwiki', ',', '2', 'delete', '(', 'more', 'or', 'less', ')', '.', 'the', \"'\", \"'\", 'comments', \"'\", \"'\", 'favour', 'no', 'consensus', '/', 'transwiki', '.', 'the', '\"', 'votes', '\"', 'favour', 'delete', ',', 'but', 'voting', 'is', 'evil', ',', 'of', 'course', '.', '.', '.'], ['somehow', ',', 'i', 'suspect', 'you', 'may', 'wish', 'to', 'participate', 'in', 'UNK', 'discussion', '.', 'cheers', ',']], ['i', 'assume', 'your', 'deliberate', 'lying', 'has', 'a', 'point', ',', 'but', 'get', 'over', 'it', '.', 'stop', 'bizarrely', 'goin', 'on', 'about', 'UNK', '.', 'that', 'has', 'nothing', 'to', 'do', 'with', 'the', 'afd', '.', 'there', 'was', 'a', 'plain', 'consensus', 'for', 'deleting', 'the', 'article', '.', 'UNK', 'is', 'completely', 'unrelated', '.', 'please', 'don', \"'\", 't', 'be', 'so', 'deliberately', 'obtuse', 'in', 'the', 'future', '.', 'wasting', 'other', 'people', \"'\", 's', 'time', 'is', 'simply', 'rude', '.'], 1, '144065917.12226.12226')\n([['if', 'you', 'have', 'problems', 'with', 'my', 'edits', 'to', 'the', 'UNK', 'page', 'please', 'let', 'me', 'know', ',', 'do', 'not', 'just', 'revert', 'the', 'edits', '.', 'although', 'the', 'UNK', 'article', 'is', 'very', 'accurate', 'the', 'introduction', 'is', 'riddled', 'with', 'errors', ',', 'which', 'i', 'corrected', '.', 'i', 'think', 'it', 'is', 'everyone', \"'\", 's', 'best', 'interests', 'to', 'make', 'wiki', 'pages', 'as', 'accurate', 'as', 'possible', 'and', 'the', 'four', 'wheel', 'drive', 'article', 'is', 'not', 'a', 'UNK', 'example', 'of', 'this', '.', 'i', '.', 'e', '.', 'all', '-', 'wheel'], ['*', 'shrug', '*', 'it', '*', 'is', '*', 'just', 'a', 'marketing', 'term', '.', 'i', 'wish', 'you', 'lot', 'would', 'stop', 'editing', 'it', 'otherwise', '.', 'UNK', '.']], ['although', 'UNK', 'can', 'be', 'considered', 'a', 'form', 'of', 'UNK', 'it', 'is', 'not', 'the', 'same', 'drive', 'train', 'type', 'as', 'part', '-', 'time', 'UNK', '.', 'so', 'i', 'would', 'have', 'to', 'say', 'calling', 'it', 'just', 'a', 'marketing', 'term', 'is', 'a', 'narrow', 'minded', 'and', 'inaccurate', 'statement', '.', 'even', 'though', 'they', 'are', 'similar', 'you', 'can', \"'\", 't', 'just', 'UNK', 'them', 'into', 'the', 'same', 'group', '.', 'if', ',', 'as', 'you', 'say', ',', 'UNK', 'is', 'just', 'a', 'marketing', 'term', 'then', 'taking', 'a', 'turn', 'in', 'a', 'audi'], 0, '127772860.903.903')\n([['please', 'stop', 'removing', 'and', 'altering', 'other', 'editors', \"'\", 'comments', '.', 'what', 'appeared', 'to', 'be', 'valid', 'concern', 'is', 'quickly', 'descending', 'into', 'trolling', ',', 'and', 'if', 'you', 'continue', ',', 'you', 'may', 'be', 'blocked', 'from', 'editing', '.', 'stop', 'it', '.', '-'], ['well', 'please', 'stop', 'posting', 'incorrect', 'information', '.', 'if', 'you', 'were', 'right', 'i', \"'\", 'd', 'agree', 'with', 'you', ',', 'and', 'i', 'am', 'not', 'trolling', '.'], ['UNK', 'is', 'trolling', ',', 'as', 'is', 'removing', 'other', 'people', \"'\", 's', 'comments', '.', 'look', ',', 'wikipedia', 'is', 'built', 'on', 'consensus', ',', 'and', 'consensus', 'has', 'it', 'that', 'we', 'use', 'american', 'style', 'for', 'american', 'subjects', '.', 'end', 'of', 'story', '.', 'any', 'more', 'complaint', 'about', 'trolling', 'about', 'this', 'topic', 'and', 'i', \"'\", 'll', 'report', 'you', 'myself', '.']], ['bullshit', '.', 'i', 'am', 'correcting', 'a', 'simple', 'mistake', '.', 'if', 'i', 'was', 'trolling', 'i', \"'\", 'd', 'be', 'doing', 'damage', 'to', 'the', 'page', ',', 'yet', 'i', 'am', 'not', '.', 'what', 'was', 'written', 'is', 'wrong', ',', 'simple', 'as', 'that', '.', 'all', 'i', 'have', 'done', 'is', 'disagree', 'with', 'what', 'was', 'written', 'and', 'written', 'as', 'such', '.', 'if', 'that', \"'\", 's', 'trolling', 'then', 'you', 'are', 'guilty', 'as', 'well', '.', 'and', 'stop', 'UNK', 'my', 'page', 'dickhead', '.', 'UNK', '.'], 1, '144645449.1479.1479')\n([['please', 'stop', 'including', 'disreputable', 'sources', 'for', 'this', 'article', '.', 'wikipedia', 'policy', 'is', 'quite', 'clear', 'on', 'this', 'matter', 'blogs', 'and', 'other', 'websites', 'which', 'do', 'not', 'employ', 'editorial', 'oversight', 'of', 'authors', \"'\", 'work', 'are', 'not', 'permitted', 'as', 'sources', 'here', '.', 'please', 'stop', 'adding', 'blogs', '.'], ['please', 'stop', 'deleting', 'reputable', 'sources', 'from', 'this', 'article', '.', 'you', 'have', 'deleted', 'joe', 'wilson', \"'\", 's', 'nyt', 'article', 'that', 'is', 'a', 'key', 'factor', 'in', 'this', 'whole', 'controversy', '!', 'among', 'others', '.', 'simply', 'because', 'the', 'article', 'is', 'printed', 'on', 'a', 'different', 'site', 'does', 'not', 'mean', 'it', 'is', 'sourced', 'to', 'a', '\"', 'heinous', 'blog', '\"', '(', 'which', 'the', 'site', 'is', 'not', 'anyway', ')', '.', 'if', 'you', 'find', 'a', 'better', 'place', 'that', 'the', 'article', 'exists', ',', 'put', 'it', 'there', '.', 'or', 'if'], ['the', 'american', 'prospect', 'article', 'should', 'stay', '-', 'american', 'prospect', 'easily', 'meets', 'UNK', '.', 'the', 'cooperative', 'research', 'project', 'link', 'should', 'be', 'nuked', 'and', 'should', 'stay', 'nuked', '-', 'i', 'see', 'no', 'evidence', 'that', 'it', \"'\", 's', 'a', 'reliable', 'source', '.', 'factcheck', '.', 'org', 'is', 'reliable', 'enough', 'that', 'the', 'vice', 'president', 'of', 'the', 'united', 'states', '(', 'incorrectly', ')', 'cited', 'it', 'in', 'his', 'debate', 'as', 'an', 'authoritative', 'source', ';', 'they', 'have', 'a', 'good', 'reputation', ',', 'and', 'their', 'very', \"'\", \"'\", 'purpose', \"'\", \"'\"], ['agreed', 'UNK', 'cooperative', 'research', 'but', 'not', 'the', 'alternet', 'citation', '-', 'they', 'are', 'transcribing', 'an', 'interview', 'on', 'a', 'well', 'known', 'radio', 'show', 'with', 'a', 'well', 'known', 'source', 'with', 'expertise', 'on', 'this', 'topic', 'whose', 'comments', 'are', 'cited', 'in', 'numerous', 'mainstream', 'sources', '.', 'if', 'you', 'have', 'a', 'better', 'source', 'for', 'the', 'transcript', 'that', 'is', 'fine', 'but', 'you', 'cannot', 'just', 'delete', 'it', 'because', 'it', 'is', '\"', 'edited', '\"', '-', 'unless', 'you', 'have', 'evidence', 'that', 'they', 'are', 'making', 'stuff', 'up', ',', 'we', 'must', 'presume'], ['actually', ',', 'especially', 'with', 'alternet', ',', 'we', \"'\", \"'\", 'can', \"'\", 't', \"'\", \"'\", 'assume', 'good', 'faith', ';', 'we', 'need', 'to', 'do', 'exactly', 'the', 'opposite', '.', 'we', 'need', 'to', 'examine', 'sources', 'critically', ',', 'according', 'to', 'the', 'guidelines', 'on', 'UNK', '.', 'were', 'it', 'to', 'be', 'a', 'verbatim', 'copy', ',', 'perhaps', 'we', 'could', 'accept', 'it', 'as', 'a', 'source', '(', \"'\", \"'\", 'perhaps', \"'\", \"'\", 'being', 'absolutely', 'critical', ')', ',', 'but', 'because', 'it', \"'\", 's', 'edited', 'and', 'doesn', \"'\", 't', 'contain', 'information']], ['(', '1', ')', 'please', 'substantiate', 'that', 'the', 'source', 'is', '\"', 'notoriously', 'unreliable', '.', '\"', '(', '2', ')', 'please', 'indicate', 'where', 'it', 'says', 'we', 'should', 'assume', 'bad', 'faith', 'with', 'sources', 'that', 'are', 'transcripts', 'of', 'interviews', '(', 'i', 'know', 'the', 'quote', 'in', 'the', 'article', 'is', 'directly', 'from', 'the', 'interview', 'as', 'i', 'listened', 'to', 'the', 'interview', 'myself', ';', 'i', 'also', 'have', 'looked', 'at', 'the', 'transcript', 'and', 'do', 'not', 'see', 'anything', 'that', 'is', 'different', 'from', 'what', 'i', 'heard', ';', 'but', 'apparently', 'i', 'should'], 0, '67176052.25110.25110')\n"
     ]
    }
   ],
   "source": [
    "# Validate the conversion by checking data size and some samples\n",
    "print(len(train_pairs))\n",
    "print(len(val_pairs))\n",
    "print(len(test_pairs))\n",
    "for p in train_pairs[:5]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghTVeRFK0CUe"
   },
   "source": [
    "## Part 3: define the inference pipeline\n",
    "\n",
    "CRAFT inference consists of three steps: (1) using the utterance encoder to produce embeddings of each comment in the context (2) running the comment embeddings through the context encoder to get a final representation of conversational context (3) running the classifier head on the context embedding. To streamline the subsequent code, we encapsulate these three steps in a single PyTorch `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZzAgSRKi0p_I"
   },
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    \"\"\"This helper module encapsulates the CRAFT pipeline, defining the logic of passing an input through each consecutive sub-module.\"\"\"\n",
    "    def __init__(self, encoder, context_encoder, classifier):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.context_encoder = context_encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length):\n",
    "        # Forward input through encoder model\n",
    "        _, utt_encoder_hidden = self.encoder(input_batch, utt_lengths)\n",
    "        \n",
    "        # Convert utterance encoder final states to batched dialogs for use by context encoder\n",
    "        context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)\n",
    "        \n",
    "        # Forward pass through context encoder\n",
    "        context_encoder_outputs, context_encoder_hidden = self.context_encoder(context_encoder_input, dialog_lengths)\n",
    "        \n",
    "        # Forward pass through classifier to get prediction logits\n",
    "        logits = self.classifier(context_encoder_outputs, dialog_lengths)\n",
    "        \n",
    "        # Apply sigmoid activation\n",
    "        predictions = F.sigmoid(logits)\n",
    "        return predictions"
   ]
  },
  {
   "source": [
    "## Note on LSA insertion\n",
    "\n",
    "I think it would be useful to append the LSA of the utterance being considered after the encoding has already occurred, then feed that through the classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjC1hgIWGl7g"
   },
   "source": [
    "## Part 4: define training loop\n",
    "\n",
    "Now that we have all the model components defined, we need to define the actual training procedure. This will be a fairly standard neural network training loop, iterating over batches of labeled dialogs and computing cross-entropy loss on the predicted label. We will also define evaluation functions so that we can compute accuracy on the validation set after every epoch, allowing us to keep the model with the best validation performance. Note that for the sake of simpler code, validation accuracy is computed in the \"unfair\" manner using a single run of CRAFT over the full context preceding the actual personal attack, rather than the more realistic (and complicated) iterated evaluation that is used for final evaluation of the test set (in practice the two metrics track each other fairly well, making this a reasonable simplification for the sake of easy validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zIAHOvcdHR_h"
   },
   "outputs": [],
   "source": [
    "def train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments\n",
    "          encoder, context_encoder, attack_clf,                                                                    # network arguments\n",
    "          encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments\n",
    "          batch_size, clip, max_length=MAX_LENGTH):                                                                # misc arguments\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    context_encoder_optimizer.zero_grad()\n",
    "    attack_clf_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    dialog_lengths = dialog_lengths.to(device)\n",
    "    utt_lengths = utt_lengths.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward pass through utterance encoder\n",
    "    _, utt_encoder_hidden = encoder(input_variable, utt_lengths)\n",
    "    \n",
    "    # Convert utterance encoder final states to batched dialogs for use by context encoder\n",
    "    context_encoder_input = makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)\n",
    "    \n",
    "    # Forward pass through context encoder\n",
    "    context_encoder_outputs, _ = context_encoder(context_encoder_input, dialog_lengths)\n",
    "\n",
    "    # Forward pass through classifier to get prediction logits\n",
    "    logits = attack_clf(context_encoder_outputs, dialog_lengths)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(context_encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(attack_clf.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    context_encoder_optimizer.step()\n",
    "    attack_clf_optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def evaluateBatch(encoder, context_encoder, predictor, voc, input_batch, dialog_lengths, \n",
    "                  dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, device, max_length=MAX_LENGTH):\n",
    "    # Set device options\n",
    "    input_batch = input_batch.to(device)\n",
    "    dialog_lengths = dialog_lengths.to(device)\n",
    "    utt_lengths = utt_lengths.to(device)\n",
    "    # Predict future attack using predictor\n",
    "    scores = predictor(input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length)\n",
    "    predictions = (scores > 0.5).float()\n",
    "    return predictions, scores\n",
    "\n",
    "def validate(dataset, encoder, context_encoder, predictor, voc, batch_size, device):\n",
    "    # create a batch iterator for the given data\n",
    "    batch_iterator = batchIterator(voc, dataset, batch_size, shuffle=False)\n",
    "    # find out how many iterations we will need to cover the whole dataset\n",
    "    n_iters = len(dataset) // batch_size + int(len(dataset) % batch_size > 0)\n",
    "    # containers for full prediction results so we can compute accuracy at the end\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for iteration in range(1, n_iters+1):\n",
    "        batch, batch_dialogs, _, true_batch_size = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len = batch\n",
    "        dialog_lengths_list = [len(x) for x in batch_dialogs]\n",
    "        # run the model\n",
    "        predictions, scores = evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,\n",
    "                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices,\n",
    "                                            true_batch_size, device)\n",
    "        # aggregate results for computing accuracy at the end\n",
    "        all_preds += [p.item() for p in predictions]\n",
    "        all_labels += [l.item() for l in labels]\n",
    "        print(\"Iteration: {}; Percent complete: {:.1f}%\".format(iteration, iteration / n_iters * 100))\n",
    "\n",
    "    # compute and return the accuracy\n",
    "    return (np.asarray(all_preds) == np.asarray(all_labels)).mean()\n",
    "\n",
    "def trainIters(voc, pairs, val_pairs, encoder, context_encoder, attack_clf,\n",
    "               encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,\n",
    "               n_iteration, batch_size, print_every, validate_every, clip):\n",
    "    \n",
    "    # create a batch iterator for training data\n",
    "    batch_iterator = batchIterator(voc, pairs, batch_size)\n",
    "    \n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    # keep track of best validation accuracy - only save when we have a model that beats the current best\n",
    "    best_acc = 0\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch, training_dialogs, _, true_batch_size = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, _, target_variable, mask, max_target_len = training_batch\n",
    "        dialog_lengths_list = [len(x) for x in training_dialogs]\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments\n",
    "                     encoder, context_encoder, attack_clf,                                                                    # network arguments\n",
    "                     encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      # optimization arguments\n",
    "                     true_batch_size, clip)                                                                                   # misc arguments\n",
    "        print_loss += loss\n",
    "        \n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        if (iteration % validate_every == 0):\n",
    "            print(\"Validating!\")\n",
    "            # put the network components into evaluation mode\n",
    "            encoder.eval()\n",
    "            context_encoder.eval()\n",
    "            attack_clf.eval()\n",
    "            \n",
    "            predictor = Predictor(encoder, context_encoder, attack_clf)\n",
    "            accuracy = validate(val_pairs, encoder, context_encoder, predictor, voc, batch_size, device)\n",
    "            print(\"Validation set accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "            # keep track of our best model so far\n",
    "            if accuracy > best_acc:\n",
    "                print(\"Validation accuracy better than current best; saving model...\")\n",
    "                best_acc = accuracy\n",
    "                torch.save({\n",
    "                    'iteration': iteration,\n",
    "                    'en': encoder.state_dict(),\n",
    "                    'ctx': context_encoder.state_dict(),\n",
    "                    'atk_clf': attack_clf.state_dict(),\n",
    "                    'en_opt': encoder_optimizer.state_dict(),\n",
    "                    'ctx_opt': context_encoder_optimizer.state_dict(),\n",
    "                    'atk_clf_opt': attack_clf_optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    'voc_dict': voc.__dict__,\n",
    "                    'embedding': embedding.state_dict()\n",
    "                }, os.path.join(save_dir, \"finetuned_model.tar\"))\n",
    "            \n",
    "            # put the network components back into training mode\n",
    "            encoder.train()\n",
    "            context_encoder.train()\n",
    "            attack_clf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eG1p_cH5fw9"
   },
   "source": [
    "## Part 5: define the evaluation procedure\n",
    "\n",
    "We're almost ready to run! The last component we need is some code to evaluate performance on the test set after fine-tuning is completed. This evaluation should use the full iterative procedure described in the paper, replicating how a system might be deployed in practice, without knowledge of where the personal attack occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yZqEcwEJ5bqn"
   },
   "outputs": [],
   "source": [
    "def evaluateDataset(dataset, encoder, context_encoder, predictor, voc, batch_size, device):\n",
    "    # create a batch iterator for the given data\n",
    "    batch_iterator = batchIterator(voc, dataset, batch_size, shuffle=False)\n",
    "    # find out how many iterations we will need to cover the whole dataset\n",
    "    n_iters = len(dataset) // batch_size + int(len(dataset) % batch_size > 0)\n",
    "    output_df = {\n",
    "        \"id\": [],\n",
    "        \"prediction\": [],\n",
    "        \"score\": []\n",
    "    }\n",
    "    for iteration in range(1, n_iters+1):\n",
    "        batch, batch_dialogs, _, true_batch_size = next(batch_iterator)\n",
    "        # Extract fields from batch\n",
    "        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len = batch\n",
    "        dialog_lengths_list = [len(x) for x in batch_dialogs]\n",
    "        # run the model\n",
    "        predictions, scores = evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,\n",
    "                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices,\n",
    "                                            true_batch_size, device)\n",
    "\n",
    "        # format the output as a dataframe (which we can later re-join with the corpus)\n",
    "        for i in range(true_batch_size):\n",
    "            convo_id = convo_ids[i]\n",
    "            pred = predictions[i].item()\n",
    "            score = scores[i].item()\n",
    "            output_df[\"id\"].append(convo_id)\n",
    "            output_df[\"prediction\"].append(pred)\n",
    "            output_df[\"score\"].append(score)\n",
    "                \n",
    "        print(\"Iteration: {}; Percent complete: {:.1f}%\".format(iteration, iteration / n_iters * 100))\n",
    "\n",
    "    return pd.DataFrame(output_df).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0VIv8sbOaB6"
   },
   "source": [
    "## Part 6: build and fine-tune the model\n",
    "\n",
    "We finally have all the components we need! Now we can instantiate the CRAFT model components, load the pre-trained weights, and run fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\ewais\\Documents\\GitHub\\CRAFT\\saved_models\\wikiconv\n"
     ]
    }
   ],
   "source": [
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4QRinW10Oo_G",
    "outputId": "99df8b29-f6cb-4fab-80db-611e73ab3869",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n",
      "Building optimizers...\n",
      "Starting Training!\n",
      "Will train for 1170 iterations\n",
      "Initializing ...\n",
      "Training...\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 2.5094e-02,  7.0583e-03, -6.1583e-03,  ..., -3.4799e-03,\n",
      "          -5.9452e-03, -5.0593e-02],\n",
      "         [ 8.5994e-03,  9.1785e-02, -2.7779e-03,  ..., -3.5229e-03,\n",
      "          -1.7892e-02, -4.0148e-02],\n",
      "         [ 1.3100e-02, -1.6534e-01,  1.4633e-02,  ...,  1.7335e-03,\n",
      "           5.5499e-03, -3.1306e-02],\n",
      "         ...,\n",
      "         [ 6.8962e-03, -8.7166e-02, -1.2234e-03,  ..., -3.0816e-03,\n",
      "          -6.9299e-03, -7.3052e-02],\n",
      "         [ 5.7617e-03, -1.2811e-01, -5.8840e-03,  ..., -9.7401e-04,\n",
      "          -9.6754e-03, -1.2935e-01],\n",
      "         [-7.5805e-04, -4.8018e-02, -2.9214e-02,  ...,  7.4505e-04,\n",
      "          -5.4657e-03, -1.2377e-01]],\n",
      "\n",
      "        [[ 2.9120e-02, -3.6171e-02, -7.1788e-03,  ..., -4.0888e-03,\n",
      "          -6.9608e-03, -1.2126e-01],\n",
      "         [ 3.0749e-02,  1.2547e-01, -3.3916e-03,  ..., -5.4642e-03,\n",
      "          -1.9768e-02, -2.8742e-02],\n",
      "         [ 1.6511e-02, -9.1365e-02,  1.3404e-02,  ..., -3.8961e-04,\n",
      "           1.0357e-03, -3.8335e-02],\n",
      "         ...,\n",
      "         [ 8.0683e-03, -2.1602e-01, -5.1250e-03,  ..., -6.3469e-03,\n",
      "          -1.4231e-02, -5.5036e-02],\n",
      "         [-2.1328e-02, -1.9629e-01, -7.4614e-03,  ..., -7.6053e-04,\n",
      "          -1.5688e-02, -8.5346e-02],\n",
      "         [-5.2291e-03, -1.2018e-01, -4.2150e-02,  ..., -5.9412e-04,\n",
      "          -8.1283e-03, -1.0626e-01]],\n",
      "\n",
      "        [[ 2.9782e-02, -6.7270e-02, -7.6661e-03,  ..., -4.3202e-03,\n",
      "          -7.6698e-03, -1.6975e-01],\n",
      "         [ 3.1243e-02,  1.4318e-01, -5.9605e-03,  ..., -6.5205e-03,\n",
      "          -2.1171e-02,  2.1976e-02],\n",
      "         [ 1.5654e-02, -1.0415e-01,  1.1487e-02,  ..., -1.6922e-03,\n",
      "          -3.0324e-03, -5.4057e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.5870e-02,  3.1510e-01, -1.2753e-02,  ..., -1.9064e-02,\n",
      "          -1.6537e-02,  8.5533e-02],\n",
      "         [ 3.9508e-02, -5.1964e-02, -2.2779e-02,  ..., -1.4807e-02,\n",
      "          -3.2970e-02,  1.9171e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.7962e-02,  3.1877e-01, -1.4038e-02,  ..., -2.1321e-02,\n",
      "          -1.7662e-02,  1.0160e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 6.5667e-02,  4.0725e-01, -1.4499e-02,  ..., -2.2903e-02,\n",
      "          -1.9596e-02, -7.4690e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-4.7112e-03, -1.0284e-01, -4.3142e-03,  ..., -1.8551e-03,\n",
      "          -5.3945e-03, -6.0781e-02],\n",
      "         [ 1.2404e-02, -2.4196e-02, -2.7580e-03,  ..., -4.1749e-03,\n",
      "          -3.6625e-03, -3.4701e-02],\n",
      "         [-6.3809e-02,  3.2190e-01,  1.6421e-03,  ..., -8.1841e-03,\n",
      "           7.3479e-04, -4.4772e-03],\n",
      "         ...,\n",
      "         [ 1.1498e-03, -2.4999e-01, -1.1725e-02,  ..., -4.6048e-03,\n",
      "          -4.7437e-03,  6.0606e-03],\n",
      "         [-6.9980e-05, -1.2552e-02, -2.8522e-03,  ..., -3.2485e-03,\n",
      "          -9.8083e-03, -4.2736e-02],\n",
      "         [ 3.6413e-03, -1.2348e-01, -4.8461e-03,  ..., -4.4399e-03,\n",
      "           6.4147e-03,  2.9877e-02]],\n",
      "\n",
      "        [[-2.8701e-03, -1.2204e-02, -5.0557e-03,  ..., -4.1350e-03,\n",
      "          -8.7058e-04, -9.4964e-02],\n",
      "         [ 3.7934e-02, -1.4971e-02, -1.0597e-04,  ..., -5.3692e-03,\n",
      "          -3.8886e-03,  7.4839e-02],\n",
      "         [-1.1266e-01,  2.7682e-01, -1.2995e-03,  ..., -9.0128e-03,\n",
      "          -6.0336e-03, -5.9867e-02],\n",
      "         ...,\n",
      "         [ 1.3475e-03, -2.8719e-01, -1.4406e-02,  ..., -5.8052e-03,\n",
      "          -7.0536e-03,  5.0820e-02],\n",
      "         [ 4.0845e-03, -1.0317e-01, -3.9908e-03,  ..., -4.4623e-03,\n",
      "          -1.4129e-02, -1.5987e-02],\n",
      "         [ 6.9082e-03, -1.4171e-01, -8.2682e-03,  ..., -6.3774e-03,\n",
      "           6.7289e-03,  5.2594e-02]],\n",
      "\n",
      "        [[-8.6790e-03, -1.0156e-01, -8.2767e-03,  ..., -7.8358e-03,\n",
      "          -2.2194e-03, -9.4129e-02],\n",
      "         [ 3.7941e-02,  1.6399e-01, -3.1790e-03,  ..., -7.6787e-03,\n",
      "          -1.2192e-02,  9.3273e-02],\n",
      "         [-1.2541e-01,  5.2629e-01, -4.5020e-03,  ..., -1.1562e-02,\n",
      "          -1.0671e-02,  6.0670e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.2591e-04, -4.4684e-02, -1.3474e-02,  ..., -2.0814e-02,\n",
      "           5.6294e-03, -1.2637e-01],\n",
      "         [ 2.1450e-02,  2.9313e-01, -7.7263e-03,  ..., -1.1342e-02,\n",
      "          -1.7622e-02,  1.3346e-01],\n",
      "         [-1.0956e-01,  2.8758e-01, -1.2944e-02,  ..., -1.7088e-02,\n",
      "          -2.1880e-02, -1.3663e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.6225e-03, -1.0546e-01, -1.4746e-02,  ..., -2.1515e-02,\n",
      "           1.3812e-03, -1.5111e-01],\n",
      "         [ 3.3382e-02,  3.7764e-01, -8.3456e-03,  ..., -1.2466e-02,\n",
      "          -1.9613e-02,  6.4134e-02],\n",
      "         [-1.0663e-01,  2.7558e-01, -1.3408e-02,  ..., -1.7899e-02,\n",
      "          -2.5624e-02, -4.3782e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.7638e-03, -7.2188e-02, -1.5965e-02,  ..., -2.3064e-02,\n",
      "           2.3496e-03, -1.1857e-01],\n",
      "         [ 2.3600e-02,  4.3084e-01, -1.2139e-02,  ..., -1.3601e-02,\n",
      "          -2.3217e-02,  3.8964e-02],\n",
      "         [-1.0517e-01,  1.9747e-01, -1.4419e-02,  ..., -1.8313e-02,\n",
      "          -2.7149e-02, -1.1791e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([16, 64, 500])\n",
      "encoder_input_lengths:  tensor([16, 11,  9,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  3,  3,  3,  3,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-9.8975e-04, -6.5897e-02, -9.2394e-03,  ..., -5.6000e-03,\n",
      "           4.0628e-03, -3.7418e-02],\n",
      "         [ 1.0757e-02, -1.4198e-01, -1.6350e-02,  ..., -6.4703e-03,\n",
      "           3.9323e-03, -8.5070e-02],\n",
      "         [ 1.3236e-03, -8.6876e-02, -8.5243e-04,  ..., -1.0091e-02,\n",
      "           5.7062e-03, -1.0765e-01],\n",
      "         ...,\n",
      "         [-4.5888e-03, -1.0294e-01, -1.4741e-02,  ..., -5.3341e-03,\n",
      "          -1.0945e-02,  1.3045e-02],\n",
      "         [ 7.5693e-04, -1.5493e-01,  3.2843e-02,  ..., -7.9096e-03,\n",
      "           4.2087e-03, -1.1024e-01],\n",
      "         [-2.4359e-02,  8.1100e-03, -3.9872e-03,  ..., -3.6319e-03,\n",
      "          -6.7526e-03, -4.9051e-02]],\n",
      "\n",
      "        [[ 3.8663e-03, -1.9206e-01, -1.7561e-02,  ..., -1.3570e-02,\n",
      "           6.0081e-03, -1.2491e-01],\n",
      "         [ 1.1232e-02, -2.5297e-01, -1.7692e-02,  ..., -9.6482e-03,\n",
      "          -1.9491e-03,  7.8766e-03],\n",
      "         [ 3.0177e-03,  5.3264e-02, -4.4542e-03,  ..., -1.4567e-02,\n",
      "           6.3882e-03, -1.1740e-01],\n",
      "         ...,\n",
      "         [-7.4265e-03, -6.9016e-02, -2.1428e-02,  ..., -1.1534e-02,\n",
      "          -7.6783e-03, -4.0977e-02],\n",
      "         [-2.4817e-04, -1.5919e-01,  2.6535e-02,  ..., -1.2162e-02,\n",
      "           2.3711e-03, -1.1620e-01],\n",
      "         [-1.1189e-02, -6.7636e-02, -7.6183e-03,  ..., -8.9143e-03,\n",
      "          -6.7862e-03,  6.9238e-02]],\n",
      "\n",
      "        [[ 5.1691e-03, -2.6421e-01, -2.1157e-02,  ..., -1.5154e-02,\n",
      "           9.5435e-03, -9.4431e-02],\n",
      "         [ 3.1791e-03, -2.1874e-01, -2.3970e-02,  ..., -1.0372e-02,\n",
      "          -7.6052e-03,  6.7488e-02],\n",
      "         [ 3.5174e-02,  3.3384e-01, -5.4280e-03,  ..., -1.5853e-02,\n",
      "          -9.2430e-03, -6.9897e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.1936e-02, -2.8818e-01, -6.1177e-02,  ..., -3.2786e-02,\n",
      "           3.4038e-02, -3.9373e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.0973e-02, -2.9778e-01, -6.3092e-02,  ..., -3.3151e-02,\n",
      "           3.4299e-02,  3.2178e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.9711e-02, -2.8463e-01, -6.4605e-02,  ..., -3.3923e-02,\n",
      "           3.4134e-02,  7.9605e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([14, 64, 500])\n",
      "encoder_input_lengths:  tensor([14,  9,  9,  9,  9,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 2.2431e-02, -1.3889e-01,  5.1554e-03,  ..., -3.4214e-03,\n",
      "          -1.1214e-02, -7.9210e-02],\n",
      "         [-2.6170e-03, -1.7170e-01, -2.0905e-03,  ..., -7.7083e-03,\n",
      "           5.3848e-03,  3.9127e-02],\n",
      "         [ 5.5832e-02,  6.5295e-02, -2.9908e-03,  ..., -2.3104e-03,\n",
      "          -1.0521e-02, -9.3205e-02],\n",
      "         ...,\n",
      "         [-8.1642e-03, -2.6439e-01, -6.7956e-03,  ..., -6.2226e-03,\n",
      "          -1.2934e-02, -5.5053e-03],\n",
      "         [ 1.5811e-02,  1.3906e-01, -4.6839e-03,  ..., -2.7249e-03,\n",
      "          -9.2857e-03,  5.7886e-02],\n",
      "         [ 1.6414e-02,  4.1829e-01, -3.8251e-03,  ..., -1.0917e-02,\n",
      "          -1.2518e-03,  6.6417e-02]],\n",
      "\n",
      "        [[ 3.7127e-03, -5.1282e-02, -2.3984e-02,  ..., -6.3899e-03,\n",
      "          -2.7447e-02, -4.9468e-02],\n",
      "         [-2.6626e-03, -2.4089e-01, -3.5136e-03,  ..., -8.5677e-03,\n",
      "           3.5905e-03,  4.3019e-02],\n",
      "         [ 4.5381e-02, -4.6738e-02, -3.5267e-03,  ..., -2.8223e-03,\n",
      "          -1.3909e-02, -6.6260e-02],\n",
      "         ...,\n",
      "         [-1.0363e-02, -2.8751e-01, -8.4912e-03,  ..., -8.0172e-03,\n",
      "          -1.6099e-02,  1.2503e-03],\n",
      "         [-2.9129e-02,  2.6544e-01, -6.4889e-03,  ..., -1.5568e-02,\n",
      "          -9.2179e-03,  1.9504e-01],\n",
      "         [ 1.8405e-02,  4.5576e-01, -6.0135e-03,  ..., -1.2972e-02,\n",
      "          -2.3551e-04,  6.0807e-02]],\n",
      "\n",
      "        [[ 8.1544e-03, -5.8726e-02, -2.6771e-02,  ..., -7.5619e-03,\n",
      "          -3.1242e-02, -4.9113e-02],\n",
      "         [-4.1553e-03, -2.8260e-01, -3.8588e-03,  ..., -1.1569e-02,\n",
      "           2.2684e-04,  7.6859e-02],\n",
      "         [ 5.2936e-02, -1.1043e-01, -6.2451e-03,  ..., -5.1662e-03,\n",
      "          -2.0383e-02, -1.2252e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.4900e-03,  5.9982e-03, -4.0169e-02,  ..., -1.7836e-02,\n",
      "          -6.0100e-02,  1.5607e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.4523e-04,  2.7550e-02, -3.3074e-02,  ..., -1.7589e-02,\n",
      "          -6.3412e-02,  5.7648e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-6.4522e-03, -5.0866e-02, -3.9265e-02,  ..., -1.6029e-02,\n",
      "          -6.7810e-02,  1.2123e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([15, 64, 500])\n",
      "encoder_input_lengths:  tensor([15, 12,  9,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  7,  7,  7,  7,\n",
      "         7,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 6.1877e-03, -2.4702e-01, -3.0645e-04,  ..., -1.1014e-02,\n",
      "          -5.5255e-03, -5.5243e-02],\n",
      "         [-1.1239e-02, -9.3324e-03, -1.8107e-02,  ...,  1.0134e-03,\n",
      "          -3.9517e-03, -9.6362e-02],\n",
      "         [-5.2165e-02,  3.1445e-01, -3.9536e-03,  ..., -3.5693e-03,\n",
      "          -9.6632e-03, -4.2054e-02],\n",
      "         ...,\n",
      "         [-2.2967e-03,  3.6489e-01, -4.3757e-03,  ..., -6.7208e-03,\n",
      "           2.4841e-03, -9.5896e-02],\n",
      "         [-3.2726e-02,  1.1707e-01, -1.0033e-02,  ..., -4.2526e-03,\n",
      "           1.6221e-04, -9.4342e-02],\n",
      "         [ 4.0769e-02,  2.0523e-01, -4.6471e-03,  ..., -1.0183e-02,\n",
      "          -1.3454e-02, -1.1877e-02]],\n",
      "\n",
      "        [[ 8.0540e-03, -2.6962e-01, -1.5838e-03,  ..., -1.5340e-02,\n",
      "          -6.5816e-03, -2.5290e-02],\n",
      "         [-8.1802e-03, -8.6389e-02, -1.9651e-02,  ...,  2.9158e-04,\n",
      "          -5.5658e-03, -1.3477e-01],\n",
      "         [-4.8076e-02,  2.0164e-01, -5.1483e-03,  ..., -4.5638e-03,\n",
      "          -8.9159e-03, -2.9340e-02],\n",
      "         ...,\n",
      "         [ 5.2054e-02,  5.5080e-01, -6.2943e-03,  ..., -9.0816e-03,\n",
      "           2.7836e-04,  9.3627e-03],\n",
      "         [-2.8540e-01,  2.6284e-02, -1.8959e-02,  ..., -1.0761e-02,\n",
      "           7.6911e-03, -6.6363e-02],\n",
      "         [ 5.8119e-02,  2.7221e-01, -7.5624e-03,  ..., -2.0085e-02,\n",
      "          -1.4011e-02,  7.4508e-02]],\n",
      "\n",
      "        [[ 1.2763e-02, -2.0501e-01, -1.7325e-03,  ..., -4.5392e-02,\n",
      "          -1.3922e-02, -1.3909e-01],\n",
      "         [-4.8620e-03, -1.3475e-01, -2.1173e-02,  ..., -7.2890e-04,\n",
      "          -6.1402e-03, -1.7989e-01],\n",
      "         [-4.0446e-02,  1.4264e-01, -7.6095e-03,  ..., -6.0091e-03,\n",
      "          -1.0879e-02, -3.1600e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.9153e-02, -1.0048e-01, -4.8205e-03,  ..., -8.3870e-02,\n",
      "          -5.2013e-02,  6.4707e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.9806e-02, -4.9813e-02, -5.3331e-03,  ..., -8.4698e-02,\n",
      "          -5.5294e-02,  1.0966e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.0352e-02, -2.7834e-04, -5.6525e-03,  ..., -8.7053e-02,\n",
      "          -5.7973e-02, -1.0634e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  7,  6,  6,  6,  6,  6,  6,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,\n",
      "         3,  3,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0165,  0.0838, -0.0020,  ..., -0.0062, -0.0376, -0.0161],\n",
      "         [ 0.0317,  0.0392,  0.0025,  ..., -0.0031, -0.0042, -0.0445],\n",
      "         [-0.0502,  0.1240, -0.0039,  ..., -0.0043, -0.0107, -0.0032],\n",
      "         ...,\n",
      "         [-0.0012, -0.1780, -0.0072,  ..., -0.0068, -0.0015, -0.0130],\n",
      "         [-0.0043, -0.0973, -0.0014,  ..., -0.0141, -0.0033,  0.0416],\n",
      "         [-0.0099, -0.0586,  0.0375,  ..., -0.0396,  0.0069, -0.1336]],\n",
      "\n",
      "        [[ 0.0088,  0.1834, -0.0009,  ..., -0.0086, -0.0396, -0.0208],\n",
      "         [ 0.0329, -0.0261,  0.0011,  ..., -0.0058, -0.0050, -0.1277],\n",
      "         [-0.0486,  0.0305, -0.0048,  ..., -0.0059, -0.0127,  0.0287],\n",
      "         ...,\n",
      "         [-0.0019, -0.0491, -0.0155,  ..., -0.0083, -0.0087,  0.0524],\n",
      "         [-0.0056, -0.1471, -0.0031,  ..., -0.0170, -0.0039,  0.0263],\n",
      "         [-0.0111, -0.1192,  0.0331,  ..., -0.0514,  0.0062, -0.0933]],\n",
      "\n",
      "        [[ 0.0177,  0.1685, -0.0014,  ..., -0.0103, -0.0398, -0.0436],\n",
      "         [ 0.0317, -0.0610, -0.0023,  ..., -0.0109, -0.0062, -0.0761],\n",
      "         [-0.0453, -0.0009, -0.0065,  ..., -0.0078, -0.0151,  0.0306],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0342,  0.1234, -0.0079,  ..., -0.0122, -0.0616,  0.0890],\n",
      "         [ 0.0191, -0.0468, -0.0160,  ..., -0.0172, -0.0112, -0.0647],\n",
      "         [-0.0281, -0.1370, -0.0096,  ..., -0.0195, -0.0204,  0.0985],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0334,  0.2785, -0.0086,  ..., -0.0130, -0.0628,  0.0910],\n",
      "         [ 0.0192, -0.0486, -0.0163,  ..., -0.0173, -0.0118, -0.1103],\n",
      "         [-0.0235, -0.1216, -0.0086,  ..., -0.0209, -0.0255,  0.0749],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0310,  0.2275, -0.0102,  ..., -0.0133, -0.0635,  0.0620],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([12, 64, 500])\n",
      "encoder_input_lengths:  tensor([12,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,\n",
      "         7,  7,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 3.4826e-03,  2.1845e-01,  1.0282e-03,  ..., -4.6718e-03,\n",
      "          -2.4370e-04, -7.6456e-02],\n",
      "         [-2.9692e-03, -4.1527e-02, -2.9376e-02,  ..., -2.6404e-03,\n",
      "          -7.6088e-03,  5.8202e-02],\n",
      "         [-1.2538e-03, -1.0478e-01, -8.9041e-03,  ..., -5.1934e-03,\n",
      "          -3.0079e-02, -1.0525e-02],\n",
      "         ...,\n",
      "         [ 6.6522e-03, -1.4213e-01, -1.1774e-02,  ..., -5.6741e-03,\n",
      "          -6.9649e-03, -4.9764e-02],\n",
      "         [ 1.2415e-02,  8.9564e-02, -1.1426e-03,  ..., -1.6331e-02,\n",
      "          -5.1077e-05, -7.0964e-02],\n",
      "         [-3.6060e-03,  1.2600e-01, -4.8310e-03,  ..., -5.7046e-03,\n",
      "           3.1196e-02, -8.0597e-02]],\n",
      "\n",
      "        [[ 5.6992e-03,  1.6506e-01, -1.4556e-03,  ..., -7.3549e-03,\n",
      "          -5.9596e-04, -2.6904e-02],\n",
      "         [ 2.3023e-03,  2.5077e-01, -3.9256e-02,  ..., -3.6644e-03,\n",
      "          -8.0496e-03,  7.4086e-02],\n",
      "         [-2.9411e-03,  3.1793e-02, -3.2828e-02,  ..., -1.2932e-02,\n",
      "          -3.4109e-02, -1.9546e-03],\n",
      "         ...,\n",
      "         [ 7.3098e-03, -1.6700e-01, -1.4310e-02,  ..., -9.2781e-03,\n",
      "          -1.0351e-02, -2.3410e-02],\n",
      "         [ 2.9089e-02,  2.2630e-01, -1.9531e-03,  ..., -2.0818e-02,\n",
      "          -1.2057e-02, -8.6983e-03],\n",
      "         [-3.5964e-02,  7.5013e-02, -2.3753e-02,  ...,  1.3868e-02,\n",
      "           6.4157e-02, -8.7007e-02]],\n",
      "\n",
      "        [[ 1.0336e-02,  1.2062e-01, -2.7734e-03,  ..., -8.9411e-03,\n",
      "          -9.6096e-04, -8.0154e-03],\n",
      "         [ 4.0155e-03,  4.5344e-02, -4.0684e-02,  ..., -3.9316e-03,\n",
      "          -1.0999e-02,  8.9467e-02],\n",
      "         [-4.9317e-03,  7.1923e-03, -5.3219e-02,  ..., -1.5777e-02,\n",
      "          -3.6809e-02,  5.4811e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8023e-02,  3.3793e-01, -7.5563e-03,  ..., -3.3172e-02,\n",
      "          -6.4915e-04, -4.4428e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.6899e-02,  2.0417e-01, -7.9397e-03,  ..., -3.5236e-02,\n",
      "          -1.0937e-03, -5.9856e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-7.3454e-02,  2.5449e-01, -8.5419e-03,  ..., -3.9871e-02,\n",
      "          -1.7558e-05, -6.9625e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.3090e-02,  1.6339e-01, -4.1431e-03,  ..., -1.2347e-02,\n",
      "           1.3620e-02,  2.6193e-02],\n",
      "         [ 3.4916e-03, -1.7110e-01, -1.3315e-02,  ..., -2.2494e-04,\n",
      "          -2.7995e-02, -1.9697e-02],\n",
      "         [ 2.4492e-03, -6.1269e-02, -1.1829e-03,  ..., -1.4524e-02,\n",
      "          -9.4309e-03, -9.9835e-02],\n",
      "         ...,\n",
      "         [-1.6030e-02,  2.2322e-01, -1.5090e-02,  ..., -2.5348e-03,\n",
      "          -5.8541e-03, -2.9151e-02],\n",
      "         [-5.1666e-03, -3.0480e-01,  3.5635e-01,  ..., -2.0966e-02,\n",
      "           8.8697e-03, -6.4907e-02],\n",
      "         [-3.2576e-03,  1.4906e-01, -3.2268e-03,  ..., -3.7768e-03,\n",
      "           8.7057e-04, -2.1075e-02]],\n",
      "\n",
      "        [[-3.6259e-03,  2.1168e-01, -5.8919e-03,  ..., -2.0967e-02,\n",
      "           5.8722e-03,  9.0979e-02],\n",
      "         [-1.6513e-02, -1.2443e-01, -1.9045e-02,  ..., -3.6388e-03,\n",
      "          -3.3227e-02,  2.8127e-02],\n",
      "         [ 3.5706e-03, -1.1822e-01, -2.9520e-03,  ..., -2.8067e-02,\n",
      "          -1.9976e-02, -4.1244e-02],\n",
      "         ...,\n",
      "         [-2.2169e-02,  3.9832e-01, -1.8210e-02,  ..., -7.0944e-03,\n",
      "          -1.2258e-02, -3.8870e-02],\n",
      "         [-7.0463e-03, -3.7465e-01,  3.1481e-01,  ..., -2.3644e-02,\n",
      "           4.5537e-03, -3.1659e-02],\n",
      "         [ 3.4733e-03,  2.0186e-01, -5.3217e-03,  ..., -7.5808e-03,\n",
      "           6.3981e-04, -9.6343e-03]],\n",
      "\n",
      "        [[-5.4718e-03,  3.5913e-01, -8.1017e-03,  ..., -2.6639e-02,\n",
      "           6.6305e-03,  1.1598e-01],\n",
      "         [-7.8523e-02, -1.1922e-01, -4.2038e-02,  ..., -1.9571e-03,\n",
      "          -3.6584e-02,  6.8787e-02],\n",
      "         [-8.0894e-04, -9.4882e-02, -2.9664e-03,  ..., -3.0118e-02,\n",
      "          -2.3727e-02,  6.7386e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.5031e-02,  5.5881e-01, -1.5235e-02,  ..., -5.1877e-02,\n",
      "          -2.8713e-03, -4.0043e-02],\n",
      "         [-8.0199e-02, -2.1408e-01, -4.6189e-02,  ..., -1.0816e-02,\n",
      "          -4.5173e-02,  7.7077e-02],\n",
      "         [ 6.5245e-03, -5.2548e-03, -5.1692e-03,  ..., -3.8443e-02,\n",
      "          -2.9117e-02,  5.2755e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.4233e-02,  4.3765e-01, -1.7435e-02,  ..., -5.3633e-02,\n",
      "          -1.3575e-03, -7.0511e-03],\n",
      "         [-8.0986e-02, -1.4913e-01, -4.7081e-02,  ..., -1.1805e-02,\n",
      "          -4.8198e-02,  3.5915e-02],\n",
      "         [ 7.5268e-03,  1.1506e-02, -4.4382e-03,  ..., -3.8318e-02,\n",
      "          -3.1499e-02,  1.2692e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.6327e-02,  3.1010e-01, -1.9169e-02,  ..., -5.9731e-02,\n",
      "          -1.7740e-03, -2.7352e-02],\n",
      "         [-8.1365e-02, -2.0959e-01, -4.7033e-02,  ..., -1.2314e-02,\n",
      "          -4.9894e-02,  5.1351e-02],\n",
      "         [-3.7764e-02,  1.6923e-01, -4.7178e-03,  ..., -3.9165e-02,\n",
      "          -3.4996e-02,  1.9788e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 9.3343e-03, -4.5279e-02, -2.6929e-03,  ..., -3.5698e-03,\n",
      "          -5.5217e-03, -4.8638e-02],\n",
      "         [ 4.3641e-02,  1.3935e-01, -9.0858e-03,  ..., -1.1883e-02,\n",
      "          -1.5980e-02, -1.0615e-01],\n",
      "         [-5.9707e-02, -8.3493e-02, -1.5503e-02,  ..., -7.8410e-03,\n",
      "           3.5340e-03, -5.1910e-02],\n",
      "         ...,\n",
      "         [ 5.6600e-03,  1.3333e-02, -5.3842e-03,  ..., -1.1002e-02,\n",
      "          -2.2427e-04,  4.7061e-03],\n",
      "         [ 6.5332e-03, -1.0202e-01, -2.1289e-03,  ..., -7.5372e-03,\n",
      "          -5.7018e-03, -7.5280e-02],\n",
      "         [-2.9041e-03, -2.2738e-02, -3.8176e-03,  ..., -5.6899e-03,\n",
      "          -2.7301e-03, -4.0398e-02]],\n",
      "\n",
      "        [[-2.2772e-02,  1.6413e-01, -6.1298e-03,  ..., -5.9581e-03,\n",
      "          -2.7031e-03,  5.6528e-02],\n",
      "         [ 6.6600e-02,  4.8537e-02, -1.5245e-02,  ..., -1.2821e-02,\n",
      "          -1.7415e-02, -4.3027e-02],\n",
      "         [-8.7741e-02, -1.4001e-01, -2.8417e-02,  ..., -1.3481e-02,\n",
      "           5.4756e-03, -5.6786e-02],\n",
      "         ...,\n",
      "         [ 5.7647e-03, -1.1359e-02, -6.7622e-03,  ...,  1.9380e-02,\n",
      "          -7.0243e-03, -5.8794e-02],\n",
      "         [ 8.4644e-03, -1.0007e-01, -1.5533e-03,  ..., -1.0403e-02,\n",
      "          -9.8592e-03, -1.1956e-01],\n",
      "         [-2.1624e-03, -9.4291e-02, -6.0595e-03,  ..., -1.2492e-02,\n",
      "          -2.9133e-03, -1.6528e-02]],\n",
      "\n",
      "        [[-6.9645e-03,  2.6441e-01, -8.0959e-03,  ..., -8.9329e-03,\n",
      "          -5.1033e-04,  1.2374e-01],\n",
      "         [ 7.3517e-02,  9.4964e-02, -1.9306e-02,  ..., -1.3503e-02,\n",
      "          -1.4306e-02,  1.9909e-02],\n",
      "         [-1.0266e-01, -1.2659e-01, -3.4995e-02,  ..., -1.4221e-02,\n",
      "           7.5177e-03, -1.0335e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5193e-02,  1.4519e-01, -1.2859e-02,  ..., -1.6509e-02,\n",
      "          -4.5170e-04,  2.0507e-01],\n",
      "         [ 5.0206e-02, -7.0639e-02, -2.5438e-02,  ..., -1.6414e-02,\n",
      "          -1.2939e-02,  6.0159e-03],\n",
      "         [-1.1562e-01, -1.8589e-01, -3.8972e-02,  ..., -1.7200e-02,\n",
      "           5.6876e-03,  2.6495e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.0414e-02,  1.4895e-01, -1.4810e-02,  ..., -1.8057e-02,\n",
      "           3.3794e-04,  1.8890e-01],\n",
      "         [ 4.1301e-02, -1.8103e-01, -2.6637e-02,  ..., -1.8083e-02,\n",
      "          -1.2875e-02,  1.6683e-02],\n",
      "         [-1.1449e-01, -2.2594e-01, -3.9358e-02,  ..., -1.7569e-02,\n",
      "           5.0796e-03,  3.4062e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-6.3182e-03,  1.4342e-01, -1.5586e-02,  ..., -1.8741e-02,\n",
      "           1.1904e-03,  1.9189e-01],\n",
      "         [ 5.5099e-02,  7.5813e-02, -3.0229e-02,  ..., -1.9263e-02,\n",
      "          -1.1904e-02,  1.7708e-03],\n",
      "         [-1.1137e-01, -3.3983e-01, -4.0906e-02,  ..., -2.0061e-02,\n",
      "           4.3583e-03,  2.3161e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.7055e-02,  4.8104e-01,  2.4468e-02,  ..., -1.7197e-02,\n",
      "           1.9535e-03, -4.2301e-02],\n",
      "         [ 2.3389e-02,  6.5917e-02, -2.2119e-02,  ..., -1.2191e-02,\n",
      "           1.9081e-02, -2.2556e-02],\n",
      "         [-2.7206e-03, -2.8623e-01, -2.3471e-02,  ..., -1.3366e-02,\n",
      "           3.2153e-02, -1.2053e-01],\n",
      "         ...,\n",
      "         [ 5.6722e-03, -1.6542e-01, -8.8494e-03,  ..., -1.4181e-02,\n",
      "           1.4864e-02, -2.3641e-02],\n",
      "         [-9.0027e-03, -1.2230e-01, -7.5342e-03,  ..., -1.5342e-02,\n",
      "          -2.0735e-02, -1.0257e-01],\n",
      "         [ 1.0675e-02, -8.9316e-02, -5.1581e-03,  ..., -6.4111e-03,\n",
      "          -3.5122e-02, -1.9654e-02]],\n",
      "\n",
      "        [[ 3.1671e-02,  7.0423e-01,  3.6943e-02,  ..., -2.0923e-02,\n",
      "          -2.3464e-03,  2.9439e-02],\n",
      "         [ 3.1191e-02,  8.6245e-02, -2.5052e-02,  ..., -1.4325e-02,\n",
      "           2.0909e-02,  2.0126e-02],\n",
      "         [-8.7920e-03, -4.0284e-01, -4.9344e-02,  ..., -1.8607e-02,\n",
      "           5.4421e-02, -1.3745e-01],\n",
      "         ...,\n",
      "         [ 2.4555e-04, -1.3161e-01, -1.4056e-02,  ..., -1.9027e-02,\n",
      "           2.3131e-02, -5.3348e-02],\n",
      "         [-3.8391e-03, -2.0597e-01, -1.1615e-02,  ..., -2.2025e-02,\n",
      "          -2.2146e-02, -1.5439e-01],\n",
      "         [ 1.3642e-02, -1.3533e-01, -5.5236e-03,  ..., -8.9016e-03,\n",
      "          -4.2766e-02, -3.0970e-02]],\n",
      "\n",
      "        [[ 3.9571e-02,  7.1787e-01,  3.1775e-02,  ..., -2.3038e-02,\n",
      "          -4.8818e-03,  7.9109e-02],\n",
      "         [ 2.7781e-02,  5.8767e-02, -2.5151e-02,  ..., -1.6632e-02,\n",
      "           1.4775e-02,  9.6060e-02],\n",
      "         [-8.9940e-03, -4.5629e-01, -5.6356e-02,  ..., -2.0982e-02,\n",
      "           6.4854e-02, -1.1886e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.0073e-02,  8.0861e-01,  6.9124e-02,  ..., -2.6897e-02,\n",
      "          -1.0695e-02,  1.2906e-01],\n",
      "         [ 3.2073e-02,  7.9628e-02, -3.1943e-02,  ..., -2.0082e-02,\n",
      "           2.8933e-03,  1.9065e-01],\n",
      "         [-1.2602e-02, -3.8323e-01, -7.8459e-02,  ..., -2.7492e-02,\n",
      "           7.8459e-02, -8.5008e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.3491e-02,  8.1481e-01,  7.3653e-02,  ..., -2.7817e-02,\n",
      "          -1.0862e-02, -7.4602e-02],\n",
      "         [ 3.3137e-02,  2.8591e-02, -3.2669e-02,  ..., -2.0389e-02,\n",
      "           1.2057e-03,  1.7359e-01],\n",
      "         [-1.6045e-02, -2.6173e-01, -8.4063e-02,  ..., -3.2526e-02,\n",
      "           9.2784e-02, -1.3290e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 9.1982e-02,  8.3669e-01,  7.7130e-02,  ..., -3.4501e-02,\n",
      "          -1.5951e-02, -1.4843e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 10; Percent complete: 0.9%; Average loss: 0.6938\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 4.5086e-03, -1.5586e-01, -3.9948e-03,  ..., -5.9645e-03,\n",
      "          -3.3524e-03, -1.1914e-01],\n",
      "         [-6.3522e-03,  1.3691e-01, -5.3588e-03,  ..., -3.1839e-03,\n",
      "          -3.4634e-03, -2.5645e-02],\n",
      "         [-1.0870e-02, -3.9798e-02, -6.0085e-03,  ..., -1.8850e-03,\n",
      "          -1.0055e-02,  1.4057e-02],\n",
      "         ...,\n",
      "         [ 2.8228e-02,  2.8683e-01, -1.1961e-03,  ..., -1.0295e-02,\n",
      "          -7.5832e-03,  1.0379e-01],\n",
      "         [-1.6960e-02, -1.6520e-01, -7.1462e-03,  ..., -3.7084e-03,\n",
      "           1.7604e-03, -3.8257e-02],\n",
      "         [-3.2336e-04, -3.0214e-01, -4.6599e-03,  ..., -1.4969e-02,\n",
      "           1.1794e-02,  3.2848e-02]],\n",
      "\n",
      "        [[ 1.9684e-02, -4.2789e-02, -7.4752e-03,  ..., -1.3812e-02,\n",
      "          -6.9667e-03, -9.9252e-02],\n",
      "         [ 4.9586e-03,  3.4651e-02, -8.5937e-03,  ..., -4.2024e-03,\n",
      "          -6.2904e-03, -6.9147e-02],\n",
      "         [-1.2289e-02, -6.4579e-02, -7.9327e-03,  ..., -3.7100e-03,\n",
      "          -7.9695e-03,  4.4813e-02],\n",
      "         ...,\n",
      "         [ 3.5509e-02,  2.1881e-01, -1.8383e-03,  ..., -1.2105e-02,\n",
      "          -7.8039e-03,  1.1216e-01],\n",
      "         [-4.7966e-02, -1.6051e-01, -9.0461e-03,  ..., -6.4542e-03,\n",
      "           1.0117e-03,  5.1081e-03],\n",
      "         [ 4.1829e-03, -3.4211e-01, -7.6524e-03,  ..., -1.7053e-02,\n",
      "           8.5146e-03,  1.3945e-02]],\n",
      "\n",
      "        [[ 3.8930e-02, -6.2453e-02, -2.0843e-02,  ..., -1.6984e-02,\n",
      "          -2.0402e-02, -1.2541e-01],\n",
      "         [ 1.0455e-02,  1.4162e-01, -1.0129e-02,  ..., -4.9309e-03,\n",
      "          -6.6770e-03, -1.5224e-02],\n",
      "         [-1.9053e-02, -1.1882e-01, -1.2362e-02,  ..., -6.3610e-03,\n",
      "          -8.7489e-03,  7.9289e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.1021e-02, -1.1225e-01, -4.0952e-02,  ..., -3.0783e-02,\n",
      "          -3.0018e-02,  7.9908e-02],\n",
      "         [ 1.6085e-02,  2.6265e-01, -1.4099e-02,  ..., -1.0098e-02,\n",
      "          -9.1385e-03, -5.3871e-02],\n",
      "         [-2.2505e-02, -1.9093e-01, -1.8680e-02,  ..., -1.9188e-02,\n",
      "          -7.4024e-03,  7.7771e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.7733e-02,  1.2948e-02, -4.4293e-02,  ..., -3.7637e-02,\n",
      "          -2.5771e-02, -3.6384e-02],\n",
      "         [ 1.8606e-02,  3.1303e-01, -1.4149e-02,  ..., -1.1016e-02,\n",
      "          -1.1632e-02,  3.4751e-03],\n",
      "         [-2.3394e-02, -1.4508e-01, -1.9509e-02,  ..., -1.9696e-02,\n",
      "          -7.9103e-03,  1.0311e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.7862e-02, -7.4841e-03, -4.7832e-02,  ..., -3.8805e-02,\n",
      "          -2.8314e-02,  8.0638e-03],\n",
      "         [ 1.8415e-02,  3.2884e-01, -1.5587e-02,  ..., -1.1129e-02,\n",
      "          -1.5674e-02, -2.5509e-02],\n",
      "         [-2.2442e-02, -1.7727e-01, -2.0968e-02,  ..., -1.9925e-02,\n",
      "          -8.4774e-03,  1.0715e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 10,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0018, -0.0954, -0.0048,  ..., -0.0078, -0.0101, -0.0500],\n",
      "         [ 0.0024,  0.2475, -0.0081,  ..., -0.0030, -0.0283,  0.0480],\n",
      "         [ 0.0070, -0.1606, -0.0118,  ..., -0.0049,  0.0014, -0.1109],\n",
      "         ...,\n",
      "         [ 0.0147, -0.2495,  0.0273,  ..., -0.0065, -0.0097, -0.0520],\n",
      "         [ 0.0041, -0.0059, -0.0019,  ..., -0.0030, -0.0015, -0.0758],\n",
      "         [-0.0028, -0.0788, -0.0102,  ..., -0.0030, -0.0059, -0.0321]],\n",
      "\n",
      "        [[ 0.0042, -0.1826, -0.0101,  ..., -0.0081, -0.0178,  0.0641],\n",
      "         [-0.0029,  0.2086, -0.0105,  ..., -0.0065, -0.0325,  0.0820],\n",
      "         [-0.0246, -0.0859, -0.0162,  ..., -0.0088,  0.0123, -0.1953],\n",
      "         ...,\n",
      "         [ 0.0008, -0.2148,  0.0418,  ..., -0.0105, -0.0150, -0.0728],\n",
      "         [ 0.0071, -0.0808, -0.0027,  ..., -0.0042, -0.0048, -0.1240],\n",
      "         [-0.0282,  0.0876, -0.0174,  ..., -0.0047, -0.0187, -0.0739]],\n",
      "\n",
      "        [[ 0.0107, -0.2617, -0.0131,  ..., -0.0111, -0.0296,  0.1330],\n",
      "         [-0.0411,  0.2640, -0.0139,  ..., -0.0092, -0.0368,  0.1162],\n",
      "         [-0.0239, -0.1187, -0.0167,  ..., -0.0093,  0.0114, -0.2330],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0306, -0.2987, -0.0201,  ..., -0.0326, -0.0643,  0.0441],\n",
      "         [-0.0745,  0.1804, -0.0345,  ..., -0.0179, -0.0396,  0.0600],\n",
      "         [-0.0213, -0.1901, -0.0171,  ..., -0.0104,  0.0042, -0.2682],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0340, -0.3894, -0.0212,  ..., -0.0271, -0.0874,  0.1877],\n",
      "         [-0.0713,  0.1752, -0.0347,  ..., -0.0186, -0.0419,  0.0941],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0377, -0.4287, -0.0228,  ..., -0.0276, -0.0898,  0.2016],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10, 10,  9,  8,  8,  8,  8,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,\n",
      "         3,  3,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-4.3111e-03, -9.1980e-02, -2.2530e-02,  ...,  5.8464e-04,\n",
      "          -7.3711e-03, -5.9875e-02],\n",
      "         [-1.3397e-02,  3.4450e-01, -1.5491e-02,  ..., -4.5182e-03,\n",
      "          -2.1549e-02,  2.5090e-03],\n",
      "         [ 1.1460e-03, -1.5833e-01, -2.1589e-03,  ..., -1.8193e-03,\n",
      "          -1.1878e-03, -3.8866e-02],\n",
      "         ...,\n",
      "         [ 4.5039e-05, -8.7527e-02, -1.4820e-02,  ..., -2.8899e-03,\n",
      "          -5.6495e-03,  1.0307e-02],\n",
      "         [ 2.5998e-03, -9.3491e-02, -3.7727e-02,  ..., -2.2062e-02,\n",
      "          -2.1542e-03, -1.0632e-01],\n",
      "         [ 1.5549e-03, -1.9176e-01, -1.0764e-02,  ..., -5.1183e-03,\n",
      "          -1.1689e-02, -1.7554e-02]],\n",
      "\n",
      "        [[-3.6270e-03, -9.8972e-02, -2.6587e-02,  ...,  1.0843e-02,\n",
      "          -1.1715e-02, -1.2446e-02],\n",
      "         [-1.6514e-02,  5.2349e-01, -2.0189e-02,  ..., -7.9192e-03,\n",
      "          -2.4082e-02, -1.6134e-02],\n",
      "         [ 6.3091e-03, -9.8421e-02, -3.3039e-03,  ..., -2.5182e-03,\n",
      "          -5.1913e-03, -4.7972e-02],\n",
      "         ...,\n",
      "         [-8.1073e-04, -1.2856e-01, -1.7535e-02,  ..., -5.0896e-03,\n",
      "          -6.3104e-03,  9.1780e-03],\n",
      "         [ 2.5776e-03, -1.8094e-01, -4.2424e-02,  ..., -2.3417e-02,\n",
      "          -5.5365e-03, -5.0855e-02],\n",
      "         [-2.9700e-03, -1.3412e-01, -1.1997e-02,  ..., -8.0527e-03,\n",
      "          -1.8030e-02, -1.4000e-01]],\n",
      "\n",
      "        [[-4.3719e-03, -8.8918e-02, -3.4283e-02,  ...,  1.0919e-02,\n",
      "          -1.3153e-02,  3.4067e-02],\n",
      "         [-1.1285e-02,  6.4392e-01, -2.1131e-02,  ..., -1.0962e-02,\n",
      "          -2.5639e-02,  2.9563e-02],\n",
      "         [-5.3103e-03,  1.0153e-01, -8.0817e-03,  ..., -4.1523e-03,\n",
      "          -7.8975e-03, -4.6024e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0775e-02, -6.6959e-02, -7.2946e-02,  ...,  6.0600e-02,\n",
      "          -4.8853e-03,  1.5169e-01],\n",
      "         [ 4.6625e-04,  5.3126e-01, -2.0435e-02,  ..., -1.5111e-02,\n",
      "          -4.8952e-02,  1.9702e-01],\n",
      "         [ 6.4968e-03, -8.2284e-02, -1.8090e-02,  ..., -1.0350e-02,\n",
      "          -1.8439e-02, -7.3377e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.0191e-02,  7.3046e-03, -7.4510e-02,  ...,  6.1340e-02,\n",
      "          -2.6328e-03,  1.9907e-01],\n",
      "         [-4.1517e-03,  6.1307e-01, -1.8033e-02,  ..., -1.5867e-02,\n",
      "          -5.0215e-02,  1.4309e-01],\n",
      "         [ 5.7833e-03, -8.8129e-02, -1.8382e-02,  ..., -1.0573e-02,\n",
      "          -1.9043e-02, -6.2442e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.9923e-02, -7.7981e-05, -7.8200e-02,  ...,  6.5287e-02,\n",
      "          -2.3398e-03,  2.4322e-01],\n",
      "         [ 5.0248e-03,  6.2325e-01, -1.6102e-02,  ..., -1.9082e-02,\n",
      "          -5.2188e-02,  6.0057e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0235,  0.0875, -0.0045,  ..., -0.0085, -0.0256, -0.1533],\n",
      "         [ 0.0030, -0.1583, -0.0061,  ..., -0.0038, -0.0034, -0.1208],\n",
      "         [ 0.0053,  0.0217, -0.0167,  ..., -0.0060,  0.0244, -0.0346],\n",
      "         ...,\n",
      "         [ 0.0047, -0.1605, -0.0062,  ..., -0.0167,  0.0041, -0.1271],\n",
      "         [ 0.0066, -0.1855, -0.0043,  ..., -0.0036, -0.0075, -0.0903],\n",
      "         [ 0.0020, -0.1048, -0.0030,  ..., -0.0049, -0.0024, -0.0808]],\n",
      "\n",
      "        [[ 0.0260,  0.0728, -0.0059,  ..., -0.0096, -0.0309, -0.1394],\n",
      "         [ 0.0031, -0.1794, -0.0077,  ..., -0.0049, -0.0069, -0.1628],\n",
      "         [ 0.0092,  0.1763, -0.0223,  ..., -0.0073,  0.0215,  0.0195],\n",
      "         ...,\n",
      "         [ 0.0113, -0.2063, -0.0073,  ..., -0.0139,  0.0055, -0.0312],\n",
      "         [ 0.0064, -0.1960, -0.0186,  ..., -0.0062, -0.0066, -0.1011],\n",
      "         [ 0.0026, -0.1226, -0.0040,  ..., -0.0063, -0.0027, -0.0601]],\n",
      "\n",
      "        [[ 0.0268,  0.0711, -0.0065,  ..., -0.0099, -0.0315, -0.1083],\n",
      "         [ 0.0075, -0.2319, -0.0143,  ..., -0.0067, -0.0069, -0.1799],\n",
      "         [ 0.0125,  0.1736, -0.0307,  ..., -0.0095,  0.0221,  0.0933],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0451,  0.0250, -0.0242,  ..., -0.0131, -0.0357, -0.1358],\n",
      "         [ 0.0116, -0.2200, -0.0180,  ..., -0.0108, -0.0141, -0.2795],\n",
      "         [ 0.0326,  0.0790, -0.0509,  ..., -0.0171,  0.0280,  0.1789],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0460,  0.0181, -0.0295,  ..., -0.0138, -0.0365, -0.1438],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0455,  0.0202, -0.0364,  ..., -0.0154, -0.0540, -0.1728],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 11, 11, 10,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  7,  7,  7,\n",
      "         7,  7,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,\n",
      "         3,  3,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.6035e-03,  1.1204e-01, -1.5791e-03,  ..., -2.3432e-03,\n",
      "          -2.9288e-03, -9.0704e-02],\n",
      "         [ 3.0473e-02,  8.1421e-02, -2.6941e-02,  ..., -1.5731e-02,\n",
      "           3.2273e-03, -7.4626e-02],\n",
      "         [ 3.2750e-03, -2.2951e-01, -4.0134e-03,  ..., -6.6373e-03,\n",
      "          -1.0567e-02, -1.3205e-01],\n",
      "         ...,\n",
      "         [ 5.1449e-03, -4.4398e-02, -1.8531e-03,  ..., -1.5503e-02,\n",
      "          -4.5223e-03, -5.7554e-02],\n",
      "         [ 2.2914e-03, -1.7715e-01, -7.9983e-03,  ..., -3.5422e-03,\n",
      "          -4.6375e-03, -2.1511e-02],\n",
      "         [-1.5016e-03, -1.3104e-02, -1.7259e-02,  ..., -4.8533e-03,\n",
      "          -2.1647e-03, -9.6130e-03]],\n",
      "\n",
      "        [[-5.3179e-03,  2.2393e-01, -2.8508e-03,  ..., -3.7912e-03,\n",
      "          -5.2626e-03, -4.3275e-02],\n",
      "         [ 3.2627e-02,  4.3301e-02, -2.9714e-02,  ..., -1.7331e-02,\n",
      "           3.0257e-03, -8.9092e-02],\n",
      "         [ 6.6540e-03, -2.0540e-01, -5.7369e-03,  ..., -1.0414e-02,\n",
      "          -1.3647e-02, -1.0729e-01],\n",
      "         ...,\n",
      "         [ 7.2335e-03, -1.4561e-01, -4.9381e-03,  ..., -2.2473e-02,\n",
      "          -7.8319e-03, -4.2481e-02],\n",
      "         [ 7.6309e-03, -1.1504e-01, -4.6397e-02,  ..., -9.5194e-03,\n",
      "          -9.5065e-03, -3.9992e-03],\n",
      "         [ 4.5105e-04, -1.0536e-02, -1.9483e-02,  ..., -7.0387e-03,\n",
      "          -1.7385e-03, -5.5135e-02]],\n",
      "\n",
      "        [[-3.6156e-03,  1.7796e-01, -2.2192e-03,  ..., -4.0167e-03,\n",
      "          -7.3959e-03, -2.9404e-02],\n",
      "         [ 6.7596e-02,  2.9993e-02, -4.1612e-02,  ..., -2.3109e-02,\n",
      "           3.5744e-03, -1.1769e-02],\n",
      "         [ 1.0660e-02, -2.6875e-01, -6.6709e-03,  ..., -1.6120e-02,\n",
      "          -1.3816e-04, -1.9201e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7779e-02,  3.2211e-02, -1.8991e-02,  ..., -1.0815e-02,\n",
      "          -2.1857e-02,  2.3161e-02],\n",
      "         [ 1.4537e-01,  2.5197e-01, -6.4224e-02,  ..., -5.2233e-02,\n",
      "           9.8206e-03, -1.8642e-01],\n",
      "         [ 3.8754e-02, -9.5092e-02, -1.4958e-02,  ..., -3.3955e-02,\n",
      "          -3.2270e-03,  2.7069e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.8891e-02,  1.3965e-01, -1.8668e-02,  ..., -1.1319e-02,\n",
      "          -2.4596e-02,  6.8188e-03],\n",
      "         [ 1.4127e-01,  1.4311e-01, -7.4151e-02,  ..., -6.0992e-02,\n",
      "           1.2716e-02, -1.0850e-01],\n",
      "         [ 4.0044e-02, -1.1490e-01, -1.8278e-02,  ..., -3.6234e-02,\n",
      "          -3.3405e-03,  8.1418e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.4789e-02,  1.0239e-01, -1.9976e-02,  ..., -1.1442e-02,\n",
      "          -2.6526e-02, -5.5084e-03],\n",
      "         [ 1.4377e-01, -8.6698e-02, -7.1488e-02,  ..., -6.3661e-02,\n",
      "           1.5579e-02, -1.0264e-01],\n",
      "         [ 4.0965e-02, -1.2915e-01, -2.0717e-02,  ..., -3.8206e-02,\n",
      "          -2.0054e-03,  1.3899e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([12, 64, 500])\n",
      "encoder_input_lengths:  tensor([12,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-0.0005, -0.1213, -0.0056,  ..., -0.0065, -0.0076,  0.0246],\n",
      "         [-0.0035, -0.0534, -0.0028,  ..., -0.0042, -0.0023, -0.0548],\n",
      "         [ 0.0006,  0.0670, -0.0053,  ..., -0.0033, -0.0004, -0.0325],\n",
      "         ...,\n",
      "         [ 0.0087, -0.1558, -0.0229,  ...,  0.0100,  0.0111,  0.0113],\n",
      "         [ 0.0171,  0.0350, -0.0045,  ..., -0.0040, -0.0008, -0.0415],\n",
      "         [ 0.0476,  0.0645, -0.0174,  ...,  0.0017, -0.0133, -0.0259]],\n",
      "\n",
      "        [[ 0.0012, -0.1403, -0.0071,  ..., -0.0095, -0.0083,  0.0683],\n",
      "         [-0.0008, -0.0606, -0.0064,  ..., -0.0073, -0.0050, -0.0980],\n",
      "         [-0.0118, -0.0409, -0.0084,  ..., -0.0082,  0.0037, -0.0699],\n",
      "         ...,\n",
      "         [ 0.0157, -0.2041, -0.0273,  ...,  0.0335,  0.0058, -0.0260],\n",
      "         [ 0.0249, -0.0952, -0.0054,  ..., -0.0034, -0.0134, -0.0782],\n",
      "         [ 0.0349,  0.0705, -0.0216,  ...,  0.0049,  0.0008, -0.0007]],\n",
      "\n",
      "        [[-0.0028, -0.1968, -0.0095,  ..., -0.0258, -0.0112,  0.1745],\n",
      "         [ 0.0035, -0.1881, -0.0156,  ..., -0.0067, -0.0044, -0.1522],\n",
      "         [-0.0203, -0.0668, -0.0092,  ..., -0.0112,  0.0049, -0.1149],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0020, -0.0300, -0.0371,  ..., -0.1197, -0.0338, -0.0436],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0026,  0.0150, -0.0371,  ..., -0.1282, -0.0353, -0.0146],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0018,  0.0054, -0.0374,  ..., -0.1301, -0.0357, -0.0190],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 10,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  7,  7,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-0.0078, -0.1188, -0.0021,  ..., -0.0065, -0.0004, -0.0214],\n",
      "         [-0.0032, -0.1499, -0.0028,  ..., -0.0071,  0.0075, -0.1017],\n",
      "         [-0.0120, -0.0791, -0.0274,  ..., -0.0031, -0.0092,  0.0283],\n",
      "         ...,\n",
      "         [ 0.0074, -0.1980, -0.0015,  ..., -0.0046,  0.0049, -0.0013],\n",
      "         [ 0.0099, -0.1338, -0.0088,  ..., -0.0128, -0.0037, -0.0267],\n",
      "         [-0.0100,  0.0668, -0.0028,  ..., -0.0094, -0.0058, -0.0636]],\n",
      "\n",
      "        [[-0.0175,  0.1614, -0.0038,  ..., -0.0087, -0.0029, -0.0507],\n",
      "         [ 0.0041, -0.1712, -0.0032,  ..., -0.0106,  0.0096, -0.0615],\n",
      "         [-0.0066, -0.0654, -0.0283,  ..., -0.0075, -0.0149,  0.0459],\n",
      "         ...,\n",
      "         [ 0.0093, -0.1600, -0.0043,  ..., -0.0099,  0.0062,  0.0693],\n",
      "         [ 0.0133, -0.1391, -0.0122,  ..., -0.0271, -0.0187,  0.0860],\n",
      "         [ 0.0096,  0.0254, -0.0033,  ..., -0.0126, -0.0009, -0.0618]],\n",
      "\n",
      "        [[-0.0080,  0.1646, -0.0055,  ..., -0.0100, -0.0036, -0.0336],\n",
      "         [ 0.0011,  0.0494, -0.0037,  ..., -0.0306,  0.0146, -0.1206],\n",
      "         [-0.0053, -0.0854, -0.0292,  ..., -0.0089, -0.0173,  0.0581],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0013,  0.0815, -0.0456,  ..., -0.0192, -0.0106,  0.0742],\n",
      "         [ 0.0043,  0.0872, -0.0073,  ..., -0.0404,  0.0030,  0.0234],\n",
      "         [ 0.0045, -0.1027, -0.0358,  ..., -0.0156, -0.0390,  0.0510],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0091,  0.1946, -0.0498,  ..., -0.0213, -0.0109,  0.0571],\n",
      "         [ 0.0046,  0.0582, -0.0084,  ..., -0.0448,  0.0002,  0.0435],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0089,  0.1596, -0.0504,  ..., -0.0218, -0.0114,  0.0547],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,\n",
      "         3,  3,  3,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-3.9861e-03,  5.7750e-02, -2.7953e-03,  ...,  7.8307e-04,\n",
      "          -1.2091e-02, -4.5569e-04],\n",
      "         [ 2.2003e-03, -5.8473e-03, -3.1539e-03,  ..., -3.9993e-03,\n",
      "          -1.8210e-03, -4.7017e-02],\n",
      "         [-2.9643e-03,  5.2437e-03, -4.7720e-03,  ..., -7.0878e-03,\n",
      "           2.8550e-02, -5.1380e-02],\n",
      "         ...,\n",
      "         [-4.9707e-03, -2.0866e-01, -6.6490e-03,  ..., -4.3044e-02,\n",
      "           1.3655e-04, -1.3712e-01],\n",
      "         [ 2.6344e-03, -7.6125e-02, -4.5559e-03,  ..., -2.9777e-03,\n",
      "          -3.1487e-03, -3.2624e-02],\n",
      "         [ 5.6332e-03,  8.2521e-02, -8.3412e-03,  ..., -7.6311e-03,\n",
      "           1.3372e-03, -7.3412e-02]],\n",
      "\n",
      "        [[-1.4624e-02,  6.9038e-02, -5.7003e-03,  ...,  1.2369e-03,\n",
      "          -2.1825e-02,  2.3268e-02],\n",
      "         [-9.2323e-03,  2.6781e-01, -3.8891e-03,  ..., -5.4974e-03,\n",
      "          -6.7831e-03, -9.8912e-04],\n",
      "         [-4.0127e-03, -5.5840e-02, -5.7967e-03,  ..., -8.0968e-03,\n",
      "           2.7084e-02, -6.4787e-02],\n",
      "         ...,\n",
      "         [-1.0833e-02, -2.8533e-01, -1.9958e-02,  ..., -3.8813e-02,\n",
      "           5.8462e-03, -1.5164e-01],\n",
      "         [ 2.1915e-03, -4.2935e-02, -5.6771e-03,  ..., -3.6627e-03,\n",
      "          -5.2843e-03, -4.7554e-02],\n",
      "         [ 8.3248e-03,  5.8031e-02, -1.2921e-02,  ..., -1.0840e-02,\n",
      "          -2.2412e-03, -1.1511e-01]],\n",
      "\n",
      "        [[-1.6804e-02, -2.5752e-02, -8.8878e-03,  ..., -4.1742e-04,\n",
      "          -2.9621e-02, -3.4104e-03],\n",
      "         [-1.4318e-02,  3.8915e-01, -5.4554e-03,  ..., -6.6055e-03,\n",
      "          -5.9481e-03, -2.4921e-02],\n",
      "         [ 4.9095e-02,  3.7212e-02, -9.6693e-03,  ..., -1.1040e-02,\n",
      "           3.2799e-02, -8.4771e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7981e-02, -5.1025e-02, -2.2080e-02,  ..., -1.5286e-02,\n",
      "          -3.3686e-02,  9.7015e-02],\n",
      "         [ 4.1853e-03,  4.2520e-01, -1.0959e-02,  ..., -8.8674e-03,\n",
      "          -2.9057e-02, -5.5274e-02],\n",
      "         [ 1.2673e-01,  1.0877e-01, -1.5031e-02,  ..., -2.1743e-02,\n",
      "           2.7442e-02, -8.0206e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.4869e-02, -6.9725e-02, -2.3760e-02,  ..., -1.7820e-02,\n",
      "          -3.7716e-02,  5.6884e-02],\n",
      "         [ 5.8865e-03,  3.6339e-01, -1.1402e-02,  ..., -9.3275e-03,\n",
      "          -3.0211e-02, -5.8885e-02],\n",
      "         [ 1.5146e-01,  1.6100e-01, -1.5705e-02,  ..., -2.2731e-02,\n",
      "           3.5191e-02, -7.8619e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-9.9578e-03, -9.4847e-02, -2.4359e-02,  ..., -1.9736e-02,\n",
      "          -4.4951e-02,  1.2890e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([8, 64, 500])\n",
      "encoder_input_lengths:  tensor([8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0149,  0.0079, -0.0060,  ...,  0.0011, -0.0296, -0.0067],\n",
      "         [-0.0216, -0.0298, -0.0030,  ..., -0.0020, -0.0034, -0.1228],\n",
      "         [ 0.0108,  0.1376, -0.0038,  ..., -0.0381, -0.0035, -0.1210],\n",
      "         ...,\n",
      "         [ 0.0015, -0.1288, -0.0138,  ..., -0.0104,  0.0012, -0.0268],\n",
      "         [ 0.0022, -0.0980, -0.0079,  ..., -0.0139, -0.0083, -0.0826],\n",
      "         [ 0.0217,  0.0562, -0.0068,  ..., -0.0019, -0.0064, -0.0256]],\n",
      "\n",
      "        [[ 0.0279,  0.0145, -0.0084,  ...,  0.0014, -0.0555,  0.0510],\n",
      "         [-0.0194, -0.0212, -0.0056,  ..., -0.0028, -0.0051, -0.0198],\n",
      "         [ 0.0122,  0.1510, -0.0043,  ..., -0.0498, -0.0035, -0.1386],\n",
      "         ...,\n",
      "         [ 0.0027, -0.1467, -0.0157,  ..., -0.0144,  0.0006, -0.0077],\n",
      "         [ 0.0046, -0.1706, -0.0100,  ..., -0.0104, -0.0178, -0.0041],\n",
      "         [ 0.0237,  0.0032, -0.0113,  ..., -0.0027, -0.0102,  0.0019]],\n",
      "\n",
      "        [[ 0.0270, -0.0201, -0.0095,  ...,  0.0010, -0.0582, -0.0208],\n",
      "         [-0.0190, -0.0224, -0.0078,  ..., -0.0031, -0.0058, -0.0287],\n",
      "         [ 0.0159,  0.1861, -0.0052,  ..., -0.0529, -0.0048, -0.1195],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0030,  0.0319, -0.0106,  ..., -0.0075, -0.0628, -0.0185],\n",
      "         [-0.0073, -0.0166, -0.0073,  ..., -0.0043, -0.0090, -0.1568],\n",
      "         [ 0.0106,  0.2018, -0.0069,  ..., -0.0692, -0.0055,  0.0147],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0028,  0.0597, -0.0111,  ..., -0.0082, -0.0639, -0.0675],\n",
      "         [-0.0058, -0.0818, -0.0098,  ..., -0.0051, -0.0135, -0.0772],\n",
      "         [ 0.0215,  0.1290, -0.0093,  ..., -0.0652, -0.0064,  0.0299],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0083,  0.0559, -0.0115,  ..., -0.0092, -0.0640, -0.0555],\n",
      "         [-0.0055, -0.0796, -0.0115,  ..., -0.0056, -0.0163,  0.0183],\n",
      "         [ 0.0218,  0.0908, -0.0109,  ..., -0.0666, -0.0090,  0.0044],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.0256e-02, -2.2693e-01, -3.3207e-02,  ..., -3.5846e-02,\n",
      "           3.4991e-02, -1.1391e-01],\n",
      "         [ 6.7355e-03, -3.6129e-03, -2.8695e-03,  ..., -1.9212e-03,\n",
      "          -3.5082e-03, -1.5036e-01],\n",
      "         [ 1.2231e-02, -3.3307e-02, -7.9484e-03,  ..., -4.1564e-03,\n",
      "          -5.0875e-03, -8.0747e-02],\n",
      "         ...,\n",
      "         [-3.8956e-03, -1.0400e-01,  6.6509e-03,  ..., -7.9134e-03,\n",
      "          -1.0802e-02, -3.2653e-02],\n",
      "         [-2.4403e-02, -8.0708e-02, -6.0746e-03,  ..., -3.2205e-03,\n",
      "          -7.1115e-03, -3.3278e-02],\n",
      "         [-4.6267e-02,  1.1440e-01, -7.0176e-03,  ..., -2.3696e-02,\n",
      "          -1.5729e-03,  7.8242e-03]],\n",
      "\n",
      "        [[ 5.1094e-03, -1.4190e-01, -4.6140e-02,  ..., -3.9649e-02,\n",
      "           2.2360e-02, -1.0464e-01],\n",
      "         [ 8.5906e-03, -5.0267e-02, -4.7252e-03,  ..., -2.2554e-03,\n",
      "          -1.4182e-02, -9.4231e-02],\n",
      "         [ 6.1014e-03,  7.9393e-02, -9.4674e-03,  ...,  8.0295e-04,\n",
      "          -6.0201e-03, -5.8785e-02],\n",
      "         ...,\n",
      "         [-1.1500e-02, -7.5813e-02,  5.7247e-03,  ..., -1.2840e-02,\n",
      "          -1.3268e-02, -5.4160e-02],\n",
      "         [-2.1360e-02, -8.2350e-02, -8.4371e-03,  ..., -4.5734e-03,\n",
      "          -9.2489e-03,  1.8634e-02],\n",
      "         [-2.2881e-01,  3.6055e-01, -9.2982e-03,  ..., -2.9931e-02,\n",
      "          -7.4493e-03,  1.1781e-01]],\n",
      "\n",
      "        [[ 7.0517e-03, -5.0540e-02, -4.6569e-02,  ..., -4.0505e-02,\n",
      "           2.1337e-02, -2.3823e-02],\n",
      "         [ 8.5872e-03,  3.5805e-02, -7.0452e-03,  ..., -2.7759e-03,\n",
      "          -2.4733e-02, -2.7053e-02],\n",
      "         [ 7.2167e-03,  8.1281e-02, -1.0208e-02,  ..., -6.4109e-03,\n",
      "          -7.4317e-03, -6.0135e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1658e-02, -7.0059e-02, -4.7086e-02,  ..., -4.3650e-02,\n",
      "           2.6482e-02, -1.0839e-01],\n",
      "         [ 9.2287e-03,  5.9073e-02, -1.1577e-02,  ..., -4.0182e-03,\n",
      "          -3.0068e-02, -2.7762e-01],\n",
      "         [-1.2704e-03,  2.4452e-01, -1.3101e-02,  ..., -6.3456e-02,\n",
      "          -9.2308e-03, -2.5737e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.7855e-02,  1.4401e-01, -5.1045e-02,  ..., -4.4101e-02,\n",
      "           2.7391e-02, -1.6634e-02],\n",
      "         [ 8.1674e-03,  7.6419e-02, -1.3541e-02,  ..., -4.6451e-03,\n",
      "          -3.6904e-02, -1.3132e-01],\n",
      "         [ 1.9091e-04,  2.9893e-01, -1.4258e-02,  ..., -7.0133e-02,\n",
      "          -9.2663e-03, -2.0353e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5900e-02,  1.6259e-02, -6.4031e-02,  ..., -4.5901e-02,\n",
      "           2.9522e-02,  1.5875e-02],\n",
      "         [ 8.4585e-03,  9.6527e-02, -1.4650e-02,  ..., -5.6693e-03,\n",
      "          -3.7705e-02, -1.6956e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 20; Percent complete: 1.7%; Average loss: 0.6923\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11,  9,  9,  9,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  3,  3,  3,  3,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 3.1672e-02, -2.3706e-01,  1.1890e-02,  ..., -1.1373e-02,\n",
      "          -2.4901e-06, -5.2210e-02],\n",
      "         [ 8.9213e-03,  5.2796e-02,  1.8289e-03,  ..., -4.8852e-03,\n",
      "          -3.6943e-03, -1.7822e-01],\n",
      "         [-1.5563e-03, -1.4506e-01, -4.7154e-03,  ..., -4.8525e-03,\n",
      "          -2.2490e-02,  8.2656e-03],\n",
      "         ...,\n",
      "         [ 4.1876e-03, -5.7352e-02, -3.0294e-03,  ..., -4.1873e-03,\n",
      "          -2.1043e-03, -5.7468e-02],\n",
      "         [-1.6961e-02,  2.7732e-01, -3.1727e-03,  ..., -4.0543e-03,\n",
      "          -1.9447e-03, -3.8165e-02],\n",
      "         [ 4.1162e-03, -1.3961e-01, -1.3298e-03,  ..., -7.6111e-03,\n",
      "          -3.5992e-03, -8.2979e-02]],\n",
      "\n",
      "        [[ 3.1942e-02, -2.1124e-01,  7.8258e-03,  ..., -1.2199e-02,\n",
      "          -6.2157e-03, -2.3638e-02],\n",
      "         [ 1.3666e-02, -3.8169e-02, -3.5828e-05,  ..., -6.6982e-03,\n",
      "          -4.7113e-03, -1.8444e-01],\n",
      "         [-1.4287e-02, -5.2396e-02, -7.3815e-03,  ..., -5.7264e-03,\n",
      "          -3.1922e-02,  9.8018e-03],\n",
      "         ...,\n",
      "         [ 1.0130e-02, -9.0294e-02, -6.4550e-03,  ..., -9.2699e-03,\n",
      "          -6.9319e-03, -9.6623e-02],\n",
      "         [-3.1139e-02,  2.3392e-01, -9.3965e-03,  ..., -1.1266e-02,\n",
      "          -2.0208e-04, -6.7389e-02],\n",
      "         [ 4.0964e-02,  1.8612e-01, -6.3680e-03,  ..., -1.4174e-02,\n",
      "          -2.6626e-02, -1.5497e-01]],\n",
      "\n",
      "        [[ 3.0436e-02, -2.0906e-01,  6.2411e-03,  ..., -1.2711e-02,\n",
      "          -8.7282e-03, -1.1892e-02],\n",
      "         [ 1.1111e-02, -1.3553e-01, -6.9959e-03,  ..., -9.4198e-03,\n",
      "          -9.0013e-03, -1.3601e-01],\n",
      "         [-1.1648e-02, -1.1898e-01, -9.7535e-03,  ..., -6.7449e-03,\n",
      "          -3.8954e-02,  3.4941e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.1767e-02, -1.9773e-01,  6.0167e-03,  ..., -1.8102e-02,\n",
      "          -2.5636e-02,  5.7260e-02],\n",
      "         [ 2.4066e-03, -7.1970e-02, -1.7227e-02,  ..., -1.9420e-02,\n",
      "          -1.2225e-02, -7.7223e-02],\n",
      "         [-4.5858e-02,  4.6568e-01, -1.9337e-02,  ..., -8.6590e-03,\n",
      "          -4.9256e-02,  2.3130e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.1678e-02, -1.8202e-01,  5.6282e-03,  ..., -1.8801e-02,\n",
      "          -2.5809e-02,  4.8138e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.0734e-02, -2.1855e-01,  5.1995e-03,  ..., -1.9589e-02,\n",
      "          -2.6171e-02,  1.3768e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 4.5538e-04, -4.1811e-02,  3.4345e-04,  ..., -5.8127e-03,\n",
      "          -6.7364e-03, -1.1155e-01],\n",
      "         [-4.4571e-03, -6.3598e-02, -2.6917e-03,  ..., -5.8779e-03,\n",
      "          -4.2737e-03, -1.5117e-02],\n",
      "         [ 7.6253e-03,  1.1220e-01,  1.3228e-03,  ..., -5.7429e-03,\n",
      "           2.0458e-03, -3.2610e-02],\n",
      "         ...,\n",
      "         [ 2.6054e-03,  2.2588e-02, -7.1708e-03,  ..., -4.1535e-03,\n",
      "           2.0613e-02, -5.5027e-02],\n",
      "         [ 2.3530e-03, -1.4965e-01, -5.7629e-03,  ..., -2.2976e-03,\n",
      "          -5.8877e-03, -3.4125e-02],\n",
      "         [ 1.0652e-02, -1.2574e-01,  2.1416e-03,  ...,  4.4122e-03,\n",
      "          -9.7064e-03, -5.3065e-02]],\n",
      "\n",
      "        [[ 1.1828e-03, -5.4956e-02, -1.2007e-03,  ..., -8.8119e-03,\n",
      "          -9.7049e-03, -1.2026e-01],\n",
      "         [-1.2612e-02, -3.2765e-02, -3.8689e-03,  ..., -1.4278e-02,\n",
      "          -3.8881e-03,  2.1819e-02],\n",
      "         [ 1.8422e-02,  2.3301e-01,  8.0663e-04,  ..., -8.3036e-03,\n",
      "           2.5544e-04, -7.2276e-02],\n",
      "         ...,\n",
      "         [ 3.2929e-03,  3.5059e-01, -1.2075e-02,  ..., -5.8092e-03,\n",
      "           2.5750e-02, -3.9371e-02],\n",
      "         [ 4.9049e-03, -1.3881e-01, -6.4611e-03,  ..., -5.0571e-03,\n",
      "          -6.5893e-03,  2.4947e-02],\n",
      "         [ 1.2224e-02, -9.2797e-02,  9.8810e-04,  ...,  6.2474e-04,\n",
      "          -9.0489e-03,  2.0399e-02]],\n",
      "\n",
      "        [[ 2.5654e-03, -1.0647e-01, -3.2145e-03,  ..., -9.4318e-03,\n",
      "          -1.1128e-02, -1.4344e-01],\n",
      "         [-1.5678e-02, -5.8922e-02, -5.1646e-03,  ..., -1.6879e-02,\n",
      "          -4.6714e-03,  4.7770e-02],\n",
      "         [ 3.4886e-02,  2.9134e-01,  2.4372e-04,  ..., -9.5774e-03,\n",
      "           8.4657e-05,  3.4138e-02],\n",
      "         ...,\n",
      "         [ 4.0242e-03,  4.0084e-01, -1.6957e-02,  ..., -7.2004e-03,\n",
      "           2.8693e-02,  2.7124e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.0944e-03, -2.8801e-01, -1.2929e-02,  ..., -1.4083e-02,\n",
      "          -1.1603e-02,  3.9839e-02],\n",
      "         [-4.1115e-02,  5.5208e-02, -9.1269e-03,  ..., -2.6849e-02,\n",
      "          -4.1518e-03,  1.3720e-01],\n",
      "         [ 5.2605e-02,  1.8559e-01, -2.1646e-03,  ..., -1.3988e-02,\n",
      "          -9.8154e-04,  7.4857e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.0964e-03, -1.1129e-01, -1.4082e-02,  ..., -1.4944e-02,\n",
      "          -1.2967e-02,  1.3365e-02],\n",
      "         [-4.4561e-02,  2.4803e-02, -9.3668e-03,  ..., -2.7817e-02,\n",
      "          -4.4050e-03,  1.4237e-01],\n",
      "         [ 5.3032e-02,  1.6892e-01, -2.5884e-03,  ..., -1.4374e-02,\n",
      "          -1.0602e-03,  9.5702e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.7214e-02, -3.4193e-03, -1.8948e-02,  ..., -1.6093e-02,\n",
      "          -2.2093e-02,  2.8291e-02],\n",
      "         [-4.3180e-02,  2.3052e-02, -9.5607e-03,  ..., -2.8125e-02,\n",
      "          -4.8158e-03,  1.4333e-01],\n",
      "         [ 5.8436e-02,  2.3024e-01, -4.5933e-03,  ..., -1.7249e-02,\n",
      "          -2.1372e-03, -2.4761e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  3,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-1.1487e-03, -1.4297e-01, -6.5050e-04,  ..., -5.1934e-03,\n",
      "          -3.1522e-03, -4.6143e-02],\n",
      "         [-3.6906e-02,  1.3175e-01, -6.3236e-03,  ..., -1.1670e-02,\n",
      "           1.7528e-02, -6.5519e-02],\n",
      "         [ 1.1224e-03, -1.1888e-01, -2.9345e-03,  ..., -6.3623e-03,\n",
      "          -5.1290e-03, -3.2869e-02],\n",
      "         ...,\n",
      "         [ 1.9635e-02, -1.0452e-01, -1.3945e-02,  ..., -7.0801e-03,\n",
      "          -5.4196e-02,  1.9713e-02],\n",
      "         [-5.9657e-03, -1.7043e-01, -9.5679e-03,  ..., -1.5405e-02,\n",
      "          -9.0466e-04, -7.2436e-02],\n",
      "         [-1.0580e-02,  2.9529e-01, -5.4912e-03,  ..., -1.0965e-02,\n",
      "           8.7375e-03, -2.9562e-02]],\n",
      "\n",
      "        [[-1.4074e-03, -1.6960e-01, -4.4792e-03,  ..., -8.3024e-03,\n",
      "          -2.5654e-03, -4.3085e-02],\n",
      "         [-3.1484e-02,  1.3998e-01, -7.4132e-03,  ..., -1.2984e-02,\n",
      "           1.7935e-02, -8.1162e-02],\n",
      "         [ 9.0137e-03, -1.2923e-01, -8.6367e-03,  ..., -9.6313e-03,\n",
      "          -1.0114e-02, -9.9125e-02],\n",
      "         ...,\n",
      "         [ 1.2520e-01,  3.3243e-02, -1.9132e-02,  ..., -1.1047e-02,\n",
      "          -5.8735e-02,  7.3592e-02],\n",
      "         [-7.2111e-03, -1.3888e-01, -1.4113e-02,  ..., -1.9185e-02,\n",
      "           1.6829e-05, -3.7803e-02],\n",
      "         [ 8.5604e-03,  2.0546e-01, -8.9474e-03,  ..., -2.2431e-02,\n",
      "           1.4059e-02,  3.6301e-02]],\n",
      "\n",
      "        [[-6.7436e-03, -5.3244e-02, -5.7391e-03,  ..., -9.0546e-03,\n",
      "          -4.5365e-03, -1.3686e-02],\n",
      "         [-2.9105e-02,  7.6994e-02, -8.1062e-03,  ..., -1.4294e-02,\n",
      "           2.2547e-02, -7.3459e-02],\n",
      "         [ 7.2232e-03, -1.9494e-01, -1.2277e-02,  ..., -1.6462e-02,\n",
      "          -1.1854e-02, -1.0409e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.2254e-05, -4.3312e-02, -1.4741e-02,  ..., -1.6591e-02,\n",
      "          -7.7754e-03,  3.9032e-02],\n",
      "         [ 3.0513e-03,  1.5165e-01, -1.5741e-02,  ..., -1.8811e-02,\n",
      "           2.6211e-02,  9.0321e-02],\n",
      "         [ 2.1251e-02, -1.0335e-01, -2.2019e-02,  ..., -2.0990e-02,\n",
      "          -3.0174e-02,  2.8014e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.6773e-06, -7.5330e-02, -1.4260e-02,  ..., -1.7016e-02,\n",
      "          -9.0678e-03, -8.3934e-03],\n",
      "         [ 5.8490e-03,  1.1177e-01, -1.5197e-02,  ..., -2.0538e-02,\n",
      "           2.5462e-02,  6.4444e-02],\n",
      "         [ 2.4043e-02, -4.1298e-02, -2.3480e-02,  ..., -2.4486e-02,\n",
      "          -3.0218e-02,  5.8410e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.0545e-03, -9.7971e-02, -1.6051e-02,  ..., -1.9205e-02,\n",
      "          -1.1392e-02, -3.9705e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10, 10, 10,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  6,\n",
      "         6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.9735e-03, -8.7505e-03, -6.3566e-03,  ..., -6.1370e-03,\n",
      "           2.0774e-03,  4.4027e-02],\n",
      "         [ 2.1049e-03,  3.0892e-01, -6.2473e-03,  ..., -1.5207e-02,\n",
      "          -2.0801e-02,  3.8840e-02],\n",
      "         [-2.8861e-03, -2.1161e-01, -1.0073e-02,  ..., -1.9222e-03,\n",
      "          -3.8848e-04, -3.6540e-02],\n",
      "         ...,\n",
      "         [ 1.4275e-02,  1.7776e-01, -3.4931e-03,  ..., -1.2039e-02,\n",
      "           1.0102e-02, -7.1675e-02],\n",
      "         [-1.0704e-02, -1.7793e-01, -7.6000e-03,  ..., -4.9240e-03,\n",
      "          -1.0238e-02,  1.7149e-02],\n",
      "         [-2.2162e-03, -1.1994e-01, -1.7124e-03,  ..., -1.4784e-02,\n",
      "          -5.2634e-03,  1.9487e-02]],\n",
      "\n",
      "        [[ 1.5267e-02, -1.2395e-01, -1.0395e-02,  ..., -1.1353e-02,\n",
      "           6.6798e-03, -2.8285e-02],\n",
      "         [-2.4273e-03,  4.6949e-01, -6.8736e-03,  ..., -1.7171e-02,\n",
      "          -2.5483e-02,  1.5629e-01],\n",
      "         [-2.8109e-03, -2.3787e-01, -1.3525e-02,  ..., -2.9938e-03,\n",
      "          -8.4894e-03, -7.5709e-03],\n",
      "         ...,\n",
      "         [ 2.4218e-02,  1.6868e-01, -6.3738e-03,  ..., -1.4988e-02,\n",
      "           1.2476e-02, -1.0036e-01],\n",
      "         [-7.2858e-03, -1.4942e-01, -1.1833e-02,  ..., -3.8047e-03,\n",
      "          -2.4400e-02,  2.3017e-02],\n",
      "         [-4.4307e-03, -1.4917e-01, -3.8628e-03,  ..., -2.0374e-02,\n",
      "          -6.2217e-03,  3.2835e-02]],\n",
      "\n",
      "        [[ 5.6060e-02, -1.8218e-01, -1.2536e-02,  ..., -1.5232e-02,\n",
      "           1.2585e-02, -2.5536e-03],\n",
      "         [-3.5189e-03,  4.6583e-01, -7.6427e-03,  ..., -1.9668e-02,\n",
      "          -3.1266e-02,  2.8642e-01],\n",
      "         [ 3.3202e-04, -1.9588e-01, -1.2153e-02,  ..., -2.7581e-03,\n",
      "          -9.4941e-03,  9.9083e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.9181e-02,  3.0741e-01, -1.8790e-02,  ..., -2.0577e-02,\n",
      "           2.6628e-02, -1.1797e-02],\n",
      "         [-9.3466e-03,  4.5420e-01, -1.4175e-02,  ..., -2.2358e-02,\n",
      "          -4.3164e-02,  2.3312e-01],\n",
      "         [ 2.6349e-02, -2.1145e-01, -5.9321e-02,  ..., -5.7681e-03,\n",
      "          -4.7221e-02,  9.7513e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 6.1689e-02,  4.1765e-01, -1.9861e-02,  ..., -2.3228e-02,\n",
      "           2.6227e-02,  3.9562e-02],\n",
      "         [-4.2245e-03,  6.5873e-01, -1.5143e-02,  ..., -2.2504e-02,\n",
      "          -5.3681e-02,  2.5481e-01],\n",
      "         [ 1.4512e-02, -2.4251e-01, -6.3127e-02,  ..., -6.2374e-03,\n",
      "          -6.3575e-02,  5.2250e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.9663e-02,  4.9299e-01, -2.0868e-02,  ..., -2.6273e-02,\n",
      "           2.8355e-02,  6.4486e-02],\n",
      "         [-3.3765e-03,  4.9050e-01, -1.6646e-02,  ..., -2.5941e-02,\n",
      "          -5.8105e-02,  1.5565e-01],\n",
      "         [ 4.0685e-03, -2.6645e-01, -6.4735e-02,  ..., -6.4347e-03,\n",
      "          -7.3397e-02,  4.9033e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11,  9,  9,  8,  8,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-1.4937e-02,  2.3379e-01, -2.6054e-03,  ..., -4.1895e-03,\n",
      "          -6.8553e-03, -5.9378e-02],\n",
      "         [ 5.1399e-03, -1.1293e-01, -4.6043e-03,  ..., -5.4113e-03,\n",
      "          -1.4665e-02, -3.1697e-02],\n",
      "         [-9.9333e-03,  3.5041e-01, -1.9135e-02,  ..., -6.1211e-03,\n",
      "          -1.2686e-02, -1.0590e-02],\n",
      "         ...,\n",
      "         [-1.0854e-04, -9.2933e-02, -4.3822e-03,  ..., -6.0676e-03,\n",
      "          -1.8605e-04, -7.5198e-02],\n",
      "         [-5.0451e-03, -1.8928e-01, -4.9256e-03,  ..., -1.1639e-03,\n",
      "          -5.1901e-03, -5.5168e-02],\n",
      "         [ 5.4670e-03, -1.1738e-01, -1.6443e-02,  ..., -1.4534e-03,\n",
      "           7.3700e-03,  1.3570e-02]],\n",
      "\n",
      "        [[-4.4109e-02,  1.5987e-01, -5.0372e-03,  ..., -7.1332e-03,\n",
      "          -8.4870e-03, -3.5508e-02],\n",
      "         [-3.2679e-03, -1.7014e-01, -1.0317e-02,  ..., -7.7676e-03,\n",
      "          -2.5792e-02, -1.1151e-02],\n",
      "         [-1.4947e-02,  6.1748e-01, -2.7492e-02,  ..., -1.0659e-02,\n",
      "          -2.3526e-02,  2.3475e-02],\n",
      "         ...,\n",
      "         [ 1.9465e-04, -1.6448e-01, -6.0765e-03,  ..., -8.7689e-03,\n",
      "          -4.1528e-03, -1.9351e-02],\n",
      "         [-3.0866e-03,  1.3523e-01, -5.9643e-03,  ..., -2.7738e-03,\n",
      "          -8.6028e-03, -7.6068e-02],\n",
      "         [ 6.5050e-03, -1.7870e-01, -2.5455e-02,  ..., -4.8205e-03,\n",
      "           7.8188e-03,  5.3172e-02]],\n",
      "\n",
      "        [[-4.1287e-02,  1.3803e-01, -7.5493e-03,  ..., -8.3643e-03,\n",
      "          -9.5245e-03, -2.1169e-02],\n",
      "         [-4.7452e-03, -1.6612e-01, -1.4046e-02,  ..., -7.4088e-03,\n",
      "          -2.7527e-02, -6.8023e-03],\n",
      "         [ 1.3312e-02,  5.3027e-01, -4.0245e-02,  ..., -1.2665e-02,\n",
      "          -2.5688e-02,  3.2470e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7709e-02,  2.5575e-02, -2.5360e-02,  ..., -1.4871e-02,\n",
      "          -1.7237e-02,  4.4194e-02],\n",
      "         [-2.2457e-03, -3.0207e-01, -4.2873e-02,  ..., -1.0711e-02,\n",
      "          -5.2041e-02,  7.1980e-02],\n",
      "         [-7.6068e-02,  5.7967e-01, -4.7307e-02,  ..., -2.9207e-02,\n",
      "          -3.5082e-02, -1.4397e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.6039e-02, -4.1706e-02, -2.6520e-02,  ..., -1.5711e-02,\n",
      "          -1.7606e-02,  7.2080e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.6178e-02, -4.6894e-03, -2.7847e-02,  ..., -1.5930e-02,\n",
      "          -1.9241e-02,  7.5057e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,\n",
      "         3,  3,  3,  3,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 9.2495e-03, -1.7317e-01,  2.1793e-03,  ..., -7.7125e-03,\n",
      "          -9.7074e-03, -5.0841e-02],\n",
      "         [ 1.3335e-02, -3.2373e-02, -3.6500e-03,  ..., -2.2462e-03,\n",
      "          -5.9641e-03, -2.3462e-02],\n",
      "         [-3.7664e-03,  7.0220e-02, -1.3683e-02,  ..., -1.1183e-02,\n",
      "          -3.1825e-03, -8.4700e-02],\n",
      "         ...,\n",
      "         [-3.5582e-03, -1.3357e-01, -7.8480e-03,  ..., -8.0890e-03,\n",
      "          -4.4599e-03, -2.0533e-02],\n",
      "         [-1.5576e-02,  4.0793e-01, -1.5248e-03,  ..., -1.1690e-02,\n",
      "          -7.8866e-03, -3.4772e-02],\n",
      "         [-1.7291e-02, -1.4701e-01, -1.9772e-02,  ..., -7.4951e-03,\n",
      "          -1.0248e-02, -6.0935e-02]],\n",
      "\n",
      "        [[ 8.6908e-03, -2.6759e-01, -1.0204e-03,  ..., -9.9940e-03,\n",
      "          -9.6595e-03, -3.0268e-02],\n",
      "         [ 1.5343e-02, -8.6120e-02, -5.0284e-03,  ..., -3.9214e-03,\n",
      "          -1.0416e-02, -4.4811e-03],\n",
      "         [ 1.8016e-04, -2.1842e-02, -1.7743e-02,  ..., -1.1799e-02,\n",
      "          -6.1163e-03, -3.7306e-02],\n",
      "         ...,\n",
      "         [-9.8954e-03, -2.4363e-01, -1.1672e-02,  ..., -1.3387e-02,\n",
      "          -3.7634e-03, -9.9297e-03],\n",
      "         [ 4.7339e-02,  6.1741e-01, -5.1712e-03,  ..., -1.5361e-02,\n",
      "          -1.5906e-02, -2.1551e-02],\n",
      "         [-2.4074e-02, -1.5325e-01, -2.9764e-02,  ..., -8.7659e-03,\n",
      "          -1.3106e-02, -3.0884e-02]],\n",
      "\n",
      "        [[-1.0071e-02, -4.2493e-01, -8.5394e-03,  ..., -9.7703e-03,\n",
      "          -9.5337e-03, -6.7730e-02],\n",
      "         [ 1.8992e-02, -1.2105e-01, -9.1723e-03,  ..., -7.6183e-03,\n",
      "          -2.2118e-02, -2.4664e-02],\n",
      "         [-1.9852e-04, -1.3612e-01, -2.1658e-02,  ..., -1.4878e-02,\n",
      "          -8.7102e-03, -2.9228e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8617e-02, -2.9275e-01, -2.4458e-02,  ..., -1.3538e-02,\n",
      "          -1.0918e-02,  1.6137e-02],\n",
      "         [ 3.6758e-02, -9.1473e-03, -8.6876e-03,  ..., -3.6608e-02,\n",
      "          -3.3025e-02, -3.5159e-02],\n",
      "         [-5.0715e-03, -9.0780e-02, -3.4007e-02,  ..., -1.9370e-02,\n",
      "          -1.9745e-02, -8.7851e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-6.6953e-02, -3.6959e-01, -2.5060e-02,  ..., -1.4998e-02,\n",
      "          -1.1057e-02,  1.2226e-01],\n",
      "         [ 3.6567e-02, -2.6876e-03, -8.3541e-03,  ..., -3.7011e-02,\n",
      "          -3.5973e-02,  6.5258e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-7.1613e-02, -2.1887e-01, -2.5971e-02,  ..., -1.5619e-02,\n",
      "          -1.0666e-02,  3.2836e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-0.0244,  0.0584, -0.0119,  ..., -0.0024, -0.0005, -0.0024],\n",
      "         [-0.0115,  0.0448, -0.0041,  ..., -0.0010, -0.0051, -0.0332],\n",
      "         [ 0.0074,  0.1201, -0.0044,  ..., -0.0043,  0.0023,  0.0978],\n",
      "         ...,\n",
      "         [-0.0008, -0.1547, -0.0060,  ..., -0.0064, -0.0050, -0.1068],\n",
      "         [ 0.0186, -0.1945, -0.0334,  ..., -0.0050, -0.0346, -0.0272],\n",
      "         [-0.0208, -0.2015,  0.0101,  ..., -0.1657,  0.0053, -0.0381]],\n",
      "\n",
      "        [[-0.0469,  0.1512, -0.0194,  ..., -0.0058,  0.0170, -0.0659],\n",
      "         [-0.0051, -0.0092, -0.0092,  ..., -0.0030, -0.0073, -0.0444],\n",
      "         [ 0.0123,  0.1233, -0.0067,  ..., -0.0055,  0.0029,  0.1239],\n",
      "         ...,\n",
      "         [-0.0031,  0.0562, -0.0073,  ..., -0.0160, -0.0073, -0.0268],\n",
      "         [ 0.0173, -0.1665, -0.0454,  ..., -0.0066, -0.0470,  0.0357],\n",
      "         [-0.0201,  0.0669,  0.0094,  ..., -0.2186,  0.0055,  0.0008]],\n",
      "\n",
      "        [[-0.0396,  0.1336, -0.0239,  ..., -0.0104,  0.0154,  0.0176],\n",
      "         [-0.0037, -0.0362, -0.0098,  ..., -0.0033, -0.0081, -0.0944],\n",
      "         [ 0.0112,  0.3196, -0.0078,  ..., -0.0066,  0.0030,  0.1697],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0619,  0.1411, -0.0343,  ..., -0.0225,  0.0056,  0.0184],\n",
      "         [-0.0183,  0.0616, -0.0445,  ..., -0.0074, -0.0283,  0.0715],\n",
      "         [-0.0198,  0.1695, -0.0176,  ..., -0.0225,  0.0107,  0.2533],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0684,  0.1776, -0.0380,  ..., -0.0244, -0.0028,  0.0599],\n",
      "         [-0.0179,  0.0310, -0.0466,  ..., -0.0089, -0.0303,  0.0118],\n",
      "         [-0.0427,  0.1417, -0.0185,  ..., -0.0250,  0.0139,  0.2972],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0680,  0.1228, -0.0395,  ..., -0.0260, -0.0039, -0.0105],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 3.7186e-03, -6.6287e-02, -5.5569e-03,  ..., -3.9928e-03,\n",
      "           1.7437e-02, -3.6337e-02],\n",
      "         [ 1.1914e-02,  3.6641e-04, -1.0792e-03,  ..., -6.9503e-03,\n",
      "          -5.6038e-03, -6.0011e-02],\n",
      "         [ 4.6875e-03, -8.1262e-02, -2.3869e-03,  ..., -4.5134e-03,\n",
      "          -6.6690e-03, -3.4805e-02],\n",
      "         ...,\n",
      "         [ 6.2799e-03, -1.7071e-01, -1.0305e-02,  ..., -4.5317e-03,\n",
      "          -2.0554e-02, -3.1172e-02],\n",
      "         [ 1.6233e-03, -8.8106e-02, -9.0622e-03,  ..., -7.2627e-03,\n",
      "          -7.7498e-03, -2.5761e-02],\n",
      "         [ 2.3429e-03, -4.0513e-02, -1.1627e-02,  ..., -3.7310e-03,\n",
      "          -4.8393e-03, -2.0937e-02]],\n",
      "\n",
      "        [[ 8.2788e-03, -2.1831e-02, -5.3209e-03,  ..., -8.0621e-03,\n",
      "           1.9998e-02, -5.6978e-02],\n",
      "         [ 1.6324e-02, -1.0022e-01, -1.8299e-03,  ..., -7.9489e-03,\n",
      "          -6.2913e-03, -2.7684e-02],\n",
      "         [ 8.2119e-03, -1.3158e-01, -3.4915e-03,  ..., -9.0419e-03,\n",
      "          -2.8719e-03, -2.0292e-02],\n",
      "         ...,\n",
      "         [ 5.4153e-03, -2.1226e-01, -1.2591e-02,  ..., -5.5992e-03,\n",
      "          -2.6210e-02, -6.8053e-02],\n",
      "         [-1.4067e-04,  2.7675e-01, -1.0458e-02,  ..., -1.0859e-02,\n",
      "          -8.8091e-03,  2.3775e-02],\n",
      "         [ 1.5720e-02, -1.8775e-01, -2.9910e-02,  ..., -2.1710e-02,\n",
      "          -2.9655e-02,  9.5862e-02]],\n",
      "\n",
      "        [[ 7.7184e-03, -5.9755e-02, -7.0511e-03,  ..., -1.0250e-02,\n",
      "           2.4596e-02, -4.0327e-02],\n",
      "         [ 1.7131e-02, -1.1994e-01, -1.9796e-03,  ..., -8.6166e-03,\n",
      "          -7.2460e-03,  1.2111e-02],\n",
      "         [ 1.0253e-02, -1.5717e-01, -4.2052e-03,  ..., -9.9396e-03,\n",
      "          -8.1971e-03,  7.6683e-04],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9683e-02, -3.0662e-02, -1.3416e-02,  ..., -2.9303e-02,\n",
      "           4.8506e-02,  2.4712e-03],\n",
      "         [ 5.3349e-02, -3.7202e-02, -8.6363e-03,  ..., -1.7151e-02,\n",
      "          -1.6869e-02,  1.5837e-01],\n",
      "         [ 1.7601e-02, -2.0167e-01, -1.0078e-02,  ..., -1.5859e-02,\n",
      "          -1.9025e-02,  9.7272e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.6515e-02, -9.2408e-02, -1.6294e-02,  ..., -3.8412e-02,\n",
      "           5.3819e-02, -5.2506e-03],\n",
      "         [ 5.2102e-02,  1.9948e-01, -9.7238e-03,  ..., -1.7813e-02,\n",
      "          -2.0019e-02,  1.6830e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.7182e-02, -1.1705e-01, -1.6853e-02,  ..., -4.3551e-02,\n",
      "           5.4076e-02, -4.9855e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 7.1708e-03, -1.6403e-01, -1.9614e-03,  ..., -1.3555e-02,\n",
      "          -6.1327e-03, -4.3504e-02],\n",
      "         [-2.7779e-03,  4.9594e-03, -9.7112e-03,  ..., -4.5459e-03,\n",
      "          -1.2605e-02, -2.3236e-02],\n",
      "         [-1.2249e-02, -2.9014e-01, -4.4762e-03,  ..., -3.7124e-03,\n",
      "          -6.2702e-02, -9.2245e-02],\n",
      "         ...,\n",
      "         [-9.6257e-04, -5.8600e-02, -1.0053e-03,  ..., -2.6084e-03,\n",
      "          -4.3949e-03, -1.1179e-01],\n",
      "         [ 1.8209e-03, -1.5387e-01, -4.9647e-03,  ..., -6.0302e-03,\n",
      "          -5.7364e-03, -1.1913e-01],\n",
      "         [ 3.1848e-02, -8.0849e-02, -1.2153e-02,  ..., -7.6983e-03,\n",
      "          -1.4791e-02, -1.8961e-02]],\n",
      "\n",
      "        [[ 1.2723e-02, -7.9934e-02, -4.8803e-03,  ..., -1.7880e-02,\n",
      "          -7.8530e-03,  3.5341e-02],\n",
      "         [-3.6616e-02, -6.3152e-02, -1.8419e-02,  ..., -1.3210e-02,\n",
      "          -1.8254e-02,  3.0777e-02],\n",
      "         [-2.3281e-02, -2.9991e-01, -6.4185e-03,  ..., -1.7707e-03,\n",
      "          -7.4255e-02, -1.1208e-01],\n",
      "         ...,\n",
      "         [-2.8277e-03, -6.4601e-02, -2.0992e-03,  ..., -4.6912e-03,\n",
      "          -6.1497e-03, -8.6046e-02],\n",
      "         [ 7.4113e-03, -1.3272e-01, -9.0866e-03,  ..., -1.1342e-02,\n",
      "          -1.0103e-02, -1.6568e-01],\n",
      "         [ 2.9805e-02, -6.8471e-02, -1.5010e-02,  ..., -1.0005e-02,\n",
      "          -1.7836e-02, -6.6262e-03]],\n",
      "\n",
      "        [[ 1.3468e-02, -6.7528e-02, -6.9232e-03,  ..., -1.9967e-02,\n",
      "          -1.1049e-02,  1.0346e-02],\n",
      "         [-5.9819e-02, -9.6029e-02, -2.4881e-02,  ..., -1.6007e-02,\n",
      "          -1.9109e-02,  4.1500e-02],\n",
      "         [-4.7955e-02, -4.6235e-02, -8.6687e-03,  ..., -3.2233e-03,\n",
      "          -7.2879e-02, -5.3290e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9012e-02, -1.9097e-01, -5.9897e-03,  ..., -2.4318e-02,\n",
      "          -1.5009e-02, -5.4278e-02],\n",
      "         [-7.7702e-02, -3.3139e-02, -4.1603e-02,  ..., -2.3000e-02,\n",
      "          -2.7252e-02, -1.5978e-02],\n",
      "         [-6.4216e-02, -1.2769e-01, -1.2948e-02,  ..., -4.9074e-03,\n",
      "          -8.1120e-02, -7.5385e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.2792e-02, -1.5348e-02, -4.7353e-04,  ..., -2.8998e-02,\n",
      "          -1.5660e-02, -1.2767e-01],\n",
      "         [-7.5703e-02, -7.7729e-02, -4.2667e-02,  ..., -2.3777e-02,\n",
      "          -2.9582e-02, -1.3435e-02],\n",
      "         [-5.2708e-02, -3.3825e-03, -1.3367e-02,  ..., -6.3199e-03,\n",
      "          -8.2713e-02, -6.8078e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.2358e-02, -3.7768e-02,  1.0227e-04,  ..., -3.0650e-02,\n",
      "          -1.6162e-02, -6.9037e-02],\n",
      "         [-7.5706e-02, -1.0484e-01, -4.3660e-02,  ..., -2.3915e-02,\n",
      "          -3.0824e-02, -5.7833e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([12, 64, 500])\n",
      "encoder_input_lengths:  tensor([12, 10, 10, 10, 10,  9,  9,  9,  7,  7,  7,  7,  7,  7,  7,  7,  6,  6,\n",
      "         6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,\n",
      "         3,  3,  3,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-5.6489e-03,  2.0155e-02, -2.4985e-02,  ..., -7.5819e-03,\n",
      "           1.1003e-03, -5.2470e-02],\n",
      "         [ 2.1504e-03,  3.9063e-02, -2.9618e-03,  ..., -1.3099e-02,\n",
      "           3.7762e-03, -6.3364e-02],\n",
      "         [-1.2308e-01,  2.2710e-01, -1.0995e-02,  ..., -3.3051e-03,\n",
      "          -3.2313e-03,  4.0758e-02],\n",
      "         ...,\n",
      "         [ 1.5145e-02, -2.7499e-02, -1.2472e-02,  ..., -7.1562e-03,\n",
      "           4.0317e-03, -5.0114e-02],\n",
      "         [ 6.6738e-03, -2.7319e-01, -2.3792e-03,  ..., -6.8128e-03,\n",
      "          -7.7090e-04, -9.7335e-02],\n",
      "         [ 8.5446e-03, -4.5731e-02, -4.4864e-03,  ..., -2.8249e-03,\n",
      "          -4.4147e-02, -2.5775e-02]],\n",
      "\n",
      "        [[-1.6235e-02, -2.9305e-02, -3.1715e-02,  ..., -1.4534e-02,\n",
      "           4.7264e-03, -3.4815e-02],\n",
      "         [ 3.4220e-03, -2.7004e-02, -4.4872e-03,  ..., -1.9955e-02,\n",
      "          -2.8581e-04, -3.2701e-03],\n",
      "         [-1.0945e-01,  1.4074e-01, -1.8462e-02,  ..., -4.0551e-03,\n",
      "          -4.7824e-03,  7.9433e-02],\n",
      "         ...,\n",
      "         [ 2.5018e-02, -9.2652e-02, -2.9560e-02,  ..., -6.9259e-03,\n",
      "           9.0771e-03,  4.8984e-02],\n",
      "         [ 5.0646e-03, -3.1823e-01, -8.2209e-03,  ..., -9.4250e-03,\n",
      "           6.0545e-05, -3.8490e-02],\n",
      "         [ 1.8549e-02, -1.2520e-01, -7.6768e-03,  ..., -4.3837e-03,\n",
      "          -6.1141e-02,  1.1292e-02]],\n",
      "\n",
      "        [[-2.0980e-03, -6.6687e-02, -4.2012e-02,  ..., -1.6056e-02,\n",
      "           2.4580e-03, -5.8112e-02],\n",
      "         [ 4.6224e-03,  7.0257e-02, -4.4385e-03,  ..., -1.0151e-02,\n",
      "           6.7518e-03, -6.1664e-02],\n",
      "         [-8.1680e-02,  1.8121e-01, -2.1497e-02,  ..., -5.9788e-03,\n",
      "          -1.5317e-02,  1.9081e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.3106e-02, -1.4109e-02, -6.7743e-02,  ..., -2.9020e-02,\n",
      "           9.1656e-03, -4.4629e-02],\n",
      "         [ 9.6251e-03,  1.8881e-01, -9.9571e-03,  ..., -1.1274e-01,\n",
      "           1.9547e-02, -6.0522e-02],\n",
      "         [-9.0017e-02,  6.4993e-02, -3.8642e-02,  ..., -2.6661e-02,\n",
      "          -2.1938e-02, -8.0330e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.8763e-02, -1.6863e-02, -7.0444e-02,  ..., -2.8560e-02,\n",
      "           9.6322e-03, -5.1160e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4243e-02, -7.3712e-02, -7.3537e-02,  ..., -2.9404e-02,\n",
      "           1.0502e-02, -1.9465e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 30; Percent complete: 2.6%; Average loss: 0.6926\n",
      "encoder outputs shape:  torch.Size([14, 64, 500])\n",
      "encoder_input_lengths:  tensor([14, 11, 10,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,\n",
      "         7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  3,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 6.1250e-03, -1.1222e-01,  8.3470e-03,  ..., -1.7801e-02,\n",
      "           1.2340e-02, -3.3669e-02],\n",
      "         [-3.3506e-03, -1.0981e-01, -1.0796e-02,  ..., -6.3384e-03,\n",
      "          -2.8584e-02,  1.2370e-02],\n",
      "         [ 2.2297e-02, -1.3686e-01,  2.1234e-05,  ..., -1.2195e-03,\n",
      "          -6.9973e-03, -1.2899e-02],\n",
      "         ...,\n",
      "         [-1.3860e-03, -1.8332e-01, -1.1256e-02,  ..., -1.9161e-02,\n",
      "           5.0132e-03, -2.5857e-02],\n",
      "         [ 8.0891e-03,  4.0249e-01, -1.0073e-02,  ..., -1.0866e-02,\n",
      "           4.0827e-03, -7.4687e-02],\n",
      "         [ 2.7588e-03, -8.1093e-02, -1.8497e-02,  ..., -8.8556e-03,\n",
      "          -4.0898e-02, -3.7654e-02]],\n",
      "\n",
      "        [[ 7.0309e-03, -1.7284e-01,  8.3233e-03,  ..., -2.1765e-02,\n",
      "           1.5102e-02,  1.2269e-02],\n",
      "         [-2.8839e-03, -1.7795e-01, -1.4198e-02,  ..., -6.6188e-03,\n",
      "          -3.0512e-02,  4.9017e-02],\n",
      "         [ 2.5370e-02, -7.9872e-02,  1.2656e-03,  ..., -4.5456e-03,\n",
      "          -1.4014e-02, -1.0789e-01],\n",
      "         ...,\n",
      "         [-4.4848e-03, -1.0911e-01, -1.4096e-02,  ..., -3.5153e-02,\n",
      "           5.8052e-03,  1.4446e-03],\n",
      "         [-2.2429e-02,  4.1511e-01, -1.6306e-02,  ..., -3.3313e-02,\n",
      "           1.9123e-02, -8.1664e-02],\n",
      "         [ 4.6837e-03, -1.2228e-01, -2.1189e-02,  ..., -1.1771e-02,\n",
      "          -4.6133e-02, -1.6768e-02]],\n",
      "\n",
      "        [[ 2.3356e-02,  7.2666e-02,  6.7267e-03,  ..., -3.3997e-02,\n",
      "           2.1237e-02,  3.8593e-02],\n",
      "         [-5.4853e-03, -2.7579e-02, -1.6018e-02,  ..., -9.1102e-03,\n",
      "          -3.2703e-02,  9.3020e-02],\n",
      "         [ 1.1001e-02,  5.1443e-02,  1.2117e-03,  ..., -8.6341e-03,\n",
      "          -1.5689e-02, -4.2034e-02],\n",
      "         ...,\n",
      "         [-4.8274e-03, -2.0065e-01, -1.6415e-02,  ..., -3.8025e-02,\n",
      "          -5.7539e-04,  9.0584e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6130e-02, -2.2474e-01,  5.0269e-03,  ..., -4.3072e-02,\n",
      "           1.8293e-02,  1.2470e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.7681e-03, -2.4619e-01,  3.8095e-03,  ..., -4.4238e-02,\n",
      "           1.8452e-02,  9.7499e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4342e-03, -2.2995e-01,  3.0151e-03,  ..., -4.5982e-02,\n",
      "           1.5622e-02,  1.4937e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([14, 64, 500])\n",
      "encoder_input_lengths:  tensor([14, 10,  9,  9,  8,  8,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-7.7211e-03,  3.2445e-01, -2.8710e-03,  ..., -4.0563e-03,\n",
      "          -2.1504e-02, -9.7896e-03],\n",
      "         [ 7.1411e-03, -8.7030e-02, -7.5106e-03,  ..., -6.9193e-03,\n",
      "           2.2499e-03, -6.3693e-02],\n",
      "         [ 2.2418e-03,  1.2223e-01, -3.0519e-03,  ..., -4.3901e-03,\n",
      "          -7.3878e-04, -8.0590e-02],\n",
      "         ...,\n",
      "         [ 1.6820e-05, -8.8899e-02, -9.3821e-03,  ..., -9.0450e-03,\n",
      "          -4.4913e-03,  3.6226e-02],\n",
      "         [ 2.0469e-03, -8.7841e-02, -5.9155e-03,  ..., -3.6774e-02,\n",
      "           1.2102e-02,  7.8961e-02],\n",
      "         [-4.5056e-04,  1.2661e-01,  1.3324e-01,  ..., -2.4170e-02,\n",
      "          -5.5447e-03, -8.9695e-02]],\n",
      "\n",
      "        [[-3.1761e-03,  4.0682e-02, -3.9343e-03,  ..., -8.6776e-03,\n",
      "          -2.7010e-02,  4.1172e-02],\n",
      "         [ 1.0381e-02, -2.0434e-01, -1.0279e-02,  ..., -1.2807e-02,\n",
      "           3.5317e-03, -8.3111e-02],\n",
      "         [ 4.4026e-03,  3.0847e-02, -6.2185e-03,  ..., -5.9973e-03,\n",
      "          -1.0441e-03, -1.0748e-01],\n",
      "         ...,\n",
      "         [-3.2432e-03, -1.4030e-01, -1.3651e-02,  ..., -1.3742e-02,\n",
      "          -3.7280e-03,  4.8706e-02],\n",
      "         [ 1.1528e-02, -1.7033e-01, -9.2831e-03,  ..., -4.5864e-02,\n",
      "           1.7762e-02,  7.6514e-02],\n",
      "         [-1.2560e-03,  1.5314e-01,  1.5449e-01,  ..., -2.9279e-02,\n",
      "          -1.0119e-02, -6.8293e-02]],\n",
      "\n",
      "        [[-7.2567e-03,  5.8879e-02, -4.2191e-03,  ..., -1.0778e-02,\n",
      "          -2.7156e-02,  8.5488e-02],\n",
      "         [ 1.0590e-02, -2.4808e-01, -1.1885e-02,  ..., -1.4155e-02,\n",
      "           6.1848e-03, -6.1125e-02],\n",
      "         [-3.4590e-03,  1.0181e-01, -7.1583e-03,  ..., -8.5597e-03,\n",
      "          -5.5595e-04,  2.5713e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.5860e-03,  3.0923e-01, -1.2348e-02,  ..., -2.3096e-02,\n",
      "          -3.4926e-02,  1.9006e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.7739e-04,  3.0412e-01, -1.2643e-02,  ..., -2.3603e-02,\n",
      "          -3.6140e-02,  2.4137e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.8835e-03,  2.6149e-01, -1.3311e-02,  ..., -2.4944e-02,\n",
      "          -3.6617e-02,  2.0568e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 3.6007e-02,  5.9230e-01,  9.0266e-03,  ..., -1.4420e-02,\n",
      "          -2.6381e-02,  8.5060e-03],\n",
      "         [-1.6000e-04,  3.9614e-01, -3.4428e-03,  ..., -3.2851e-03,\n",
      "          -6.1351e-03, -2.2942e-02],\n",
      "         [-3.4336e-03, -1.1702e-01, -2.1358e-02,  ..., -7.4101e-03,\n",
      "          -5.8825e-02, -1.5179e-02],\n",
      "         ...,\n",
      "         [-1.0387e-02,  2.2400e-01, -1.2474e-02,  ..., -7.3603e-03,\n",
      "           1.5944e-02, -7.1751e-02],\n",
      "         [ 3.8860e-04,  1.0386e-02, -8.9026e-03,  ..., -1.1021e-02,\n",
      "           8.6412e-03, -1.0042e-01],\n",
      "         [-8.5549e-02,  4.2891e-01, -2.4730e-03,  ..., -5.1684e-03,\n",
      "          -2.0317e-03, -1.2219e-02]],\n",
      "\n",
      "        [[ 4.3204e-02,  7.3265e-01,  5.2481e-03,  ..., -1.6092e-02,\n",
      "          -2.9069e-02,  1.0058e-01],\n",
      "         [ 1.2152e-02,  3.0270e-01, -2.6006e-03,  ..., -7.3464e-03,\n",
      "          -8.7670e-03, -3.1402e-03],\n",
      "         [-4.8158e-02, -1.9075e-01, -3.2324e-02,  ..., -9.2236e-03,\n",
      "          -7.3547e-02,  4.0377e-02],\n",
      "         ...,\n",
      "         [-1.1017e-02,  1.4331e-01, -1.6106e-02,  ..., -1.0224e-02,\n",
      "           2.1344e-02, -3.4164e-02],\n",
      "         [-2.9040e-02,  7.5546e-02, -2.2926e-02,  ..., -1.5101e-02,\n",
      "           1.0793e-02, -1.2104e-01],\n",
      "         [-9.1138e-02,  4.1514e-01, -5.3160e-03,  ..., -8.8459e-03,\n",
      "          -6.2230e-03,  1.0238e-03]],\n",
      "\n",
      "        [[ 4.5050e-02,  7.8864e-01,  5.0045e-02,  ..., -1.8299e-02,\n",
      "          -3.4245e-02,  1.3927e-01],\n",
      "         [ 1.9121e-02,  4.2361e-01, -2.6518e-03,  ..., -1.1712e-02,\n",
      "          -8.6041e-03,  7.5518e-03],\n",
      "         [-9.7016e-02,  1.6568e-01, -4.2657e-02,  ..., -1.0160e-02,\n",
      "          -8.1060e-02,  8.0403e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.2853e-02,  6.2730e-01,  3.4447e-02,  ..., -2.0796e-02,\n",
      "          -4.6290e-02,  6.6927e-02],\n",
      "         [ 5.5039e-02,  5.3084e-01, -5.5941e-03,  ..., -1.8942e-02,\n",
      "          -1.5713e-02,  2.7575e-02],\n",
      "         [-6.0667e-02,  4.0493e-01, -5.9424e-02,  ..., -1.1607e-02,\n",
      "          -1.0510e-01,  1.6110e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.8959e-02,  6.9001e-01,  3.4505e-02,  ..., -2.4545e-02,\n",
      "          -4.7255e-02,  8.0865e-02],\n",
      "         [ 5.5018e-02,  5.6942e-01, -6.3947e-03,  ..., -1.9824e-02,\n",
      "          -1.6052e-02,  2.8921e-02],\n",
      "         [-2.6799e-02,  5.2621e-01, -6.0756e-02,  ..., -1.2787e-02,\n",
      "          -1.1687e-01,  1.5781e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.9859e-02,  7.9741e-01,  3.0547e-02,  ..., -2.6222e-02,\n",
      "          -5.0080e-02,  5.1050e-02],\n",
      "         [ 5.7039e-02,  4.9789e-01, -6.9096e-03,  ..., -2.0548e-02,\n",
      "          -1.6143e-02,  4.1830e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 8, 8, 8, 8, 8, 8, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 4.8191e-03, -1.4937e-01, -2.6935e-03,  ..., -4.7164e-03,\n",
      "           8.6815e-04, -1.9943e-02],\n",
      "         [ 1.8683e-03, -1.1968e-01, -3.4983e-03,  ..., -9.9728e-03,\n",
      "          -3.9691e-03, -6.5771e-02],\n",
      "         [ 1.9537e-02,  1.0223e-01, -6.5857e-03,  ..., -2.4828e-03,\n",
      "          -1.7994e-02, -6.4745e-02],\n",
      "         ...,\n",
      "         [-1.7517e-02,  1.7841e-01,  1.1888e-04,  ..., -1.3307e-02,\n",
      "           7.5434e-04, -2.9896e-03],\n",
      "         [-8.7956e-03,  8.8943e-02, -5.6150e-03,  ..., -5.5422e-03,\n",
      "           7.4796e-03, -5.1258e-02],\n",
      "         [-2.3698e-02, -2.8218e-01, -8.4121e-03,  ..., -8.7346e-03,\n",
      "          -1.9348e-02,  2.1839e-02]],\n",
      "\n",
      "        [[ 1.3547e-02, -2.3883e-01, -5.6372e-03,  ..., -8.4324e-03,\n",
      "           4.8028e-03, -3.6876e-02],\n",
      "         [ 3.0568e-03, -1.0742e-01, -6.7635e-03,  ..., -1.4128e-02,\n",
      "           7.2476e-04, -8.4349e-02],\n",
      "         [ 3.1742e-02,  1.5006e-01, -1.3402e-02,  ..., -4.6965e-03,\n",
      "          -2.6189e-02,  3.0492e-02],\n",
      "         ...,\n",
      "         [-3.1890e-02,  2.9821e-01, -3.0924e-03,  ..., -1.7076e-02,\n",
      "           2.1939e-03,  3.9442e-02],\n",
      "         [ 4.4376e-03,  1.9382e-01, -7.2553e-03,  ..., -6.9569e-03,\n",
      "           6.1109e-03, -4.6421e-02],\n",
      "         [-3.9783e-02, -2.8500e-01, -1.6759e-02,  ..., -1.0335e-02,\n",
      "          -2.3578e-02,  2.8444e-02]],\n",
      "\n",
      "        [[ 3.4133e-03, -1.7143e-01, -9.5112e-03,  ..., -1.0057e-02,\n",
      "           9.5506e-03, -5.9224e-02],\n",
      "         [ 6.1560e-03, -1.3769e-01, -8.5479e-03,  ..., -1.5628e-02,\n",
      "           2.3802e-03, -8.3804e-02],\n",
      "         [ 2.8960e-02,  1.9259e-02, -1.5465e-02,  ..., -6.0555e-03,\n",
      "          -2.9238e-02,  9.5978e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2370e-02, -2.0400e-01, -1.7979e-02,  ..., -1.9105e-02,\n",
      "           1.6899e-02,  8.0800e-02],\n",
      "         [ 1.5651e-02, -9.0015e-02, -1.1468e-02,  ..., -2.1124e-02,\n",
      "          -2.3627e-03, -1.0161e-01],\n",
      "         [ 3.6747e-02, -9.3669e-02, -1.9106e-02,  ..., -9.4366e-03,\n",
      "          -4.1190e-02,  1.5150e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.3581e-02, -2.8225e-01, -2.0214e-02,  ..., -2.0810e-02,\n",
      "           2.2228e-02,  2.3144e-02],\n",
      "         [ 2.4858e-02, -5.8050e-02, -1.1885e-02,  ..., -2.4442e-02,\n",
      "          -1.7160e-03, -1.2040e-01],\n",
      "         [ 4.0427e-02, -4.1049e-02, -1.9932e-02,  ..., -1.0985e-02,\n",
      "          -4.2424e-02,  1.7827e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.7718e-02, -1.1385e-01, -2.9053e-02,  ..., -2.2370e-02,\n",
      "           1.9597e-02,  2.0045e-02],\n",
      "         [ 2.6722e-02, -7.0078e-02, -1.2325e-02,  ..., -2.6019e-02,\n",
      "          -2.9650e-03, -1.3285e-01],\n",
      "         [ 4.4024e-02,  1.1152e-01, -2.0333e-02,  ..., -1.1480e-02,\n",
      "          -4.2508e-02,  9.9352e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([17, 64, 500])\n",
      "encoder_input_lengths:  tensor([17, 13,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,\n",
      "         7,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 4.0067e-02, -9.0330e-03, -1.2984e-02,  ..., -8.8673e-03,\n",
      "          -8.2180e-03, -1.0159e-01],\n",
      "         [ 1.3842e-02, -1.5104e-01, -1.4640e-04,  ..., -9.5513e-03,\n",
      "           1.7122e-03, -8.9509e-02],\n",
      "         [-7.3000e-04, -9.4611e-02, -2.3098e-02,  ..., -4.1111e-03,\n",
      "          -3.6302e-02,  5.0448e-03],\n",
      "         ...,\n",
      "         [ 3.9536e-03, -2.2790e-01, -1.5363e-02,  ..., -1.0753e-02,\n",
      "           4.0411e-03, -3.1207e-02],\n",
      "         [-2.7765e-03, -1.7838e-01,  2.1215e-03,  ..., -7.5380e-03,\n",
      "          -4.7041e-03, -4.0248e-02],\n",
      "         [-8.5455e-04, -5.8445e-02, -5.2815e-03,  ..., -5.2782e-03,\n",
      "          -5.0339e-04, -2.3210e-02]],\n",
      "\n",
      "        [[ 4.3818e-02, -5.6911e-02, -1.9125e-02,  ..., -1.0521e-02,\n",
      "          -1.1352e-02, -6.2790e-02],\n",
      "         [ 1.4686e-02, -1.2162e-01, -2.7473e-03,  ..., -3.5536e-02,\n",
      "          -1.5623e-02, -9.7592e-02],\n",
      "         [ 3.4764e-02,  1.7583e-01, -2.7948e-02,  ..., -1.2319e-02,\n",
      "          -9.0859e-02,  1.8332e-02],\n",
      "         ...,\n",
      "         [ 6.1087e-03, -2.6405e-01, -1.7771e-02,  ..., -1.4640e-02,\n",
      "           5.7858e-03, -1.2245e-01],\n",
      "         [-1.0998e-04, -1.7660e-01,  4.3229e-04,  ..., -1.1359e-02,\n",
      "           3.8946e-05, -9.7169e-02],\n",
      "         [ 1.3549e-03, -7.0125e-02, -6.1750e-03,  ..., -8.1682e-03,\n",
      "          -1.2516e-03, -2.1319e-02]],\n",
      "\n",
      "        [[ 4.9559e-02, -1.6836e-01, -3.0238e-02,  ..., -1.1268e-02,\n",
      "          -1.4049e-02, -5.7345e-02],\n",
      "         [ 1.4540e-02, -3.1218e-02, -3.1313e-03,  ..., -5.0418e-02,\n",
      "          -2.1345e-02, -1.3635e-01],\n",
      "         [ 4.5953e-02,  1.5809e-01, -2.9475e-02,  ..., -1.4053e-02,\n",
      "          -1.2502e-01,  4.5186e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4985e-01,  2.3011e-01, -5.6988e-02,  ..., -2.2716e-02,\n",
      "          -7.0321e-02,  3.0552e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4713e-01,  1.5550e-01, -5.8892e-02,  ..., -2.3588e-02,\n",
      "          -7.1883e-02,  1.0695e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4660e-01,  1.4056e-01, -6.0201e-02,  ..., -2.4078e-02,\n",
      "          -7.1569e-02, -2.0289e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,\n",
      "         5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  3,  3,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-0.0109, -0.1453, -0.0382,  ..., -0.0022, -0.0221, -0.0024],\n",
      "         [ 0.0159,  0.0147, -0.0040,  ..., -0.0364,  0.0077,  0.0170],\n",
      "         [ 0.0163, -0.1930, -0.0066,  ..., -0.0041, -0.0132, -0.0129],\n",
      "         ...,\n",
      "         [-0.0037, -0.1158, -0.0096,  ..., -0.0048,  0.0038, -0.0383],\n",
      "         [ 0.0039, -0.1100, -0.0011,  ..., -0.0089, -0.0022, -0.0751],\n",
      "         [ 0.0063, -0.0398, -0.0119,  ..., -0.0040, -0.0092, -0.0294]],\n",
      "\n",
      "        [[-0.0112, -0.1234, -0.0452,  ..., -0.0056, -0.0277,  0.0082],\n",
      "         [ 0.0179, -0.0244, -0.0046,  ..., -0.0373,  0.0079, -0.0174],\n",
      "         [ 0.0189, -0.2230, -0.0077,  ..., -0.0055, -0.0159, -0.0922],\n",
      "         ...,\n",
      "         [-0.0051, -0.0987, -0.0149,  ..., -0.0062,  0.0024, -0.0172],\n",
      "         [ 0.0037, -0.1205, -0.0023,  ..., -0.0120, -0.0013, -0.1097],\n",
      "         [ 0.0099, -0.0419, -0.0147,  ..., -0.0055, -0.0085, -0.0216]],\n",
      "\n",
      "        [[-0.0094, -0.1363, -0.0469,  ..., -0.0064, -0.0283,  0.0070],\n",
      "         [ 0.0267, -0.0313, -0.0042,  ..., -0.0654,  0.0142,  0.0542],\n",
      "         [ 0.0197, -0.2211, -0.0185,  ..., -0.0104, -0.0184, -0.0439],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0234, -0.1545, -0.1648,  ..., -0.0103, -0.1004,  0.0298],\n",
      "         [ 0.0347, -0.1233, -0.0090,  ..., -0.1110,  0.0195,  0.2445],\n",
      "         [-0.0274, -0.1791, -0.0472,  ..., -0.0436, -0.0029,  0.1786],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0218, -0.0132, -0.1701,  ..., -0.0138, -0.0985, -0.0108],\n",
      "         [ 0.0362, -0.0878, -0.0131,  ..., -0.1127,  0.0210,  0.2052],\n",
      "         [-0.0280, -0.2239, -0.0512,  ..., -0.0458, -0.0091,  0.1687],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0201,  0.0253, -0.1715,  ..., -0.0189, -0.0968, -0.0162],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,\n",
      "         3,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-2.4392e-03, -1.4222e-01, -3.7665e-03,  ..., -5.7039e-03,\n",
      "          -1.6839e-02, -1.5922e-02],\n",
      "         [-1.7483e-03, -1.1960e-01, -1.3273e-02,  ..., -5.2701e-03,\n",
      "          -2.5541e-02,  4.8051e-03],\n",
      "         [ 1.1339e-02, -1.5983e-02, -9.0491e-03,  ..., -2.7005e-03,\n",
      "          -2.5349e-02, -6.7641e-02],\n",
      "         ...,\n",
      "         [-7.7645e-02,  2.7939e-01, -6.2558e-03,  ..., -1.1646e-02,\n",
      "          -8.3237e-03, -5.2937e-02],\n",
      "         [ 2.4916e-03, -1.6686e-01, -4.8719e-03,  ..., -7.0576e-03,\n",
      "           1.9988e-04, -1.1332e-01],\n",
      "         [-1.6706e-02, -1.2749e-01, -1.1864e-02,  ..., -4.5225e-03,\n",
      "           1.3835e-03, -6.0393e-02]],\n",
      "\n",
      "        [[-1.2055e-03, -1.7179e-01, -4.4693e-03,  ..., -7.6493e-03,\n",
      "          -2.2034e-02, -4.7073e-02],\n",
      "         [-8.2251e-02,  3.0717e-01, -1.7942e-02,  ..., -1.0991e-02,\n",
      "          -3.0386e-02,  5.6762e-02],\n",
      "         [ 1.4050e-02,  5.8736e-03, -1.4427e-02,  ..., -3.8923e-03,\n",
      "          -3.3140e-02, -7.4808e-02],\n",
      "         ...,\n",
      "         [-8.3078e-02,  2.2800e-01, -9.6359e-03,  ..., -1.3055e-02,\n",
      "          -1.0814e-02, -6.7734e-02],\n",
      "         [ 2.3084e-04, -2.9021e-01, -8.0163e-03,  ..., -9.0868e-03,\n",
      "          -7.4506e-03, -5.6486e-02],\n",
      "         [-2.1955e-02, -2.1493e-01, -2.0949e-02,  ..., -7.4252e-03,\n",
      "           1.3142e-03, -6.0079e-02]],\n",
      "\n",
      "        [[-2.4703e-03, -2.0654e-01, -5.3010e-03,  ..., -9.3770e-03,\n",
      "          -3.0086e-02, -2.2668e-02],\n",
      "         [-7.2864e-02,  1.3279e-01, -2.3339e-02,  ..., -1.0482e-02,\n",
      "          -3.5101e-02,  1.0557e-01],\n",
      "         [ 1.1511e-02, -9.3535e-04, -1.6926e-02,  ..., -4.5346e-03,\n",
      "          -3.5581e-02, -1.1587e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.0692e-03, -3.5265e-01, -8.9456e-03,  ..., -1.5744e-02,\n",
      "          -4.6917e-02, -7.9300e-02],\n",
      "         [-1.3096e-01,  2.5532e-01, -2.4785e-02,  ..., -1.0136e-02,\n",
      "          -5.3933e-02,  1.5252e-01],\n",
      "         [ 6.0124e-03,  7.2386e-02, -2.9446e-02,  ..., -1.0281e-02,\n",
      "          -6.1239e-02, -1.1333e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.0671e-03, -3.2712e-01, -1.0119e-02,  ..., -1.6805e-02,\n",
      "          -4.8622e-02, -2.0925e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 9.0816e-04, -2.8733e-01, -1.0483e-02,  ..., -1.7377e-02,\n",
      "          -4.9533e-02, -8.4021e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  6,  6,\n",
      "         6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.4836e-03,  1.2390e-01, -3.2321e-04,  ..., -1.4557e-03,\n",
      "          -7.9572e-03, -3.9314e-02],\n",
      "         [ 8.6492e-02,  1.4919e-01, -8.0745e-03,  ..., -1.7331e-02,\n",
      "           6.1345e-02, -2.4721e-02],\n",
      "         [ 6.4457e-03, -3.7003e-02, -3.0283e-03,  ..., -7.2869e-03,\n",
      "          -1.0497e-03, -2.8222e-02],\n",
      "         ...,\n",
      "         [ 6.0124e-03, -1.2087e-01, -3.9370e-03,  ..., -9.6544e-03,\n",
      "          -9.1255e-03, -7.2235e-03],\n",
      "         [ 1.0695e-02, -1.2756e-01, -8.3538e-03,  ..., -5.1311e-03,\n",
      "          -6.7151e-04, -5.8093e-02],\n",
      "         [ 5.6462e-03, -2.1101e-01,  1.1423e-03,  ..., -1.1453e-02,\n",
      "          -5.6138e-03, -1.7689e-01]],\n",
      "\n",
      "        [[-1.3965e-03,  7.8478e-02, -3.5940e-03,  ..., -1.9980e-03,\n",
      "          -8.5974e-03, -4.7410e-02],\n",
      "         [ 8.8095e-02,  1.2449e-01, -9.3179e-03,  ..., -1.8941e-02,\n",
      "           6.0085e-02, -9.0738e-02],\n",
      "         [ 4.4039e-03, -1.2379e-01, -4.4567e-03,  ..., -7.2534e-03,\n",
      "          -2.6842e-04, -5.1875e-02],\n",
      "         ...,\n",
      "         [ 9.4033e-03, -1.4864e-01, -6.3846e-03,  ..., -1.3948e-02,\n",
      "          -8.8041e-03,  4.2446e-02],\n",
      "         [ 7.8809e-03, -2.0116e-01, -1.0522e-02,  ..., -8.4728e-03,\n",
      "          -5.1650e-03,  3.4685e-02],\n",
      "         [ 8.2896e-03, -7.4339e-02,  6.6674e-04,  ..., -2.3271e-02,\n",
      "          -8.6590e-03, -1.9940e-01]],\n",
      "\n",
      "        [[-7.9726e-03,  9.4923e-02, -3.9011e-03,  ..., -1.5440e-03,\n",
      "          -1.2157e-02, -1.1409e-01],\n",
      "         [ 1.1520e-01,  2.4250e-01, -1.1308e-02,  ..., -2.1363e-02,\n",
      "           6.9829e-02, -7.5248e-02],\n",
      "         [ 4.0649e-03,  2.3302e-04, -4.5713e-03,  ..., -2.0915e-02,\n",
      "          -5.6058e-03, -7.5913e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7512e-02,  1.6488e-01, -1.0018e-02,  ..., -1.1737e-02,\n",
      "          -2.4530e-02, -2.6533e-02],\n",
      "         [ 1.6914e-01,  2.1496e-01, -1.8334e-02,  ..., -3.6136e-02,\n",
      "           7.5577e-02, -1.6236e-02],\n",
      "         [ 6.2539e-03,  7.2014e-03, -8.1853e-03,  ..., -2.8813e-02,\n",
      "          -1.7598e-02, -7.5681e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.7517e-02,  2.5390e-01, -1.0212e-02,  ..., -1.3508e-02,\n",
      "          -3.0461e-02, -1.9572e-02],\n",
      "         [ 1.3573e-01,  1.6234e-01, -1.9442e-02,  ..., -4.2038e-02,\n",
      "           7.6431e-02,  4.6985e-02],\n",
      "         [ 7.8214e-03, -2.2529e-02, -1.0036e-02,  ..., -3.3415e-02,\n",
      "          -1.9128e-02, -8.9311e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.6868e-02,  1.9192e-01, -1.0530e-02,  ..., -1.3778e-02,\n",
      "          -3.1991e-02, -3.0197e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  3,  3,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.3287e-02, -1.2979e-01,  7.9630e-03,  ..., -2.0084e-02,\n",
      "          -1.8559e-02,  4.7345e-02],\n",
      "         [-1.3581e-03, -2.4059e-01, -5.0524e-03,  ..., -1.9175e-03,\n",
      "          -2.4027e-02, -7.7195e-02],\n",
      "         [ 1.5528e-02, -8.5167e-02, -3.3602e-03,  ..., -9.2494e-03,\n",
      "           3.8628e-02, -7.0021e-02],\n",
      "         ...,\n",
      "         [-1.4645e-03, -1.5542e-01, -7.4447e-03,  ..., -1.1725e-02,\n",
      "          -1.0119e-03, -3.8727e-02],\n",
      "         [-2.0633e-02,  2.1522e-01, -1.4820e-02,  ..., -4.1504e-03,\n",
      "          -8.9995e-03, -7.2523e-04],\n",
      "         [ 4.5260e-03, -3.1710e-02,  2.7999e-03,  ..., -7.5208e-01,\n",
      "           3.4407e-03, -1.0609e-02]],\n",
      "\n",
      "        [[ 1.2281e-02, -2.3503e-01, -4.0394e-03,  ..., -2.5928e-02,\n",
      "          -9.6090e-03,  6.5193e-02],\n",
      "         [ 3.0507e-03, -2.6340e-01, -6.9273e-03,  ..., -2.7774e-03,\n",
      "          -2.8674e-02, -1.1689e-01],\n",
      "         [ 2.3665e-02, -8.8300e-02, -7.2803e-03,  ..., -1.5374e-02,\n",
      "           5.5798e-02, -6.7757e-02],\n",
      "         ...,\n",
      "         [ 1.0501e-03, -1.7471e-01, -1.1858e-02,  ..., -1.6459e-02,\n",
      "          -2.8279e-03, -1.4188e-02],\n",
      "         [-2.5043e-02,  1.3803e-01, -2.0385e-02,  ..., -6.0015e-03,\n",
      "          -2.5736e-02,  2.4673e-02],\n",
      "         [ 5.7995e-03, -1.5376e-01,  3.5790e-03,  ..., -9.1304e-01,\n",
      "           4.0182e-03,  1.6744e-01]],\n",
      "\n",
      "        [[ 1.4686e-02, -5.6694e-02, -9.6391e-03,  ..., -3.0182e-02,\n",
      "          -3.5151e-03,  5.9711e-02],\n",
      "         [ 9.9769e-03, -1.0044e-01, -9.0377e-03,  ..., -4.1598e-03,\n",
      "          -3.0143e-02, -1.3928e-01],\n",
      "         [ 2.6972e-02, -3.0241e-02, -8.3674e-03,  ..., -1.9665e-02,\n",
      "           6.1205e-02, -5.7160e-02],\n",
      "         ...,\n",
      "         [ 2.8634e-03, -1.5143e-01, -1.5425e-02,  ..., -2.0347e-02,\n",
      "          -3.7440e-03,  2.0550e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4962e-02, -1.2762e-01, -2.6057e-02,  ..., -4.3794e-02,\n",
      "           1.1200e-02,  9.1788e-02],\n",
      "         [ 2.9394e-02, -1.5566e-01, -1.4943e-02,  ..., -6.4103e-03,\n",
      "          -5.3904e-02,  3.9107e-02],\n",
      "         [ 7.4698e-02,  2.4017e-02, -4.4930e-03,  ..., -2.6383e-02,\n",
      "           4.4079e-02, -1.0500e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.5032e-02, -1.7278e-01, -2.8345e-02,  ..., -4.8443e-02,\n",
      "           1.0941e-02,  2.3459e-02],\n",
      "         [ 3.0142e-02, -1.2752e-01, -1.5990e-02,  ..., -6.7507e-03,\n",
      "          -5.4521e-02,  6.3008e-02],\n",
      "         [ 7.5518e-02, -2.5174e-02, -5.5464e-03,  ..., -3.2331e-02,\n",
      "           3.9829e-02, -2.2842e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4452e-02, -1.7856e-01, -3.0414e-02,  ..., -4.9737e-02,\n",
      "           1.1415e-02,  2.5931e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Validating!\n",
      "encoder outputs shape:  torch.Size([13, 64, 500])\n",
      "encoder_input_lengths:  tensor([13, 11, 10,  9,  9,  7,  6,  6,  6,  6,  6,  6,  6,  5,  5,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.6824e-02,  2.2580e-01, -8.0218e-03,  ..., -3.4634e-03,\n",
      "           4.8241e-03, -1.2174e-02],\n",
      "         [ 5.5895e-03,  4.1680e-01,  6.0360e-03,  ..., -9.4972e-03,\n",
      "          -1.1315e-02,  1.6664e-02],\n",
      "         [ 1.0661e-03, -1.9100e-01, -4.8000e-03,  ..., -6.2475e-03,\n",
      "           1.6355e-02, -4.1584e-02],\n",
      "         ...,\n",
      "         [-4.6303e-03, -7.3793e-02, -2.9250e-02,  ..., -1.1428e-02,\n",
      "           5.3711e-03,  3.9313e-02],\n",
      "         [-6.3096e-03, -1.0951e-01, -1.3102e-02,  ..., -7.8056e-03,\n",
      "          -1.1018e-02,  5.8670e-02],\n",
      "         [ 1.9079e-03, -1.4566e-01, -1.4637e-03,  ..., -2.5899e-03,\n",
      "          -5.1705e-03, -1.8303e-02]],\n",
      "\n",
      "        [[ 3.0564e-02,  2.1220e-01, -1.2065e-02,  ..., -6.9893e-03,\n",
      "           1.2608e-02,  5.7594e-02],\n",
      "         [ 1.2285e-02,  4.7230e-01,  5.3952e-03,  ..., -1.2410e-02,\n",
      "          -1.4018e-02,  8.6143e-02],\n",
      "         [ 8.6029e-04, -1.2929e-01, -7.4113e-03,  ..., -9.9937e-03,\n",
      "           1.7907e-02,  3.1796e-02],\n",
      "         ...,\n",
      "         [-9.4153e-03, -1.5526e-01, -2.9062e-02,  ..., -1.3409e-02,\n",
      "           9.0988e-03,  5.8263e-02],\n",
      "         [-1.2773e-02, -1.2227e-01, -1.8716e-02,  ..., -1.2727e-02,\n",
      "          -1.6663e-02,  8.7723e-02],\n",
      "         [ 4.0471e-03, -1.4370e-01, -5.9803e-03,  ..., -5.8201e-03,\n",
      "          -1.9634e-02, -4.0605e-03]],\n",
      "\n",
      "        [[ 3.0691e-02,  2.1762e-01, -1.3922e-02,  ..., -9.9733e-03,\n",
      "           1.4927e-02,  1.2898e-01],\n",
      "         [-5.5555e-02,  6.1498e-01,  4.1801e-03,  ..., -1.4898e-02,\n",
      "          -1.8230e-02,  7.6222e-02],\n",
      "         [ 5.0211e-04,  7.2657e-02, -8.2090e-03,  ..., -2.3281e-02,\n",
      "           1.5559e-02,  1.8913e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.5562e-02,  2.0156e-01, -2.6053e-02,  ..., -2.1583e-02,\n",
      "           1.6815e-02,  1.5252e-01],\n",
      "         [-4.5216e-02,  3.9066e-01, -4.0476e-03,  ..., -3.5261e-02,\n",
      "          -2.0459e-02,  1.1167e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 6.6228e-02,  1.5767e-01, -2.6933e-02,  ..., -2.2034e-02,\n",
      "           1.6271e-02,  8.1291e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.4184e-02,  3.6389e-01, -3.0130e-02,  ..., -2.2809e-02,\n",
      "           1.8621e-02,  1.3526e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 1; Percent complete: 7.1%\n",
      "encoder outputs shape:  torch.Size([18, 64, 500])\n",
      "encoder_input_lengths:  tensor([18, 10,  9,  9,  8,  8,  8,  8,  7,  7,  6,  6,  6,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 9.5939e-04, -2.1211e-01, -2.1170e-04,  ..., -1.1241e-02,\n",
      "          -5.6203e-03, -7.3981e-02],\n",
      "         [ 9.4269e-03, -1.1980e-01,  1.2121e-03,  ..., -1.3797e-02,\n",
      "          -1.4477e-03, -7.7683e-03],\n",
      "         [ 2.2973e-03, -1.2388e-01, -6.0483e-03,  ..., -9.4622e-03,\n",
      "           2.5027e-03, -5.6302e-02],\n",
      "         ...,\n",
      "         [-1.9104e-04, -1.8688e-01, -1.0449e-02,  ..., -7.9014e-03,\n",
      "          -8.4544e-04, -1.0208e-01],\n",
      "         [-1.4013e-02, -1.3230e-01,  8.5984e-02,  ..., -1.7114e-02,\n",
      "          -6.9482e-03, -6.9290e-02],\n",
      "         [ 2.2925e-03, -1.7619e-01, -1.6239e-03,  ..., -5.2799e-03,\n",
      "          -5.4086e-03, -1.3287e-01]],\n",
      "\n",
      "        [[-3.5364e-03, -3.0765e-01,  3.3075e-03,  ..., -2.3496e-02,\n",
      "          -1.2434e-02, -1.0233e-01],\n",
      "         [ 1.6743e-02, -9.6143e-02, -3.9764e-03,  ..., -2.7051e-02,\n",
      "          -6.0189e-04, -5.4097e-03],\n",
      "         [ 5.3829e-03, -1.3192e-01, -7.6999e-03,  ..., -1.1414e-02,\n",
      "          -3.1715e-04, -1.0598e-01],\n",
      "         ...,\n",
      "         [-4.5084e-03,  4.3123e-01, -1.3121e-02,  ..., -1.2899e-02,\n",
      "          -2.1825e-03, -7.3527e-02],\n",
      "         [-1.6696e-02, -9.6071e-02,  1.7961e-01,  ..., -2.3351e-02,\n",
      "          -1.2903e-02, -6.4802e-02],\n",
      "         [ 3.4261e-03, -2.2084e-01, -2.9112e-03,  ..., -7.0147e-03,\n",
      "          -9.3688e-03, -1.7286e-01]],\n",
      "\n",
      "        [[-6.1709e-03, -1.8408e-01,  4.7440e-05,  ..., -2.6080e-02,\n",
      "          -1.6773e-02, -2.8268e-02],\n",
      "         [ 2.4710e-02, -1.3537e-01, -7.6599e-03,  ..., -3.4144e-02,\n",
      "           2.6153e-03,  3.2485e-02],\n",
      "         [ 9.2800e-03, -1.1726e-01, -9.5182e-03,  ..., -1.2789e-02,\n",
      "           2.0167e-04, -9.4105e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1828e-02, -1.9695e-02, -1.2795e-02,  ..., -7.0167e-02,\n",
      "          -2.6781e-02, -9.9818e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-9.8601e-03, -1.2440e-02, -1.2956e-02,  ..., -7.2678e-02,\n",
      "          -2.6956e-02, -6.4518e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-9.5994e-03, -3.9753e-02, -1.3189e-02,  ..., -7.3468e-02,\n",
      "          -2.7635e-02, -6.8623e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 2; Percent complete: 14.3%\n",
      "encoder outputs shape: C:\\Users\\ewais\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      " torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 9.6678e-04, -7.2489e-02, -1.2586e-03,  ..., -4.5836e-03,\n",
      "           4.2661e-03, -8.5696e-02],\n",
      "         [ 1.1690e-02, -2.7773e-02, -9.0099e-03,  ..., -9.7555e-03,\n",
      "          -1.1438e-02,  5.4798e-02],\n",
      "         [ 7.0030e-03, -2.3450e-01, -1.8584e-02,  ..., -5.6141e-03,\n",
      "          -1.3452e-02, -3.0629e-02],\n",
      "         ...,\n",
      "         [ 4.3822e-03, -1.5758e-01, -1.1591e-02,  ..., -9.2814e-03,\n",
      "           8.8729e-04, -1.3726e-01],\n",
      "         [ 9.8012e-03,  4.4622e-01, -2.1155e-03,  ..., -3.7279e-03,\n",
      "           2.5985e-03, -9.3643e-03],\n",
      "         [ 1.7847e-02,  4.5605e-01, -6.2644e-03,  ..., -4.3059e-03,\n",
      "           6.9144e-03, -5.6615e-02]],\n",
      "\n",
      "        [[ 3.2481e-04, -1.5300e-01, -5.6996e-03,  ..., -1.3077e-02,\n",
      "           2.0165e-02, -8.0149e-02],\n",
      "         [ 1.8547e-02,  5.2101e-02, -1.8214e-02,  ..., -1.8939e-02,\n",
      "          -2.3135e-02,  8.3760e-02],\n",
      "         [ 4.3949e-03, -2.7541e-01, -3.7592e-02,  ..., -1.0774e-02,\n",
      "          -4.6674e-02, -9.8207e-02],\n",
      "         ...,\n",
      "         [ 3.5611e-03,  1.3622e-01, -1.3961e-02,  ..., -1.0966e-02,\n",
      "          -4.4360e-03, -4.1334e-02],\n",
      "         [ 1.3811e-02,  3.9458e-01, -2.7505e-03,  ..., -4.6457e-03,\n",
      "           6.0436e-03, -7.4493e-02],\n",
      "         [ 2.5980e-02,  4.8036e-01, -8.7202e-03,  ..., -8.8043e-03,\n",
      "           1.4072e-02, -5.9968e-02]],\n",
      "\n",
      "        [[ 2.9868e-03, -9.1026e-02, -5.2804e-03,  ..., -2.0904e-02,\n",
      "           4.6796e-02, -5.0980e-02],\n",
      "         [ 1.1752e-02, -2.5217e-02, -2.0634e-02,  ..., -2.4171e-02,\n",
      "          -3.0357e-02,  1.9695e-01],\n",
      "         [ 1.8656e-03, -1.1675e-01, -4.7845e-02,  ..., -1.3771e-02,\n",
      "          -6.6299e-02, -9.7401e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5652e-03, -1.3913e-01,  7.8023e-03,  ..., -2.8869e-02,\n",
      "           5.6473e-02, -8.7371e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.8684e-03, -1.3608e-01,  7.4165e-03,  ..., -2.9299e-02,\n",
      "           5.4914e-02, -7.2674e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-3.3785e-03, -5.7735e-02,  5.0021e-03,  ..., -3.0156e-02,\n",
      "           5.3257e-02, -9.4730e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 3; Percent complete: 21.4%\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 8, 8, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.4385e-02,  1.2957e-01, -3.2922e-03,  ..., -9.1174e-03,\n",
      "           5.6238e-03, -5.6607e-02],\n",
      "         [ 2.2178e-02,  2.5790e-01,  1.2932e-04,  ..., -1.5033e-02,\n",
      "          -6.1767e-03, -1.2010e-01],\n",
      "         [ 8.6139e-03, -4.9224e-02, -8.9506e-03,  ...,  9.2772e-03,\n",
      "          -4.2595e-03, -1.2698e-01],\n",
      "         ...,\n",
      "         [ 7.8027e-04, -1.5018e-01, -1.5192e-03,  ..., -4.5017e-03,\n",
      "          -3.8309e-03, -7.1097e-02],\n",
      "         [-1.0435e-02, -2.2782e-02, -1.6888e-02,  ..., -3.5106e-03,\n",
      "          -8.7718e-03,  5.7949e-03],\n",
      "         [ 3.1058e-03,  1.1643e-01, -8.6387e-03,  ..., -4.5304e-03,\n",
      "          -1.0421e-02, -4.7826e-02]],\n",
      "\n",
      "        [[ 1.7843e-02,  4.4414e-02, -4.9193e-03,  ..., -1.0630e-02,\n",
      "           3.6715e-03, -1.0171e-01],\n",
      "         [ 3.0293e-02,  1.9273e-01, -2.9032e-04,  ..., -1.9017e-02,\n",
      "          -6.4744e-03, -1.3902e-01],\n",
      "         [ 1.9263e-02,  2.0916e-02, -2.1881e-02,  ...,  1.9746e-03,\n",
      "           1.6388e-02, -4.5274e-02],\n",
      "         ...,\n",
      "         [-1.3099e-02, -1.7397e-01, -2.6208e-03,  ..., -1.0703e-02,\n",
      "          -9.8747e-03, -1.0870e-01],\n",
      "         [-1.6238e-02, -7.8176e-02, -4.4503e-02,  ..., -7.1578e-03,\n",
      "           4.1128e-03,  4.9163e-02],\n",
      "         [ 2.4986e-03,  2.4783e-01, -1.2398e-02,  ..., -6.6076e-03,\n",
      "          -1.1306e-02, -3.0561e-02]],\n",
      "\n",
      "        [[ 1.5694e-02,  3.2496e-01, -1.4801e-02,  ..., -2.8211e-02,\n",
      "          -8.9103e-03, -2.2893e-02],\n",
      "         [ 2.8834e-02, -2.3794e-02, -2.2996e-03,  ..., -2.0488e-02,\n",
      "          -2.1487e-03, -1.7538e-01],\n",
      "         [ 2.4144e-02, -5.7567e-02, -3.5818e-02,  ...,  4.7800e-03,\n",
      "           1.7722e-02,  4.0658e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6301e-02,  1.7102e-02, -2.5375e-02,  ..., -4.3640e-02,\n",
      "          -6.9825e-03, -2.3761e-02],\n",
      "         [ 6.6096e-02, -4.6927e-02, -1.1402e-02,  ..., -2.4545e-02,\n",
      "          -2.5388e-02, -5.4071e-02],\n",
      "         [ 2.8429e-02, -3.0530e-01, -5.9649e-02,  ...,  1.7405e-02,\n",
      "           1.6358e-02,  1.2220e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.7206e-02, -5.3995e-02, -2.6282e-02,  ..., -4.2073e-02,\n",
      "          -1.1270e-02, -2.9252e-02],\n",
      "         [ 6.8487e-02, -8.4007e-02, -1.3925e-02,  ..., -2.6982e-02,\n",
      "          -3.0039e-02, -2.4626e-02],\n",
      "         [ 2.9493e-02, -2.9436e-01, -6.1872e-02,  ...,  1.7761e-02,\n",
      "           1.6426e-02,  1.5875e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.9495e-02, -7.5226e-02, -2.8810e-02,  ..., -3.3174e-02,\n",
      "          -1.5716e-02,  3.7373e-02],\n",
      "         [ 7.0939e-02, -7.8346e-02, -1.4733e-02,  ..., -2.8058e-02,\n",
      "          -3.3118e-02, -2.9247e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 4; Percent complete: 28.6%\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-7.4786e-03,  6.4936e-02, -5.9129e-03,  ..., -7.3985e-03,\n",
      "          -2.1284e-04, -8.8067e-02],\n",
      "         [-1.1271e-02, -1.4562e-01,  4.0832e-03,  ..., -3.5144e-03,\n",
      "          -8.1657e-03, -7.0253e-02],\n",
      "         [ 9.7536e-03,  2.1290e-01,  1.9417e-03,  ..., -1.0915e-02,\n",
      "          -1.0598e-02, -9.5658e-02],\n",
      "         ...,\n",
      "         [ 1.8697e-02,  4.7279e-01, -2.4234e-03,  ..., -1.1023e-02,\n",
      "          -1.9432e-02, -7.8467e-02],\n",
      "         [-2.6743e-02,  3.4086e-01, -3.6827e-03,  ..., -6.6237e-03,\n",
      "          -1.2227e-03,  6.4646e-02],\n",
      "         [ 2.9169e-03,  5.3864e-02,  2.0818e-03,  ..., -6.0269e-03,\n",
      "           3.1584e-03, -2.5978e-02]],\n",
      "\n",
      "        [[-9.1406e-03,  8.6444e-03, -7.7696e-03,  ..., -8.3682e-03,\n",
      "          -2.9734e-03, -6.8320e-02],\n",
      "         [-2.2217e-02, -1.9825e-01,  6.7167e-03,  ..., -3.9695e-03,\n",
      "          -1.9439e-02, -3.9312e-02],\n",
      "         [ 1.3022e-02,  2.2095e-01,  6.3768e-04,  ..., -1.3948e-02,\n",
      "          -1.4004e-02, -7.4091e-02],\n",
      "         ...,\n",
      "         [ 2.3982e-02,  5.8417e-01, -3.2923e-03,  ..., -2.0088e-02,\n",
      "          -1.9830e-02,  2.4446e-03],\n",
      "         [-6.2112e-02,  3.3710e-01, -1.3288e-02,  ..., -9.5204e-03,\n",
      "           1.2584e-03,  1.2887e-01],\n",
      "         [ 9.4465e-03,  2.3153e-01,  2.0171e-03,  ..., -8.3415e-03,\n",
      "           1.7098e-03,  6.9113e-02]],\n",
      "\n",
      "        [[-8.2591e-03, -2.9458e-02, -8.7289e-03,  ..., -8.9819e-03,\n",
      "          -5.3649e-03, -5.1670e-02],\n",
      "         [-2.8194e-02, -1.9835e-01,  6.8662e-03,  ..., -4.4201e-03,\n",
      "          -2.9915e-02, -2.4272e-02],\n",
      "         [ 1.5920e-02,  1.5740e-01, -9.6956e-04,  ..., -1.3812e-02,\n",
      "          -1.6903e-02, -4.0093e-02],\n",
      "         ...,\n",
      "         [ 2.6664e-02,  6.2330e-01, -3.8467e-03,  ..., -2.4152e-02,\n",
      "          -1.2628e-02,  3.1014e-02],\n",
      "         [-6.0544e-02,  4.7094e-01, -1.5734e-02,  ..., -1.2461e-02,\n",
      "           2.9834e-03,  1.1873e-01],\n",
      "         [ 3.3984e-02,  2.5958e-01,  1.5274e-03,  ..., -9.2656e-03,\n",
      "           2.9297e-04,  1.1423e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2715e-02,  4.1719e-02, -1.5767e-02,  ..., -1.1947e-02,\n",
      "          -6.5292e-03, -1.1900e-02],\n",
      "         [-2.8986e-02, -3.5039e-01, -1.0091e-03,  ..., -1.1133e-02,\n",
      "          -1.0874e-02, -1.0519e-01],\n",
      "         [ 2.8486e-02,  7.0906e-03, -3.1716e-03,  ..., -1.8775e-02,\n",
      "          -2.3424e-02, -7.5274e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.2478e-02,  3.7788e-01, -1.7091e-02,  ..., -1.1522e-02,\n",
      "          -7.1927e-03,  1.3406e-02],\n",
      "         [-3.7285e-02, -3.1625e-01, -3.1352e-03,  ..., -1.2863e-02,\n",
      "          -1.7392e-02, -5.2004e-02],\n",
      "         [ 3.4668e-02, -1.8906e-02, -4.4677e-03,  ..., -1.9735e-02,\n",
      "          -2.4338e-02, -3.7255e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.1705e-02,  1.9055e-01, -1.7991e-02,  ..., -1.2148e-02,\n",
      "          -8.6313e-03,  1.0166e-02],\n",
      "         [-3.8777e-02, -1.4253e-01, -4.8577e-03,  ..., -1.5114e-02,\n",
      "          -1.8449e-02, -1.4679e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 5; Percent complete: 35.7%\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-9.3833e-04,  3.2800e-01, -6.9286e-03,  ..., -5.3297e-03,\n",
      "          -2.8564e-02, -3.6483e-02],\n",
      "         [ 9.3759e-03, -1.3170e-01,  9.2909e-04,  ..., -1.1270e-02,\n",
      "          -4.5712e-03, -2.5969e-02],\n",
      "         [ 6.2155e-03, -1.7030e-01, -4.7088e-03,  ..., -4.0896e-03,\n",
      "          -9.0324e-03, -2.3892e-02],\n",
      "         ...,\n",
      "         [ 8.4836e-03, -9.3961e-02, -9.7093e-03,  ..., -2.6461e-03,\n",
      "           1.7647e-02, -7.1373e-02],\n",
      "         [ 5.1744e-03, -9.7169e-02, -5.2813e-03,  ..., -1.0150e-02,\n",
      "          -1.8999e-03,  8.9679e-04],\n",
      "         [ 1.7120e-03, -6.9837e-03, -7.8497e-03,  ..., -6.7105e-03,\n",
      "           4.6843e-04, -1.4723e-01]],\n",
      "\n",
      "        [[-9.5404e-03,  4.9461e-01, -7.8172e-03,  ..., -8.3720e-03,\n",
      "          -4.6271e-02, -4.1888e-02],\n",
      "         [ 1.2164e-02, -2.8986e-01,  1.3528e-03,  ..., -1.6192e-02,\n",
      "          -7.4082e-03,  4.6773e-02],\n",
      "         [ 5.3520e-03, -4.9662e-02, -6.7851e-03,  ..., -5.0554e-03,\n",
      "          -7.7964e-03,  4.6521e-03],\n",
      "         ...,\n",
      "         [ 1.1523e-02, -8.2251e-02, -1.1300e-02,  ..., -3.3036e-03,\n",
      "           1.8039e-02, -6.5651e-02],\n",
      "         [ 1.4631e-02, -1.5418e-01, -5.6593e-03,  ..., -3.2836e-02,\n",
      "           1.8844e-04,  1.9403e-02],\n",
      "         [ 6.0873e-03, -4.6247e-02, -1.0839e-02,  ..., -1.4406e-02,\n",
      "           1.3997e-03, -7.7411e-02]],\n",
      "\n",
      "        [[-3.1170e-03,  4.1650e-01, -1.0249e-02,  ..., -9.4564e-03,\n",
      "          -4.7471e-02, -2.0009e-02],\n",
      "         [ 1.4264e-02, -3.5028e-01, -2.7497e-03,  ..., -2.7926e-02,\n",
      "           1.4301e-02,  3.5157e-02],\n",
      "         [ 6.6131e-03, -1.1797e-01, -9.1597e-03,  ..., -5.5085e-03,\n",
      "          -2.0309e-02,  1.0150e-01],\n",
      "         ...,\n",
      "         [ 1.3647e-02, -1.0116e-01, -1.2278e-02,  ..., -4.2278e-03,\n",
      "           2.3725e-02, -6.1889e-02],\n",
      "         [ 2.6637e-02, -1.7718e-01, -4.7095e-03,  ..., -6.2860e-02,\n",
      "           5.6289e-03,  6.1280e-02],\n",
      "         [ 2.1705e-02,  3.6340e-01, -1.1375e-02,  ..., -2.5134e-02,\n",
      "           1.2671e-03,  3.7977e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.9632e-02, -3.9482e-02, -1.9374e-02,  ..., -9.1472e-03,\n",
      "          -3.7106e-02, -7.0831e-02],\n",
      "         [ 1.4432e-04, -1.9151e-01, -1.4624e-02,  ..., -3.9546e-02,\n",
      "           1.0611e-02, -6.7824e-03],\n",
      "         [ 1.0130e-02, -2.2630e-01, -1.6210e-02,  ..., -1.0126e-02,\n",
      "          -1.5569e-02,  9.6763e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.1992e-02, -1.2258e-01, -2.0562e-02,  ..., -1.1017e-02,\n",
      "          -3.7873e-02, -6.3149e-02],\n",
      "         [-6.1008e-04, -2.1591e-01, -1.4904e-02,  ..., -3.9219e-02,\n",
      "           9.4437e-03, -2.6345e-02],\n",
      "         [ 9.5985e-03, -3.2753e-01, -1.8345e-02,  ..., -1.0586e-02,\n",
      "          -1.7775e-02,  1.0435e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.5782e-02, -9.7030e-02, -2.2329e-02,  ..., -1.2253e-02,\n",
      "          -3.8924e-02, -1.1674e-02],\n",
      "         [-6.5491e-03, -1.9484e-01, -1.5446e-02,  ..., -4.2187e-02,\n",
      "           1.0620e-02, -1.1113e-02],\n",
      "         [ 9.2676e-03, -2.3607e-01, -1.9579e-02,  ..., -1.2256e-02,\n",
      "          -1.6653e-02,  1.0549e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 6; Percent complete: 42.9%\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,\n",
      "         7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-1.2611e-02, -2.1955e-01,  4.5718e-03,  ..., -1.1737e-02,\n",
      "          -1.1785e-03, -4.7291e-02],\n",
      "         [ 9.7558e-03,  1.6592e-01, -7.8938e-03,  ..., -4.1158e-03,\n",
      "          -1.0544e-02, -5.9906e-02],\n",
      "         [ 1.9881e-02,  3.4175e-01, -9.5865e-03,  ..., -7.8549e-03,\n",
      "          -1.3694e-02, -4.1409e-02],\n",
      "         ...,\n",
      "         [ 2.7694e-02, -4.1803e-02, -3.0887e-03,  ..., -1.2571e-02,\n",
      "          -1.3358e-03, -1.3986e-01],\n",
      "         [-1.9513e-03, -2.5519e-01, -1.0968e-02,  ..., -1.9346e-03,\n",
      "          -1.2575e-02, -9.1833e-03],\n",
      "         [-7.9651e-03, -1.4587e-02, -2.9825e-03,  ..., -6.3271e-03,\n",
      "          -1.1997e-02, -8.0343e-02]],\n",
      "\n",
      "        [[-1.4289e-02, -2.2105e-01,  4.9683e-03,  ..., -1.3439e-02,\n",
      "          -1.8982e-03, -7.3678e-02],\n",
      "         [ 1.6229e-02,  1.2896e-01, -1.1360e-02,  ..., -5.3060e-03,\n",
      "          -1.0136e-02,  2.0465e-03],\n",
      "         [ 4.2220e-02,  4.8212e-01, -1.4717e-02,  ..., -8.3161e-03,\n",
      "          -1.4483e-02,  3.0583e-02],\n",
      "         ...,\n",
      "         [ 3.7073e-02, -1.5618e-01, -6.3780e-03,  ..., -1.5278e-02,\n",
      "           8.8448e-04, -1.2699e-01],\n",
      "         [ 1.2889e-02, -2.9603e-01, -1.1413e-02,  ..., -1.4964e-03,\n",
      "          -3.6294e-02, -5.4109e-02],\n",
      "         [-2.2524e-02, -6.6446e-05, -4.9932e-03,  ..., -1.4436e-02,\n",
      "          -1.5307e-02, -6.6256e-02]],\n",
      "\n",
      "        [[-2.3211e-02, -2.8914e-01,  4.9717e-03,  ..., -1.4370e-02,\n",
      "          -3.1992e-03,  1.9064e-02],\n",
      "         [ 2.2760e-02,  1.2110e-01, -1.5017e-02,  ..., -6.7316e-03,\n",
      "          -1.0969e-02,  3.9041e-02],\n",
      "         [ 5.3464e-02,  5.2001e-01, -2.1271e-02,  ..., -7.7841e-03,\n",
      "          -1.6559e-02,  6.5496e-02],\n",
      "         ...,\n",
      "         [ 2.1078e-02, -1.6378e-01, -1.0858e-02,  ..., -1.7553e-02,\n",
      "           2.1221e-03, -2.0044e-01],\n",
      "         [ 1.9908e-02, -2.1855e-01, -1.8299e-02,  ..., -1.0441e-03,\n",
      "          -4.8968e-02, -4.6989e-02],\n",
      "         [-2.7424e-02, -1.9345e-03, -8.0911e-03,  ..., -1.9424e-02,\n",
      "          -1.6542e-02, -6.7244e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.0805e-02, -1.3640e-01,  8.5906e-03,  ..., -2.2959e-02,\n",
      "          -1.5709e-02, -1.0474e-01],\n",
      "         [ 5.0003e-02,  5.0123e-02, -2.1961e-02,  ..., -1.4860e-02,\n",
      "          -1.2886e-02,  7.9304e-02],\n",
      "         [ 9.7447e-02,  6.6456e-01, -5.0924e-02,  ..., -1.3022e-02,\n",
      "          -2.2125e-02,  1.8414e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-4.0969e-02, -1.4780e-01,  8.4410e-03,  ..., -2.3589e-02,\n",
      "          -1.6395e-02, -1.1401e-01],\n",
      "         [ 4.6274e-02,  1.7240e-02, -2.3638e-02,  ..., -1.5848e-02,\n",
      "          -1.2598e-02,  7.3863e-02],\n",
      "         [ 9.6344e-02,  6.2176e-01, -5.2414e-02,  ..., -1.3761e-02,\n",
      "          -2.2411e-02,  2.4970e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-3.9670e-02, -1.9087e-01,  8.0394e-03,  ..., -2.4528e-02,\n",
      "          -1.6900e-02, -5.2191e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 7; Percent complete: 50.0%\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  9,  8,  8,  8,  7,  7,  7,  7,  7,  7,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.6897e-03, -3.0396e-01, -4.6868e-03,  ...,  1.0635e-02,\n",
      "          -8.1363e-03, -8.3348e-02],\n",
      "         [-1.9142e-03, -1.2491e-01, -3.0735e-03,  ..., -2.8071e-03,\n",
      "          -3.8468e-03, -6.5988e-02],\n",
      "         [ 1.0634e-02, -1.0921e-01, -2.2103e-03,  ..., -5.5768e-03,\n",
      "           7.8406e-05, -7.6968e-02],\n",
      "         ...,\n",
      "         [-2.8700e-03, -4.3946e-03, -4.6647e-03,  ..., -3.4184e-02,\n",
      "           2.9155e-04, -9.7427e-02],\n",
      "         [ 1.0479e-03, -1.3896e-01, -4.5810e-03,  ..., -6.1529e-03,\n",
      "          -3.3448e-03, -5.6337e-02],\n",
      "         [ 1.3269e-02,  9.3002e-03, -1.9311e-02,  ..., -1.9242e-02,\n",
      "          -1.5813e-02, -1.1744e-02]],\n",
      "\n",
      "        [[ 2.7412e-03, -3.1906e-01, -1.5643e-02,  ...,  1.5384e-02,\n",
      "          -2.3026e-02, -2.4999e-02],\n",
      "         [-4.4806e-03, -2.1540e-01, -4.0675e-03,  ..., -3.7672e-03,\n",
      "          -7.9972e-03, -8.2146e-02],\n",
      "         [ 1.8677e-02, -1.6103e-01, -3.2395e-03,  ..., -7.0123e-03,\n",
      "           8.6036e-05, -8.3926e-02],\n",
      "         ...,\n",
      "         [-4.2967e-03,  8.9164e-03, -6.5723e-03,  ..., -3.6186e-02,\n",
      "          -4.9444e-03, -4.3054e-02],\n",
      "         [ 1.4428e-03, -1.5539e-01, -6.4500e-03,  ..., -9.1421e-03,\n",
      "          -4.9483e-03, -6.4626e-02],\n",
      "         [-2.5126e-02,  2.4340e-01, -2.4851e-02,  ..., -2.7575e-02,\n",
      "          -2.2074e-02,  3.9611e-02]],\n",
      "\n",
      "        [[ 2.0358e-03, -2.8333e-01, -1.7153e-02,  ...,  1.3878e-02,\n",
      "          -2.3071e-02, -1.0085e-01],\n",
      "         [-3.9021e-03, -2.5769e-01, -5.6095e-03,  ..., -4.4448e-03,\n",
      "          -1.0581e-02, -6.7108e-02],\n",
      "         [ 2.4991e-02, -2.0153e-01, -4.2588e-03,  ..., -7.6956e-03,\n",
      "           3.4505e-04, -7.6422e-02],\n",
      "         ...,\n",
      "         [ 7.5190e-04, -6.9785e-02, -8.9944e-03,  ..., -4.6614e-02,\n",
      "          -8.0641e-03, -2.6525e-02],\n",
      "         [ 2.8962e-03, -1.8167e-01, -8.1048e-03,  ..., -9.4956e-03,\n",
      "          -4.6258e-03, -6.4184e-02],\n",
      "         [-4.3154e-02,  1.3513e-01, -3.9130e-02,  ..., -2.9009e-02,\n",
      "          -3.5230e-02,  9.3749e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.9397e-03, -4.1571e-01, -3.1407e-02,  ...,  4.2968e-02,\n",
      "          -4.4168e-02, -1.0024e-01],\n",
      "         [-1.5796e-03, -2.5824e-01, -1.0466e-02,  ..., -6.8583e-03,\n",
      "          -3.5513e-02, -2.4587e-02],\n",
      "         [ 9.3296e-03,  2.1189e-02, -7.4302e-04,  ..., -2.6670e-02,\n",
      "           4.9568e-04, -6.4153e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.0995e-02, -4.0915e-01, -3.2527e-02,  ...,  4.2330e-02,\n",
      "          -4.4524e-02, -1.3357e-01],\n",
      "         [ 1.3813e-03, -2.7069e-01, -1.1230e-02,  ..., -7.5048e-03,\n",
      "          -3.8665e-02, -2.4124e-03],\n",
      "         [ 2.3758e-02, -2.0003e-02, -1.2218e-03,  ..., -3.1013e-02,\n",
      "           1.2301e-03, -1.0260e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.1835e-02, -3.8685e-01, -3.3907e-02,  ...,  3.5209e-02,\n",
      "          -4.3668e-02, -5.2611e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 8; Percent complete: 57.1%\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,\n",
      "         7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 1.7538e-04, -9.3667e-02, -6.1033e-03,  ..., -3.7372e-03,\n",
      "           1.4908e-03, -4.5946e-02],\n",
      "         [ 1.1354e-02,  4.0249e-01,  3.8924e-02,  ..., -3.6264e-02,\n",
      "           8.6698e-03, -5.9010e-02],\n",
      "         [ 6.0554e-03, -9.6503e-02,  7.6846e-02,  ..., -3.1266e-03,\n",
      "          -5.0632e-03, -5.3453e-02],\n",
      "         ...,\n",
      "         [-2.5128e-03, -2.3919e-02, -1.2168e-02,  ..., -3.3693e-03,\n",
      "          -4.9036e-03,  9.7167e-03],\n",
      "         [ 3.4305e-03,  5.5064e-02, -8.1136e-03,  ..., -8.2798e-03,\n",
      "          -1.3044e-02, -8.4351e-03],\n",
      "         [-6.4773e-03, -1.0603e-01, -1.8874e-03,  ..., -8.5487e-03,\n",
      "          -3.9923e-03, -9.5043e-02]],\n",
      "\n",
      "        [[ 4.3937e-03, -1.5677e-01, -1.1362e-02,  ..., -5.6829e-03,\n",
      "          -1.7611e-03,  2.5139e-02],\n",
      "         [ 1.6698e-02,  3.2493e-01,  3.0513e-02,  ..., -4.4043e-02,\n",
      "           5.2582e-03, -5.0008e-02],\n",
      "         [ 2.5138e-02,  2.6279e-01,  1.3080e-01,  ..., -2.2625e-02,\n",
      "          -9.9245e-04, -2.8695e-02],\n",
      "         ...,\n",
      "         [-7.4910e-03,  8.1961e-02, -2.0634e-02,  ..., -6.7490e-03,\n",
      "          -8.2307e-03,  9.2438e-02],\n",
      "         [ 5.7273e-03,  1.8642e-02, -9.7937e-03,  ..., -9.4931e-03,\n",
      "          -1.4898e-02, -9.1271e-02],\n",
      "         [-3.2745e-03, -9.8855e-02, -4.7792e-03,  ..., -9.3702e-03,\n",
      "          -1.0080e-02, -1.3666e-01]],\n",
      "\n",
      "        [[-6.9977e-05,  7.0048e-04, -1.2567e-02,  ..., -7.8617e-03,\n",
      "           5.3884e-03,  3.4058e-02],\n",
      "         [ 1.8020e-02,  3.8871e-01,  2.8777e-02,  ..., -5.1195e-02,\n",
      "           5.9846e-03, -2.0513e-02],\n",
      "         [ 2.6734e-02,  9.8893e-02,  1.3756e-01,  ..., -3.9171e-02,\n",
      "           1.9279e-05,  1.7986e-02],\n",
      "         ...,\n",
      "         [-1.6554e-02,  2.6130e-03, -2.5340e-02,  ..., -8.5143e-03,\n",
      "          -8.6842e-03,  1.2654e-01],\n",
      "         [ 7.2379e-03, -5.3143e-03, -1.0505e-02,  ..., -1.0032e-02,\n",
      "          -1.6158e-02, -1.5124e-01],\n",
      "         [-3.2616e-03, -1.0133e-01, -6.6984e-03,  ..., -1.0125e-02,\n",
      "          -1.4461e-02, -8.3300e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.4504e-03,  1.2621e-02, -1.6436e-02,  ..., -3.4733e-02,\n",
      "           4.5361e-02, -2.2065e-03],\n",
      "         [ 2.6914e-02,  4.8767e-01,  5.4952e-02,  ..., -9.1879e-02,\n",
      "           4.9182e-03, -7.5364e-02],\n",
      "         [ 3.5742e-02,  8.6168e-02,  2.3630e-01,  ..., -6.0306e-02,\n",
      "           6.2398e-04,  2.9819e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.5313e-03,  9.0170e-02, -1.6978e-02,  ..., -3.6232e-02,\n",
      "           5.1267e-02, -2.1498e-02],\n",
      "         [ 2.5067e-02,  4.5666e-01,  5.3122e-02,  ..., -9.8567e-02,\n",
      "           4.3981e-03, -5.8540e-02],\n",
      "         [ 4.2191e-02,  3.7529e-01,  2.3561e-01,  ..., -6.5414e-02,\n",
      "          -5.3424e-04, -6.7027e-04],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-7.3238e-04, -1.2247e-02, -1.7331e-02,  ..., -3.7944e-02,\n",
      "           5.1933e-02, -8.4393e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 9; Percent complete: 64.3%\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 2.6280e-03, -1.4816e-01, -2.8229e-02,  ..., -4.3255e-03,\n",
      "          -5.5410e-03, -1.3816e-01],\n",
      "         [-8.0464e-05, -1.3145e-01, -1.6429e-03,  ..., -1.4513e-02,\n",
      "          -6.0118e-03, -1.0641e-01],\n",
      "         [-3.8723e-03, -1.1370e-01, -6.4477e-03,  ..., -7.8551e-03,\n",
      "          -5.2751e-03, -5.0544e-02],\n",
      "         ...,\n",
      "         [-1.1904e-02,  5.9066e-02, -7.3632e-03,  ..., -8.1881e-03,\n",
      "          -4.3131e-03, -6.6884e-02],\n",
      "         [-6.2199e-03, -8.6975e-02, -4.9990e-06,  ..., -8.6719e-03,\n",
      "          -8.4844e-03, -1.8770e-02],\n",
      "         [ 3.9254e-03, -1.7141e-01, -3.2105e-03,  ..., -1.1657e-02,\n",
      "          -1.3165e-02, -1.0891e-01]],\n",
      "\n",
      "        [[-2.8878e-03, -2.1085e-01, -3.7530e-02,  ..., -1.1311e-02,\n",
      "           8.8623e-04,  1.2359e-02],\n",
      "         [-1.0771e-03, -1.2048e-01, -2.2682e-03,  ..., -1.7138e-02,\n",
      "          -8.0290e-03, -9.6709e-02],\n",
      "         [-1.5890e-03, -9.1949e-02, -6.8720e-03,  ..., -7.5841e-03,\n",
      "          -1.5343e-02, -6.2907e-02],\n",
      "         ...,\n",
      "         [-8.1214e-02,  2.3136e-02, -1.5727e-02,  ..., -1.2835e-02,\n",
      "          -1.0152e-02, -1.5102e-02],\n",
      "         [-4.3313e-03,  6.6487e-02,  3.1513e-03,  ..., -1.3465e-02,\n",
      "          -1.3518e-02, -3.3677e-03],\n",
      "         [ 8.6161e-03, -1.6242e-01, -6.6750e-03,  ..., -1.8981e-02,\n",
      "          -1.3999e-02, -6.4574e-02]],\n",
      "\n",
      "        [[-4.5352e-03, -1.6069e-01, -4.8015e-02,  ..., -1.5511e-02,\n",
      "           2.9019e-03,  5.2061e-02],\n",
      "         [-1.2752e-03, -9.2378e-02, -2.7998e-03,  ..., -1.8669e-02,\n",
      "          -1.1443e-02, -6.9158e-02],\n",
      "         [ 5.7567e-05, -5.1990e-02, -8.9929e-03,  ..., -8.8487e-03,\n",
      "          -2.1277e-02, -3.8994e-02],\n",
      "         ...,\n",
      "         [-9.0858e-02, -9.9690e-02, -2.1303e-02,  ..., -1.5838e-02,\n",
      "          -2.0265e-02, -2.9002e-03],\n",
      "         [-3.4734e-03, -4.9645e-02,  1.3625e-03,  ..., -1.7580e-02,\n",
      "          -1.4446e-02,  5.2910e-02],\n",
      "         [ 1.0705e-02, -1.9991e-01, -7.5661e-03,  ..., -2.3084e-02,\n",
      "          -2.5092e-02, -5.3577e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.7960e-03, -2.8487e-01, -7.5907e-02,  ..., -2.4214e-02,\n",
      "           6.1327e-03, -2.8107e-02],\n",
      "         [-1.9413e-02, -1.2649e-01, -6.7187e-03,  ..., -2.2281e-02,\n",
      "          -3.4079e-02, -2.1378e-02],\n",
      "         [-2.2373e-03,  6.6017e-02, -9.8299e-03,  ..., -9.8252e-03,\n",
      "          -3.2738e-02, -4.8818e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-4.3277e-03, -2.5076e-01, -7.8743e-02,  ..., -2.6196e-02,\n",
      "           7.1503e-03,  1.0863e-02],\n",
      "         [-1.9638e-02, -1.5534e-01, -7.2125e-03,  ..., -2.1273e-02,\n",
      "          -3.8795e-02,  2.4652e-02],\n",
      "         [-2.5552e-03,  1.3220e-03, -1.0244e-02,  ..., -1.1316e-02,\n",
      "          -3.4695e-02, -2.5390e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.5295e-03, -2.5753e-01, -8.0793e-02,  ..., -2.6882e-02,\n",
      "           7.5407e-03,  6.6545e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 10; Percent complete: 71.4%\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-2.1246e-02,  5.4603e-03, -4.6403e-03,  ..., -1.9318e-02,\n",
      "           2.1998e-03, -1.4856e-01],\n",
      "         [-5.7455e-02,  1.7555e-01, -5.6511e-03,  ..., -3.7006e-03,\n",
      "          -1.4778e-02,  1.5573e-02],\n",
      "         [ 1.3279e-02,  1.9549e-01,  3.3522e-02,  ..., -5.1849e-03,\n",
      "          -4.2842e-03, -5.9705e-02],\n",
      "         ...,\n",
      "         [-5.6875e-03, -8.7309e-02, -6.2782e-03,  ..., -7.1209e-03,\n",
      "           7.1115e-03, -5.8244e-02],\n",
      "         [ 1.4838e-02,  6.9662e-02, -2.0159e-03,  ..., -5.5440e-03,\n",
      "           3.4149e-04, -2.3866e-02],\n",
      "         [ 7.0217e-03,  2.5347e-01, -1.8043e-03,  ..., -8.4429e-03,\n",
      "           2.4947e-02,  1.5962e-02]],\n",
      "\n",
      "        [[-2.3795e-02,  5.2851e-02, -8.0218e-03,  ..., -3.0123e-02,\n",
      "           9.6223e-04, -1.4462e-01],\n",
      "         [-9.3152e-02,  2.8641e-01, -5.5592e-03,  ..., -5.0280e-03,\n",
      "          -1.9729e-02,  9.1317e-02],\n",
      "         [ 1.7370e-02,  2.4781e-01,  3.3230e-02,  ..., -1.0418e-02,\n",
      "          -8.3220e-03,  1.0781e-02],\n",
      "         ...,\n",
      "         [-4.1338e-02,  6.6505e-02, -7.4832e-03,  ..., -9.4359e-03,\n",
      "           6.3593e-03, -1.1512e-01],\n",
      "         [ 1.9406e-02, -7.0213e-02, -5.5078e-03,  ..., -6.7243e-03,\n",
      "          -1.5441e-02, -2.7604e-02],\n",
      "         [ 1.1384e-02,  2.1417e-01, -3.4386e-03,  ..., -1.0714e-02,\n",
      "           2.8160e-02, -9.4286e-03]],\n",
      "\n",
      "        [[-1.8124e-02,  4.3915e-02, -1.1873e-02,  ..., -3.6989e-02,\n",
      "           3.3502e-04, -1.2367e-01],\n",
      "         [-9.3547e-02,  1.9453e-01, -7.4090e-03,  ..., -6.2571e-03,\n",
      "          -2.3882e-02,  9.8150e-02],\n",
      "         [ 2.9605e-02,  2.5696e-01,  3.1509e-02,  ..., -1.1715e-02,\n",
      "          -9.6234e-03, -6.6816e-03],\n",
      "         ...,\n",
      "         [-3.0568e-02,  3.5066e-01, -8.0628e-03,  ..., -1.2476e-02,\n",
      "           6.9104e-03, -4.2310e-02],\n",
      "         [ 2.7477e-02,  6.2509e-02, -6.8202e-03,  ..., -8.2491e-03,\n",
      "          -3.4818e-02,  9.3782e-02],\n",
      "         [ 2.6491e-02,  3.2953e-01, -3.7408e-03,  ..., -1.3416e-02,\n",
      "           3.8392e-02,  1.1828e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.3018e-02,  2.3397e-01, -2.0830e-02,  ..., -4.5198e-02,\n",
      "          -9.3029e-03,  9.3940e-02],\n",
      "         [-5.7379e-02,  2.5124e-01, -1.3114e-02,  ..., -1.0776e-02,\n",
      "          -4.4889e-02,  1.1345e-01],\n",
      "         [ 4.4118e-02,  4.0534e-01,  2.4553e-02,  ..., -1.9559e-02,\n",
      "          -2.2038e-02,  6.8317e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.6475e-02,  1.6183e-01, -2.3431e-02,  ..., -4.6746e-02,\n",
      "          -9.3214e-03,  7.4011e-02],\n",
      "         [-5.2981e-02,  3.1400e-01, -1.3464e-02,  ..., -1.2357e-02,\n",
      "          -4.8484e-02,  1.0049e-01],\n",
      "         [ 4.2832e-02,  4.0337e-01,  2.4246e-02,  ..., -2.0744e-02,\n",
      "          -2.3197e-02,  4.4096e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.8670e-02,  1.1431e-01, -2.7049e-02,  ..., -4.9960e-02,\n",
      "          -4.1465e-03,  3.3860e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 11; Percent complete: 78.6%\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 10,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0026, -0.0512, -0.0066,  ..., -0.0034, -0.0006, -0.0150],\n",
      "         [ 0.0004, -0.1123, -0.0052,  ..., -0.0034, -0.0071, -0.0349],\n",
      "         [ 0.0016,  0.0009, -0.0028,  ..., -0.0077,  0.0043,  0.0017],\n",
      "         ...,\n",
      "         [-0.0052,  0.0083, -0.0062,  ..., -0.0361, -0.0128, -0.0016],\n",
      "         [-0.0363, -0.0838, -0.0032,  ..., -0.0464, -0.0036, -0.0041],\n",
      "         [ 0.0046, -0.2042, -0.0007,  ..., -0.0059, -0.0098, -0.1238]],\n",
      "\n",
      "        [[ 0.0058, -0.0922, -0.0094,  ..., -0.0048, -0.0030, -0.0138],\n",
      "         [ 0.0019, -0.2296, -0.0067,  ..., -0.0055, -0.0099,  0.0007],\n",
      "         [ 0.0030, -0.0439, -0.0032,  ..., -0.0094,  0.0024, -0.0392],\n",
      "         ...,\n",
      "         [-0.0026, -0.0648, -0.0085,  ..., -0.0439, -0.0138,  0.0655],\n",
      "         [-0.0353, -0.0552, -0.0044,  ..., -0.0497, -0.0061,  0.0167],\n",
      "         [ 0.0042, -0.2717, -0.0016,  ..., -0.0073, -0.0154, -0.0871]],\n",
      "\n",
      "        [[ 0.0079, -0.1038, -0.0114,  ..., -0.0057, -0.0043, -0.0154],\n",
      "         [ 0.0055, -0.1157, -0.0105,  ..., -0.0081, -0.0097,  0.0107],\n",
      "         [ 0.0041, -0.0568, -0.0043,  ..., -0.0061, -0.0057, -0.0472],\n",
      "         ...,\n",
      "         [ 0.0012, -0.1060, -0.0082,  ..., -0.0465, -0.0159,  0.0885],\n",
      "         [-0.0326,  0.0530, -0.0047,  ..., -0.0711, -0.0063, -0.0171],\n",
      "         [ 0.0112, -0.0923, -0.0021,  ..., -0.0135, -0.0177, -0.0951]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0185, -0.1455, -0.0212,  ..., -0.0131, -0.0269, -0.0206],\n",
      "         [ 0.0111,  0.0657, -0.0269,  ..., -0.0208, -0.0067,  0.1749],\n",
      "         [ 0.0071, -0.1517, -0.0013,  ..., -0.0712, -0.0118, -0.0907],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0192, -0.1842, -0.0226,  ..., -0.0137, -0.0309, -0.0078],\n",
      "         [ 0.0120, -0.0290, -0.0304,  ..., -0.0229, -0.0067,  0.2342],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0216, -0.0298, -0.0247,  ..., -0.0177, -0.0391,  0.0066],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 12; Percent complete: 85.7%\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,\n",
      "         7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-2.6453e-03,  2.5822e-02, -3.4742e-03,  ..., -1.7755e-03,\n",
      "          -5.6119e-03, -1.6636e-02],\n",
      "         [ 4.1737e-02,  8.4534e-02, -3.4521e-03,  ..., -3.2003e-03,\n",
      "          -6.5246e-02, -7.5369e-02],\n",
      "         [ 1.1164e-02, -4.4261e-02,  1.7555e-03,  ..., -7.8713e-03,\n",
      "          -2.3129e-03, -7.2691e-02],\n",
      "         ...,\n",
      "         [ 1.4109e-02,  3.2316e-01, -3.3728e-03,  ..., -9.9175e-03,\n",
      "          -1.1198e-03, -2.4234e-02],\n",
      "         [ 3.0676e-03,  7.6750e-02, -7.5090e-03,  ..., -4.0819e-03,\n",
      "           7.5078e-03, -4.7097e-02],\n",
      "         [ 3.3466e-03,  1.6110e-01, -7.3711e-03,  ..., -2.0848e-03,\n",
      "          -3.4221e-03, -9.0050e-02]],\n",
      "\n",
      "        [[-1.1187e-02,  1.6699e-01, -5.3838e-03,  ..., -4.5453e-03,\n",
      "          -6.2518e-03,  5.7075e-03],\n",
      "         [ 7.1359e-02, -4.6562e-02, -6.6617e-03,  ..., -1.2033e-02,\n",
      "          -6.5590e-02, -1.5724e-01],\n",
      "         [ 1.3261e-02, -9.5980e-02,  1.5678e-04,  ..., -9.3103e-03,\n",
      "          -6.3320e-03, -6.2593e-02],\n",
      "         ...,\n",
      "         [ 1.6336e-02,  2.5775e-01, -4.7605e-03,  ..., -2.1466e-02,\n",
      "          -2.5243e-03,  9.6411e-03],\n",
      "         [ 2.2656e-03, -7.6480e-02, -8.7065e-03,  ..., -6.9835e-03,\n",
      "           6.4278e-03, -5.4159e-02],\n",
      "         [ 2.5786e-03,  3.1491e-01, -1.8978e-02,  ..., -3.7092e-03,\n",
      "          -1.1956e-02, -1.0090e-01]],\n",
      "\n",
      "        [[-7.2053e-02,  5.2597e-02, -1.2529e-02,  ..., -5.3314e-03,\n",
      "          -9.2762e-03,  3.7828e-02],\n",
      "         [ 9.5806e-02, -1.4979e-02, -7.7427e-03,  ..., -1.8527e-02,\n",
      "          -6.2560e-02, -1.8178e-01],\n",
      "         [ 1.1878e-02, -1.0505e-01,  9.8097e-04,  ..., -1.0363e-02,\n",
      "          -5.7869e-03, -5.2261e-02],\n",
      "         ...,\n",
      "         [ 1.6459e-02,  1.9024e-01, -6.1749e-03,  ..., -2.3419e-02,\n",
      "          -2.6725e-03,  2.9736e-02],\n",
      "         [ 3.0060e-03, -1.2810e-01, -1.1464e-02,  ..., -9.7603e-03,\n",
      "           5.6256e-03, -3.2744e-02],\n",
      "         [-4.5292e-03,  2.1335e-01, -2.2215e-02,  ..., -4.6087e-03,\n",
      "          -1.7047e-02, -8.2853e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.4327e-02,  6.4259e-01, -1.9266e-02,  ..., -1.1795e-02,\n",
      "          -1.8868e-02,  6.7913e-02],\n",
      "         [ 8.8303e-02, -1.3172e-01, -1.8699e-02,  ..., -2.6116e-02,\n",
      "          -8.9959e-02,  9.0327e-03],\n",
      "         [ 3.2454e-02, -4.1464e-02, -1.8010e-03,  ..., -5.5552e-02,\n",
      "          -1.7920e-02,  1.3045e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.6419e-02,  7.6985e-01, -2.0962e-02,  ..., -1.3571e-02,\n",
      "          -2.1217e-02,  7.9577e-02],\n",
      "         [ 5.8747e-02, -3.9403e-02, -2.2448e-02,  ..., -2.6816e-02,\n",
      "          -9.0318e-02, -4.9175e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.0325e-02,  8.1475e-01, -2.2367e-02,  ..., -1.4884e-02,\n",
      "          -2.3490e-02,  8.9594e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 13; Percent complete: 92.9%\n",
      "encoder outputs shape:  torch.Size([7, 8, 500])\n",
      "encoder_input_lengths:  tensor([7, 7, 6, 6, 6, 6, 5, 4], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-2.6338e-03,  1.9060e-01, -1.5879e-02,  ..., -6.7704e-03,\n",
      "          -1.4790e-02, -3.2273e-02],\n",
      "         [ 8.8506e-04, -1.3395e-01, -5.4358e-03,  ..., -4.6060e-03,\n",
      "          -4.5591e-03,  2.7136e-02],\n",
      "         [ 6.4719e-03, -2.9126e-01, -3.2908e-03,  ...,  2.6709e-04,\n",
      "           2.9954e-03, -1.3428e-01],\n",
      "         ...,\n",
      "         [ 6.1481e-02,  1.4264e-01, -3.5557e-02,  ..., -9.1317e-03,\n",
      "           1.5318e-02, -6.3997e-02],\n",
      "         [ 2.0913e-02,  2.0843e-01, -3.2410e-03,  ..., -1.9727e-02,\n",
      "           1.0822e-02, -8.1569e-02],\n",
      "         [-2.8261e-02,  1.8494e-01, -2.1500e-03,  ..., -1.4195e-02,\n",
      "          -4.1633e-03, -4.6323e-02]],\n",
      "\n",
      "        [[-6.5133e-03,  1.9999e-01, -2.0502e-02,  ..., -7.6137e-03,\n",
      "          -1.8623e-02, -2.1915e-02],\n",
      "         [ 4.0039e-03, -1.6711e-01, -6.8322e-03,  ..., -5.4002e-03,\n",
      "          -6.4176e-03,  1.9891e-03],\n",
      "         [-9.7877e-03, -2.6816e-01, -4.7013e-03,  ...,  3.3652e-04,\n",
      "           5.9583e-04, -1.2823e-01],\n",
      "         ...,\n",
      "         [ 5.7713e-02,  9.0717e-02, -4.4460e-02,  ..., -1.1531e-02,\n",
      "           4.2010e-03, -4.8639e-02],\n",
      "         [ 2.9111e-02,  2.2669e-01, -5.0909e-03,  ..., -2.4446e-02,\n",
      "           1.5543e-02, -1.8786e-02],\n",
      "         [-2.7491e-02,  1.1408e-01, -3.3171e-03,  ..., -1.8362e-02,\n",
      "          -5.8894e-03,  1.7955e-02]],\n",
      "\n",
      "        [[-1.0884e-02,  1.8776e-01, -2.1182e-02,  ..., -8.0124e-03,\n",
      "          -2.2520e-02,  1.7310e-02],\n",
      "         [ 5.2384e-03, -1.7620e-01, -9.3394e-03,  ..., -5.4390e-03,\n",
      "          -9.5284e-03, -7.0483e-02],\n",
      "         [-1.4937e-02, -1.9957e-01, -5.7583e-03,  ...,  2.1311e-05,\n",
      "          -5.1963e-04, -1.0622e-01],\n",
      "         ...,\n",
      "         [ 5.4759e-02,  5.1825e-02, -5.1463e-02,  ..., -1.2470e-02,\n",
      "           8.1390e-03, -9.3072e-02],\n",
      "         [ 3.2523e-02,  9.2118e-02, -6.0536e-03,  ..., -3.1083e-02,\n",
      "           1.6845e-02,  3.0081e-02],\n",
      "         [-2.9588e-02,  1.9634e-02, -4.4349e-03,  ..., -1.8708e-02,\n",
      "          -7.6055e-03,  6.3765e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2881e-02,  1.0678e-01, -3.0114e-02,  ..., -9.2153e-03,\n",
      "          -3.2509e-02,  4.1574e-02],\n",
      "         [ 5.4675e-03, -2.1960e-01, -1.4364e-02,  ..., -9.3700e-03,\n",
      "          -1.6863e-02, -5.1353e-03],\n",
      "         [-2.7357e-02, -3.5203e-01, -7.4357e-03,  ...,  4.5482e-04,\n",
      "           5.0110e-04, -1.2373e-01],\n",
      "         ...,\n",
      "         [ 6.2984e-02,  5.4596e-02, -6.5285e-02,  ..., -1.5512e-02,\n",
      "           3.5052e-02,  4.3066e-02],\n",
      "         [ 4.2510e-02,  4.3017e-02, -7.6634e-03,  ..., -3.5911e-02,\n",
      "           1.9402e-02,  5.3762e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.5561e-02,  2.3292e-01, -3.4170e-02,  ..., -1.0062e-02,\n",
      "          -3.2613e-02,  7.2638e-02],\n",
      "         [ 6.5436e-03, -2.0934e-01, -1.5725e-02,  ..., -1.0825e-02,\n",
      "          -1.7332e-02, -3.3298e-02],\n",
      "         [-3.1744e-02, -3.3862e-01, -8.8082e-03,  ...,  4.5148e-04,\n",
      "          -2.5751e-03, -5.4141e-02],\n",
      "         ...,\n",
      "         [ 6.1957e-02,  2.8547e-02, -6.6161e-02,  ..., -1.6019e-02,\n",
      "           3.6289e-02,  5.6999e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.2127e-02,  3.5759e-01, -3.5754e-02,  ..., -1.1222e-02,\n",
      "          -2.2083e-02,  6.3206e-02],\n",
      "         [ 7.3980e-03, -2.0593e-01, -1.6424e-02,  ..., -1.2425e-02,\n",
      "          -1.9098e-02, -2.6066e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 14; Percent complete: 100.0%\n",
      "Validation set accuracy: 50.00%\n",
      "Validation accuracy better than current best; saving model...\n",
      "encoder outputs shape:  torch.Size([9, 12, 500])\n",
      "encoder_input_lengths:  tensor([9, 8, 7, 7, 6, 5, 5, 4, 4, 4, 4, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 2.0560e-03, -8.9928e-02, -4.4307e-03,  ..., -7.3075e-03,\n",
      "          -1.1885e-03, -9.7203e-03],\n",
      "         [ 4.9526e-03,  1.7610e-01, -2.0155e-03,  ..., -4.4814e-03,\n",
      "          -1.2961e-02, -1.0532e-01],\n",
      "         [-1.2248e-02, -1.4702e-01, -2.0133e-03,  ..., -1.0061e-02,\n",
      "          -1.8345e-03, -3.9245e-04],\n",
      "         ...,\n",
      "         [ 5.4787e-03, -9.1413e-02,  1.5297e-03,  ..., -2.0921e-02,\n",
      "           8.3665e-03, -5.1373e-02],\n",
      "         [-1.0284e-01,  4.2169e-01, -1.6407e-02,  ..., -1.5874e-02,\n",
      "          -7.5489e-02, -1.0855e-01],\n",
      "         [ 7.4268e-03,  1.5282e-01, -2.9578e-03,  ..., -4.5524e-03,\n",
      "          -6.8666e-03, -2.2625e-02]],\n",
      "\n",
      "        [[ 6.8727e-03, -1.1738e-01, -7.4677e-03,  ..., -9.7333e-03,\n",
      "          -2.1481e-03, -1.9725e-03],\n",
      "         [ 8.6895e-02,  4.6317e-01, -3.1364e-03,  ..., -4.4971e-03,\n",
      "          -1.8932e-02, -8.1003e-02],\n",
      "         [ 1.6891e-02, -2.1740e-01, -5.5976e-03,  ..., -1.5911e-03,\n",
      "           1.9622e-03,  8.4319e-02],\n",
      "         ...,\n",
      "         [ 1.2234e-02, -2.5179e-01,  3.4783e-04,  ..., -5.0303e-02,\n",
      "           1.9212e-02, -6.8727e-02],\n",
      "         [-1.2653e-01,  1.3068e-01, -4.0174e-02,  ..., -1.9811e-02,\n",
      "          -6.8567e-02, -1.4705e-01],\n",
      "         [-2.6900e-02,  1.3300e-01, -1.1242e-02,  ..., -9.1522e-03,\n",
      "          -1.2523e-02,  1.8087e-02]],\n",
      "\n",
      "        [[ 3.4329e-02,  2.0972e-02, -1.0324e-02,  ..., -1.4085e-02,\n",
      "          -5.2765e-03,  3.1175e-02],\n",
      "         [ 1.1455e-01,  4.1897e-01, -2.9153e-03,  ..., -6.0017e-03,\n",
      "          -2.2083e-02, -1.6169e-02],\n",
      "         [ 1.9256e-02, -2.4829e-01, -6.6246e-03,  ..., -1.2640e-02,\n",
      "           5.8791e-04,  1.9287e-01],\n",
      "         ...,\n",
      "         [ 1.7230e-02, -1.3978e-01, -4.0711e-03,  ..., -6.7909e-02,\n",
      "           2.5952e-02, -3.0949e-03],\n",
      "         [-1.3028e-01,  2.3304e-01, -4.2706e-02,  ..., -2.5420e-02,\n",
      "          -7.6082e-02, -1.8494e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.2238e-02,  8.1757e-02, -3.4618e-02,  ..., -2.6691e-02,\n",
      "          -5.0129e-03,  5.7490e-02],\n",
      "         [ 1.5696e-01,  1.3372e-01, -6.0761e-03,  ..., -2.2093e-02,\n",
      "          -3.5945e-02, -1.5808e-01],\n",
      "         [ 5.5984e-03, -1.0507e-01, -1.2391e-02,  ..., -2.6247e-02,\n",
      "          -6.0555e-03,  1.0340e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.3848e-02,  2.5548e-02, -3.6046e-02,  ..., -2.7428e-02,\n",
      "          -5.9044e-03,  2.8153e-02],\n",
      "         [ 1.6246e-01,  1.7894e-01, -1.4554e-03,  ..., -2.3568e-02,\n",
      "          -3.7789e-02, -1.0646e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.5149e-02,  1.2058e-02, -3.6698e-02,  ..., -2.7737e-02,\n",
      "          -6.4540e-03, -5.9982e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 40; Percent complete: 3.4%; Average loss: 0.6941\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0213,  0.1161, -0.0049,  ..., -0.0069, -0.0190, -0.1513],\n",
      "         [-0.0239,  0.0033, -0.0065,  ..., -0.0077,  0.0066, -0.0610],\n",
      "         [-0.0356, -0.0067, -0.0101,  ..., -0.0057, -0.0036,  0.0056],\n",
      "         ...,\n",
      "         [-0.0003, -0.0392, -0.0023,  ..., -0.0025, -0.0105, -0.0647],\n",
      "         [ 0.0020, -0.1149, -0.0155,  ..., -0.0057, -0.0105,  0.0251],\n",
      "         [-0.0004, -0.0532, -0.0037,  ..., -0.0412,  0.0179,  0.0559]],\n",
      "\n",
      "        [[ 0.0249,  0.1146, -0.0056,  ..., -0.0082, -0.0236, -0.1422],\n",
      "         [-0.0265, -0.0018, -0.0084,  ..., -0.0103,  0.0081, -0.0070],\n",
      "         [-0.0514, -0.0435, -0.0121,  ..., -0.0082, -0.0060,  0.0778],\n",
      "         ...,\n",
      "         [ 0.0033, -0.1021, -0.0032,  ..., -0.0037, -0.0148, -0.0298],\n",
      "         [ 0.0016, -0.1725, -0.0186,  ..., -0.0076, -0.0106,  0.0314],\n",
      "         [ 0.0085, -0.1915, -0.0097,  ..., -0.0501,  0.0218,  0.0675]],\n",
      "\n",
      "        [[ 0.0288,  0.1164, -0.0063,  ..., -0.0088, -0.0229, -0.1180],\n",
      "         [-0.0249,  0.0232, -0.0103,  ..., -0.0123,  0.0095, -0.0006],\n",
      "         [-0.0251, -0.0056, -0.0127,  ..., -0.0114, -0.0077,  0.0409],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0356,  0.0461, -0.0241,  ..., -0.0134, -0.0246, -0.0652],\n",
      "         [-0.0244,  0.0008, -0.0359,  ..., -0.0292,  0.0140, -0.0363],\n",
      "         [-0.1812, -0.1161, -0.0125,  ..., -0.0284, -0.0252,  0.0463],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0338,  0.0631, -0.0315,  ..., -0.0139, -0.0251, -0.0859],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0325,  0.0172, -0.0358,  ..., -0.0152, -0.0336, -0.1631],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 11, 10,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0033, -0.0275, -0.0015,  ..., -0.0013,  0.0122, -0.0542],\n",
      "         [ 0.0240, -0.1924,  0.0084,  ..., -0.0080,  0.0163, -0.0511],\n",
      "         [-0.1309,  0.2449, -0.0091,  ..., -0.0034, -0.0057,  0.0538],\n",
      "         ...,\n",
      "         [ 0.0053, -0.1036, -0.0026,  ..., -0.0079, -0.0283, -0.0970],\n",
      "         [-0.0043, -0.1355,  0.0066,  ..., -0.0115, -0.0085, -0.0521],\n",
      "         [ 0.0048, -0.2033, -0.0119,  ..., -0.0057, -0.0114, -0.0907]],\n",
      "\n",
      "        [[ 0.0074, -0.0109, -0.0017,  ..., -0.0041,  0.0184, -0.0916],\n",
      "         [ 0.0235, -0.2307,  0.0045,  ..., -0.0089,  0.0108, -0.0220],\n",
      "         [-0.1023,  0.1376, -0.0145,  ..., -0.0047, -0.0067,  0.0949],\n",
      "         ...,\n",
      "         [ 0.0046,  0.0347, -0.0052,  ..., -0.0101, -0.0395, -0.1540],\n",
      "         [-0.0034, -0.2068,  0.0005,  ..., -0.0168, -0.0139, -0.0209],\n",
      "         [ 0.0010, -0.2072, -0.0312,  ..., -0.0077, -0.0142, -0.0876]],\n",
      "\n",
      "        [[ 0.0082, -0.0878, -0.0035,  ..., -0.0052,  0.0239, -0.0917],\n",
      "         [ 0.0247, -0.2123,  0.0037,  ..., -0.0093,  0.0081,  0.0081],\n",
      "         [-0.0713,  0.2173, -0.0180,  ..., -0.0069, -0.0138,  0.1534],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0192, -0.0147, -0.0102,  ..., -0.0238,  0.0559,  0.0643],\n",
      "         [ 0.0220, -0.1591,  0.0009,  ..., -0.0152, -0.0092,  0.0533],\n",
      "         [-0.0746,  0.1292, -0.0315,  ..., -0.0242, -0.0196, -0.0779],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0217, -0.0717, -0.0115,  ..., -0.0303,  0.0599,  0.0363],\n",
      "         [ 0.0214, -0.1567,  0.0004,  ..., -0.0160, -0.0096,  0.0587],\n",
      "         [-0.0731,  0.0664, -0.0350,  ..., -0.0251, -0.0243, -0.0574],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0212, -0.1256, -0.0121,  ..., -0.0339,  0.0600, -0.0009],\n",
      "         [ 0.0199, -0.1888, -0.0005,  ..., -0.0170, -0.0102,  0.0388],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 9, 9, 8, 8, 8, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0154,  0.0584, -0.0071,  ..., -0.0024, -0.0178, -0.0706],\n",
      "         [ 0.0012, -0.1544, -0.0041,  ..., -0.0037, -0.0029, -0.1136],\n",
      "         [-0.0050,  0.3078, -0.0012,  ..., -0.0058, -0.0053, -0.1337],\n",
      "         ...,\n",
      "         [ 0.0306, -0.2841,  0.3190,  ..., -0.0057, -0.0283, -0.0689],\n",
      "         [-0.0065, -0.1411, -0.0057,  ..., -0.0059,  0.0032, -0.0922],\n",
      "         [ 0.0018, -0.1254, -0.0090,  ..., -0.0062, -0.0074, -0.0290]],\n",
      "\n",
      "        [[ 0.0085,  0.0142, -0.0129,  ..., -0.0046, -0.0263, -0.0534],\n",
      "         [ 0.0012, -0.1817, -0.0051,  ..., -0.0052, -0.0055, -0.1635],\n",
      "         [ 0.0054,  0.3509, -0.0022,  ..., -0.0093, -0.0060, -0.0761],\n",
      "         ...,\n",
      "         [ 0.0379, -0.2747,  0.4288,  ..., -0.0071, -0.0309, -0.0562],\n",
      "         [-0.0253, -0.1470, -0.0055,  ..., -0.0163,  0.0044, -0.0970],\n",
      "         [-0.0137,  0.2653, -0.0118,  ..., -0.0108, -0.0108,  0.0377]],\n",
      "\n",
      "        [[ 0.0153,  0.0732, -0.0138,  ..., -0.0050, -0.0304, -0.0052],\n",
      "         [ 0.0036, -0.2482, -0.0135,  ..., -0.0094, -0.0045, -0.1682],\n",
      "         [ 0.0246,  0.3934, -0.0031,  ..., -0.0160, -0.0102, -0.0718],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0144, -0.0964, -0.0161,  ..., -0.0066, -0.0519,  0.0138],\n",
      "         [ 0.0090, -0.2172, -0.0165,  ..., -0.0127, -0.0094, -0.3418],\n",
      "         [ 0.0366,  0.3516, -0.0123,  ..., -0.0251, -0.0046, -0.0006],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0122, -0.1090, -0.0166,  ..., -0.0068, -0.0566,  0.0488],\n",
      "         [ 0.0095, -0.2077, -0.0167,  ..., -0.0131, -0.0104, -0.3257],\n",
      "         [ 0.0430,  0.3292, -0.0137,  ..., -0.0346,  0.0127, -0.0859],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0146, -0.1412, -0.0182,  ..., -0.0090, -0.0581,  0.0066],\n",
      "         [ 0.0098, -0.1860, -0.0168,  ..., -0.0135, -0.0119, -0.3257],\n",
      "         [ 0.0445,  0.2779, -0.0143,  ..., -0.0351,  0.0127, -0.1523],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([14, 64, 500])\n",
      "encoder_input_lengths:  tensor([14, 10,  9,  9,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  3,  3,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0177, -0.1454, -0.0036,  ..., -0.0050, -0.0096, -0.0861],\n",
      "         [ 0.0122, -0.0933, -0.0081,  ..., -0.0074,  0.0057,  0.0545],\n",
      "         [ 0.0359, -0.0256, -0.0079,  ..., -0.0146,  0.0025, -0.0400],\n",
      "         ...,\n",
      "         [ 0.0211,  0.1439, -0.0035,  ..., -0.0050, -0.0059,  0.0471],\n",
      "         [-0.0011, -0.0583, -0.0060,  ..., -0.0069, -0.0071, -0.0363],\n",
      "         [ 0.0036,  0.1303, -0.0021,  ..., -0.0057,  0.0031, -0.0556]],\n",
      "\n",
      "        [[ 0.0096, -0.0537, -0.0152,  ..., -0.0065, -0.0208, -0.0914],\n",
      "         [ 0.0365, -0.0155, -0.0117,  ..., -0.0116,  0.0076, -0.0159],\n",
      "         [ 0.0452,  0.0167, -0.0120,  ..., -0.0164,  0.0074,  0.0314],\n",
      "         ...,\n",
      "         [-0.0277,  0.2893, -0.0052,  ..., -0.0124, -0.0049,  0.2208],\n",
      "         [-0.0018, -0.1401, -0.0080,  ..., -0.0132, -0.0075,  0.0452],\n",
      "         [ 0.0044,  0.0281, -0.0034,  ..., -0.0073,  0.0063, -0.0433]],\n",
      "\n",
      "        [[ 0.0114, -0.0534, -0.0166,  ..., -0.0072, -0.0227, -0.0909],\n",
      "         [ 0.0756, -0.1986, -0.0114,  ..., -0.0165,  0.0132,  0.0020],\n",
      "         [ 0.0487, -0.0432, -0.0161,  ..., -0.0194,  0.0101,  0.0965],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0041, -0.0024, -0.0462,  ..., -0.0189, -0.0571, -0.0038],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0127, -0.0006, -0.0421,  ..., -0.0177, -0.0623,  0.0209],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0164, -0.0155, -0.0479,  ..., -0.0168, -0.0651,  0.0828],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,\n",
      "         6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,\n",
      "         3,  3,  3,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 9.3729e-03, -3.5161e-02, -1.2480e-03,  ..., -3.7244e-03,\n",
      "          -3.3535e-03, -4.6962e-02],\n",
      "         [ 6.9284e-03, -2.8957e-02, -1.9397e-03,  ..., -3.2399e-03,\n",
      "          -5.7388e-03, -2.1069e-02],\n",
      "         [ 5.6024e-03, -3.4883e-02, -4.2030e-03,  ..., -4.8662e-03,\n",
      "          -1.6568e-02, -2.7000e-03],\n",
      "         ...,\n",
      "         [ 3.0632e-03, -1.9152e-01, -4.3850e-03,  ..., -9.5475e-03,\n",
      "           4.1961e-03, -1.2550e-01],\n",
      "         [-5.9637e-04, -2.1640e-01, -5.3151e-03,  ..., -1.3218e-02,\n",
      "          -4.8161e-02, -1.6526e-01],\n",
      "         [-1.2616e-02, -1.0082e-01, -9.1901e-03,  ..., -1.2608e-02,\n",
      "          -2.4574e-02, -1.0268e-01]],\n",
      "\n",
      "        [[ 1.9925e-02, -1.1753e-01, -1.8892e-03,  ..., -5.2805e-03,\n",
      "          -5.0444e-03,  3.3486e-02],\n",
      "         [-1.0794e-02,  1.0472e-01, -4.4074e-03,  ..., -6.2167e-03,\n",
      "          -1.0034e-03,  6.5208e-02],\n",
      "         [ 1.5474e-02,  1.3099e-01, -6.0100e-03,  ..., -9.3202e-03,\n",
      "          -2.8120e-02, -1.2982e-03],\n",
      "         ...,\n",
      "         [-2.9922e-03, -2.9337e-01, -8.7888e-03,  ..., -1.1891e-02,\n",
      "          -8.0425e-04, -7.0519e-02],\n",
      "         [-1.8433e-03, -2.2891e-01, -7.4747e-03,  ..., -1.3283e-02,\n",
      "          -4.8969e-02, -1.1277e-01],\n",
      "         [-1.0610e-02, -1.3840e-01, -1.2417e-02,  ..., -7.0086e-03,\n",
      "          -2.9182e-02, -1.4562e-01]],\n",
      "\n",
      "        [[ 2.2023e-02, -1.4962e-01, -2.6260e-03,  ..., -6.0671e-03,\n",
      "          -6.1300e-03,  7.1937e-02],\n",
      "         [-6.6657e-03,  2.3168e-01, -7.1030e-03,  ..., -8.2687e-03,\n",
      "           1.2923e-03,  1.5624e-01],\n",
      "         [ 2.8740e-02,  2.8222e-01, -6.1966e-03,  ..., -9.8394e-03,\n",
      "          -3.2919e-02,  1.4199e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.6291e-02,  9.9658e-02, -8.1416e-03,  ..., -1.0716e-02,\n",
      "          -1.4845e-02,  1.6082e-01],\n",
      "         [ 5.1407e-03,  1.8826e-01, -1.2694e-02,  ..., -1.8603e-02,\n",
      "           7.8965e-04,  1.9267e-01],\n",
      "         [ 4.6100e-02, -7.2920e-02, -1.1309e-02,  ...,  6.5476e-01,\n",
      "          -5.4275e-02, -1.3370e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.6074e-02, -2.6482e-02, -9.1434e-03,  ..., -1.1213e-02,\n",
      "          -1.6631e-02,  1.7874e-01],\n",
      "         [ 1.7300e-03,  1.2782e-01, -1.3702e-02,  ..., -1.9061e-02,\n",
      "           1.4626e-03,  1.9247e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.0566e-02,  2.3772e-01, -1.0338e-02,  ..., -1.2219e-02,\n",
      "          -1.9255e-02,  2.1148e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10, 10,  9,  9,  8,  8,  8,  7,  7,  7,  7,  6,  6,  6,  6,  6,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-1.5162e-03, -2.0893e-01, -2.1978e-03,  ..., -7.0272e-03,\n",
      "           7.3063e-03, -1.1366e-01],\n",
      "         [ 2.7851e-02, -1.1924e-01, -1.1787e-03,  ..., -2.2253e-03,\n",
      "          -8.3439e-03, -1.2300e-02],\n",
      "         [-8.1129e-03,  6.2060e-03, -7.1499e-03,  ..., -6.8356e-03,\n",
      "           3.5997e-02, -4.2806e-02],\n",
      "         ...,\n",
      "         [ 2.0721e-02, -8.3059e-02, -8.2979e-03,  ..., -1.9185e-02,\n",
      "          -2.7507e-03,  9.7323e-03],\n",
      "         [-7.7643e-03,  4.0696e-01, -3.2759e-03,  ..., -8.6981e-03,\n",
      "           8.0351e-03,  3.4730e-02],\n",
      "         [-4.3490e-03, -3.3046e-01,  1.5266e-03,  ..., -9.2292e-03,\n",
      "           7.1008e-04, -2.8777e-02]],\n",
      "\n",
      "        [[ 1.8214e-03, -2.0531e-01, -2.8378e-03,  ..., -9.1687e-03,\n",
      "           1.0749e-02, -9.7848e-02],\n",
      "         [ 3.4450e-02, -6.8819e-02,  1.0479e-04,  ..., -4.5319e-03,\n",
      "          -1.4355e-02, -1.2354e-01],\n",
      "         [-7.2732e-03, -6.9272e-02, -8.0295e-03,  ..., -7.7056e-03,\n",
      "           3.5233e-02, -6.3046e-02],\n",
      "         ...,\n",
      "         [ 2.5853e-02, -3.4808e-02, -1.0305e-02,  ..., -2.2884e-02,\n",
      "          -5.2021e-03,  3.8424e-02],\n",
      "         [-1.2185e-02,  4.5072e-01, -4.5011e-03,  ..., -1.1750e-02,\n",
      "           8.3960e-03,  5.7963e-02],\n",
      "         [-6.4749e-03, -2.8521e-01,  8.0205e-04,  ..., -1.0893e-02,\n",
      "           3.6257e-04,  3.9357e-02]],\n",
      "\n",
      "        [[ 1.2900e-02, -1.8726e-02, -5.8340e-03,  ..., -2.1240e-02,\n",
      "           8.0265e-03, -1.3259e-01],\n",
      "         [ 2.0479e-02,  9.1305e-02,  1.4065e-03,  ..., -9.0849e-03,\n",
      "          -1.6111e-02, -7.1754e-02],\n",
      "         [ 6.7672e-02,  3.9370e-02, -1.1558e-02,  ..., -1.1825e-02,\n",
      "           4.2074e-02, -3.4115e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7233e-02, -8.7330e-02, -1.1996e-02,  ..., -3.1180e-02,\n",
      "          -3.2539e-03,  2.6298e-02],\n",
      "         [ 3.7981e-02, -1.8464e-03,  1.3236e-04,  ..., -1.5249e-02,\n",
      "          -5.0701e-02, -2.7654e-03],\n",
      "         [ 1.7615e-01,  1.6920e-01, -1.6672e-02,  ..., -2.7234e-02,\n",
      "           3.5409e-02,  1.0228e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.6919e-02,  1.2669e-01, -1.1531e-02,  ..., -3.4616e-02,\n",
      "          -5.7114e-03,  1.7629e-02],\n",
      "         [ 4.1572e-02,  9.7598e-02,  1.7317e-04,  ..., -1.6308e-02,\n",
      "          -5.4178e-02, -2.1731e-02],\n",
      "         [ 1.9430e-01,  2.1175e-01, -1.7532e-02,  ..., -2.8996e-02,\n",
      "           4.1041e-02, -1.6324e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.9768e-02,  1.0732e-01, -1.2819e-02,  ..., -3.8241e-02,\n",
      "          -6.7710e-03,  5.5887e-02],\n",
      "         [ 4.5520e-02,  2.1732e-01,  1.8311e-04,  ..., -1.7415e-02,\n",
      "          -5.5172e-02, -1.6821e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([12, 64, 500])\n",
      "encoder_input_lengths:  tensor([12, 10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  6,\n",
      "         6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,\n",
      "         3,  3,  3,  3,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 7.5189e-03, -2.9664e-02, -1.9463e-02,  ..., -6.8053e-03,\n",
      "           1.4891e-04, -4.4607e-02],\n",
      "         [-2.7081e-02,  3.8937e-01, -1.0072e-02,  ..., -6.3150e-03,\n",
      "          -2.1953e-02, -1.4297e-02],\n",
      "         [-4.2880e-03, -4.0762e-02, -1.6037e-02,  ..., -4.2472e-03,\n",
      "          -7.1727e-03, -2.2378e-02],\n",
      "         ...,\n",
      "         [-1.1574e-02, -1.5541e-01, -1.7789e-02,  ..., -8.2703e-03,\n",
      "           7.6431e-03, -5.2091e-02],\n",
      "         [ 2.4840e-03, -1.3940e-01, -7.1444e-03,  ..., -4.5509e-03,\n",
      "          -2.1195e-03, -5.1412e-02],\n",
      "         [-3.0303e-04, -2.9092e-03, -3.2316e-02,  ...,  9.2528e-04,\n",
      "          -7.2845e-03, -1.2794e-01]],\n",
      "\n",
      "        [[-3.3122e-03, -6.2134e-02, -2.5110e-02,  ..., -1.1572e-02,\n",
      "           4.0367e-03, -2.0113e-02],\n",
      "         [-1.1401e-03,  5.4538e-01, -1.6616e-02,  ..., -1.0463e-02,\n",
      "          -2.4449e-02, -5.1936e-02],\n",
      "         [-9.0923e-04, -4.4932e-02, -2.2314e-02,  ..., -6.6214e-03,\n",
      "          -1.2538e-02,  1.2784e-02],\n",
      "         ...,\n",
      "         [-1.5303e-02, -2.1280e-01, -2.7183e-02,  ..., -1.1335e-02,\n",
      "           9.5340e-04, -3.2010e-02],\n",
      "         [ 3.1251e-03, -1.8299e-01, -1.1734e-02,  ..., -9.2896e-03,\n",
      "          -8.1538e-03,  2.6606e-03],\n",
      "         [-5.9870e-03, -7.6500e-02, -4.3263e-02,  ..., -2.0457e-04,\n",
      "          -9.4830e-03, -1.4391e-01]],\n",
      "\n",
      "        [[ 4.3391e-03, -9.8645e-02, -3.2271e-02,  ..., -1.3594e-02,\n",
      "           3.8754e-03, -5.9665e-02],\n",
      "         [ 1.6904e-03,  6.3800e-01, -1.6348e-02,  ..., -1.3546e-02,\n",
      "          -2.6498e-02, -3.1930e-02],\n",
      "         [-5.5330e-03, -2.5702e-02, -2.6862e-02,  ..., -8.9390e-03,\n",
      "          -1.1876e-02,  1.4881e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7637e-02,  5.9575e-03, -6.5824e-02,  ..., -2.2687e-02,\n",
      "           1.4987e-02,  3.2601e-03],\n",
      "         [ 2.6329e-02,  6.6875e-01, -1.1921e-02,  ..., -2.0317e-02,\n",
      "          -5.5812e-02,  2.5773e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4714e-02, -8.3112e-03, -6.8102e-02,  ..., -2.2547e-02,\n",
      "           1.5128e-02, -3.7788e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.0029e-02, -4.3481e-02, -7.1740e-02,  ..., -2.3287e-02,\n",
      "           1.6069e-02,  1.0424e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([17, 64, 500])\n",
      "encoder_input_lengths:  tensor([17, 13, 10,  9,  9,  9,  8,  8,  8,  8,  8,  7,  7,  7,  7,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         3,  3,  3,  3,  3,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0392,  0.0126, -0.0108,  ..., -0.0105, -0.0184, -0.0974],\n",
      "         [ 0.0206, -0.1674, -0.0036,  ..., -0.0117,  0.0038, -0.0894],\n",
      "         [ 0.0005,  0.0515, -0.0051,  ..., -0.0205, -0.0015, -0.0504],\n",
      "         ...,\n",
      "         [ 0.0101,  0.1199, -0.0029,  ..., -0.0027,  0.0104, -0.0354],\n",
      "         [ 0.0031, -0.2319, -0.0018,  ..., -0.0024, -0.0082, -0.0337],\n",
      "         [ 0.0078, -0.0566, -0.0087,  ..., -0.0034, -0.0086, -0.0406]],\n",
      "\n",
      "        [[ 0.0445, -0.0255, -0.0204,  ..., -0.0130, -0.0202, -0.0740],\n",
      "         [ 0.0232, -0.1676, -0.0085,  ..., -0.0227, -0.0131, -0.0928],\n",
      "         [ 0.0013, -0.0363, -0.0073,  ..., -0.0251, -0.0069, -0.0120],\n",
      "         ...,\n",
      "         [ 0.0085,  0.0823, -0.0057,  ..., -0.0056,  0.0161, -0.0236],\n",
      "         [ 0.0046, -0.3112, -0.0021,  ..., -0.0079, -0.0080, -0.2338],\n",
      "         [ 0.0100, -0.0600, -0.0110,  ..., -0.0048, -0.0086, -0.0379]],\n",
      "\n",
      "        [[ 0.0495, -0.1316, -0.0373,  ..., -0.0134, -0.0209, -0.0680],\n",
      "         [ 0.0234, -0.1030, -0.0091,  ..., -0.0456, -0.0194, -0.1549],\n",
      "         [ 0.0023,  0.0351, -0.0074,  ..., -0.0187, -0.0013, -0.0636],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2679,  0.2003, -0.0732,  ..., -0.0219, -0.0510,  0.0094],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.2633,  0.1240, -0.0753,  ..., -0.0228, -0.0519,  0.0365],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.2631,  0.1063, -0.0780,  ..., -0.0235, -0.0516, -0.0120],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 10,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         3,  3,  3,  3,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0262,  0.0263, -0.0092,  ..., -0.0059, -0.0020, -0.0617],\n",
      "         [ 0.0015,  0.3619, -0.0040,  ..., -0.0137, -0.0249,  0.0205],\n",
      "         [ 0.0098, -0.0261, -0.0040,  ..., -0.0069, -0.0021, -0.0664],\n",
      "         ...,\n",
      "         [ 0.0162,  0.0107, -0.0047,  ..., -0.0026, -0.0088, -0.0334],\n",
      "         [-0.0158,  0.1271, -0.0094,  ..., -0.0045, -0.0012, -0.0340],\n",
      "         [-0.0062, -0.1801, -0.0039,  ..., -0.0094, -0.0037, -0.0193]],\n",
      "\n",
      "        [[ 0.0299, -0.0144, -0.0127,  ..., -0.0070, -0.0026, -0.0759],\n",
      "         [-0.0027,  0.4949, -0.0050,  ..., -0.0193, -0.0329,  0.1618],\n",
      "         [ 0.0130, -0.0609, -0.0051,  ..., -0.0087, -0.0111, -0.0634],\n",
      "         ...,\n",
      "         [ 0.0332, -0.0206, -0.0067,  ..., -0.0012, -0.0276, -0.0486],\n",
      "         [-0.0041,  0.2293, -0.0115,  ..., -0.0057, -0.0011, -0.0580],\n",
      "         [-0.0094, -0.2146, -0.0128,  ..., -0.0167, -0.0020, -0.0085]],\n",
      "\n",
      "        [[ 0.0581, -0.0228, -0.0259,  ..., -0.0114, -0.0011,  0.0184],\n",
      "         [-0.0036,  0.3879, -0.0055,  ..., -0.0213, -0.0400,  0.2817],\n",
      "         [-0.0147, -0.0721, -0.0082,  ..., -0.0115, -0.0175, -0.0846],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1266,  0.2568, -0.0325,  ..., -0.0360,  0.0054, -0.1648],\n",
      "         [-0.0054,  0.6276, -0.0131,  ..., -0.0237, -0.0791,  0.2666],\n",
      "         [-0.0136,  0.0597, -0.0188,  ..., -0.0271, -0.0426, -0.0049],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0908,  0.1400, -0.0506,  ..., -0.0443,  0.0113, -0.0845],\n",
      "         [-0.0026,  0.4537, -0.0145,  ..., -0.0277, -0.0816,  0.1566],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0936, -0.0257, -0.0554,  ..., -0.0491,  0.0141, -0.0614],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 2.6775e-03, -8.2006e-02, -7.5427e-03,  ..., -4.0083e-03,\n",
      "           5.9158e-03, -5.4205e-02],\n",
      "         [ 4.8095e-03, -1.5490e-01, -5.3812e-03,  ..., -2.9221e-03,\n",
      "          -1.0456e-02, -4.5126e-02],\n",
      "         [ 1.4670e-02,  2.3118e-01, -3.9185e-03,  ..., -1.7213e-02,\n",
      "           1.6277e-02,  4.4506e-02],\n",
      "         ...,\n",
      "         [ 2.9998e-03,  5.2052e-01, -2.6045e-03,  ..., -6.8748e-03,\n",
      "          -6.2105e-03,  7.7237e-02],\n",
      "         [ 3.2068e-03, -7.6774e-02, -1.9007e-03,  ..., -1.9216e-03,\n",
      "          -3.3503e-03, -3.3301e-02],\n",
      "         [ 2.2098e-03, -2.0492e-02, -1.0618e-02,  ..., -1.0702e-02,\n",
      "          -4.0621e-04,  2.4576e-02]],\n",
      "\n",
      "        [[ 3.3226e-03,  2.9141e-02, -1.0242e-02,  ..., -2.7460e-02,\n",
      "          -1.0789e-02, -5.9994e-03],\n",
      "         [-6.0471e-03, -1.9611e-01, -1.3153e-02,  ..., -6.2736e-03,\n",
      "          -2.2164e-02, -2.1161e-02],\n",
      "         [-5.3802e-03,  2.4739e-01, -5.1572e-03,  ..., -2.4298e-02,\n",
      "           1.1833e-02,  1.0523e-01],\n",
      "         ...,\n",
      "         [ 4.7159e-03,  5.1723e-01, -5.8915e-03,  ..., -9.9499e-03,\n",
      "          -9.5168e-03,  6.5905e-02],\n",
      "         [ 7.7094e-03, -2.3370e-02, -2.7602e-03,  ..., -2.4231e-03,\n",
      "          -6.5099e-03, -6.5341e-02],\n",
      "         [ 2.8119e-03, -7.5820e-02, -1.2738e-02,  ..., -1.3945e-02,\n",
      "          -2.1529e-03,  3.7853e-02]],\n",
      "\n",
      "        [[ 1.8379e-03, -2.6556e-02, -1.1347e-02,  ..., -1.9009e-02,\n",
      "          -1.5665e-02, -4.7028e-02],\n",
      "         [-1.1320e-02, -1.7637e-01, -1.7712e-02,  ..., -6.4051e-03,\n",
      "          -2.3977e-02, -8.0203e-03],\n",
      "         [-1.1009e-03,  4.0848e-01, -6.5985e-03,  ..., -2.7896e-02,\n",
      "           1.5520e-02,  1.1792e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.1625e-03, -3.0808e-02, -1.7501e-02,  ..., -5.3070e-02,\n",
      "          -2.7690e-02,  6.3703e-02],\n",
      "         [-1.3478e-02, -1.8864e-01, -3.5698e-02,  ..., -1.2395e-02,\n",
      "          -3.8810e-02,  6.0760e-02],\n",
      "         [ 5.8789e-02,  5.1054e-01, -1.3210e-02,  ..., -5.9741e-02,\n",
      "           1.7247e-02, -6.0546e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.1655e-03,  4.6023e-02, -1.7734e-02,  ..., -6.1151e-02,\n",
      "          -3.3294e-02,  1.0746e-01],\n",
      "         [-1.1408e-02, -2.1011e-01, -3.8840e-02,  ..., -1.2025e-02,\n",
      "          -4.1700e-02,  9.6724e-02],\n",
      "         [ 7.8734e-02,  4.7307e-01, -1.6404e-02,  ..., -6.3279e-02,\n",
      "           2.4083e-02, -3.9643e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.5671e-03, -8.8304e-02, -1.8204e-02,  ..., -6.8233e-02,\n",
      "          -3.0357e-02,  9.3472e-02],\n",
      "         [-8.4094e-03, -3.1466e-01, -4.6731e-02,  ..., -1.0945e-02,\n",
      "          -4.3699e-02,  4.3334e-02],\n",
      "         [ 7.8212e-02,  2.9807e-01, -1.9311e-02,  ..., -7.1161e-02,\n",
      "           2.4511e-02, -5.7546e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 50; Percent complete: 4.3%; Average loss: 0.6936\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,\n",
      "         7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  3,  3,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 8.7862e-03, -1.4656e-01, -1.6744e-02,  ..., -6.0762e-03,\n",
      "           2.7426e-03, -9.7006e-02],\n",
      "         [ 5.8197e-03,  7.2510e-02, -1.3264e-02,  ...,  6.3421e-04,\n",
      "          -7.0511e-03, -7.8406e-02],\n",
      "         [ 2.5531e-02,  3.2960e-01, -1.9181e-03,  ..., -8.6064e-03,\n",
      "           1.0030e-02, -4.8513e-02],\n",
      "         ...,\n",
      "         [-1.2233e-04, -2.2957e-01, -9.8187e-03,  ..., -1.2985e-02,\n",
      "          -1.1429e-03, -4.3592e-02],\n",
      "         [-8.0422e-02,  1.1294e-01, -5.6385e-03,  ..., -7.8516e-03,\n",
      "           3.8778e-03,  1.3212e-03],\n",
      "         [-1.6752e-03, -1.8179e-01, -1.1936e-02,  ..., -1.0054e-02,\n",
      "          -9.7717e-04, -1.0161e-01]],\n",
      "\n",
      "        [[ 9.7754e-03, -2.5950e-01, -1.8288e-02,  ..., -1.1502e-02,\n",
      "          -2.4689e-03, -1.3130e-02],\n",
      "         [ 1.0052e-02,  1.7508e-01, -2.0197e-02,  ...,  3.1017e-03,\n",
      "          -1.1548e-02, -1.0626e-01],\n",
      "         [ 4.9270e-02,  1.9830e-01, -3.0746e-03,  ..., -1.0094e-02,\n",
      "           1.2572e-02,  3.4303e-02],\n",
      "         ...,\n",
      "         [ 1.6044e-03, -2.3475e-01, -2.9926e-02,  ..., -2.0822e-02,\n",
      "           7.5737e-03,  1.0944e-02],\n",
      "         [-8.1146e-02,  6.9884e-02, -6.6512e-03,  ..., -9.1797e-03,\n",
      "           2.5155e-03,  1.4149e-02],\n",
      "         [-4.1034e-03, -2.3790e-01, -1.9135e-02,  ..., -1.8699e-02,\n",
      "          -2.6284e-03,  4.0877e-03]],\n",
      "\n",
      "        [[ 2.9584e-03, -2.2275e-01, -2.7768e-02,  ..., -1.3312e-02,\n",
      "          -6.9904e-03,  1.1634e-01],\n",
      "         [ 1.1145e-02,  1.4229e-01, -2.7048e-02,  ...,  7.2413e-03,\n",
      "          -1.3309e-02, -4.8462e-02],\n",
      "         [ 5.8598e-02,  1.4938e-01, -4.0908e-03,  ..., -1.4272e-02,\n",
      "           5.8830e-03,  4.3823e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.6443e-03, -4.4177e-02, -4.7466e-02,  ..., -1.7146e-02,\n",
      "          -2.6543e-02,  1.5260e-01],\n",
      "         [ 1.9103e-02,  1.9892e-01, -5.3031e-02,  ...,  1.3312e-02,\n",
      "          -1.7522e-02, -1.1482e-01],\n",
      "         [ 2.2978e-01,  1.6123e-01, -6.7374e-03,  ..., -6.1671e-02,\n",
      "           2.5442e-03,  3.9203e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.3352e-04, -1.0799e-01, -5.3571e-02,  ..., -1.7486e-02,\n",
      "          -3.0298e-02,  7.7686e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.0144e-04, -1.6152e-01, -6.5014e-02,  ..., -1.7520e-02,\n",
      "          -3.1196e-02,  1.4610e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([12, 64, 500])\n",
      "encoder_input_lengths:  tensor([12, 11, 10,  9,  9,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-0.0007, -0.1248, -0.0090,  ..., -0.0039, -0.0042,  0.0116],\n",
      "         [-0.0079,  0.2679, -0.0014,  ..., -0.0019, -0.0041, -0.0592],\n",
      "         [ 0.0049,  0.0585, -0.0057,  ..., -0.0034, -0.0051, -0.0111],\n",
      "         ...,\n",
      "         [-0.0747,  0.2880, -0.0038,  ..., -0.0093, -0.0085, -0.0726],\n",
      "         [ 0.0023, -0.0656, -0.0049,  ..., -0.0141, -0.0088, -0.0823],\n",
      "         [ 0.0028, -0.1165, -0.0029,  ..., -0.0038, -0.0066, -0.0627]],\n",
      "\n",
      "        [[-0.0003, -0.1391, -0.0109,  ..., -0.0071, -0.0048,  0.0668],\n",
      "         [-0.0406,  0.1794, -0.0061,  ..., -0.0039, -0.0057, -0.0496],\n",
      "         [ 0.0061, -0.0269, -0.0069,  ..., -0.0042, -0.0071, -0.0203],\n",
      "         ...,\n",
      "         [-0.0841,  0.2472, -0.0070,  ..., -0.0110, -0.0123, -0.0745],\n",
      "         [ 0.0072, -0.1208, -0.0072,  ..., -0.0079, -0.0255,  0.0042],\n",
      "         [ 0.0034, -0.1197, -0.0043,  ..., -0.0089, -0.0055, -0.0401]],\n",
      "\n",
      "        [[-0.0071, -0.2486, -0.0153,  ..., -0.0243, -0.0062,  0.1694],\n",
      "         [-0.0397,  0.1736, -0.0085,  ..., -0.0045, -0.0064, -0.0427],\n",
      "         [ 0.0082, -0.1039, -0.0081,  ..., -0.0050, -0.0097, -0.0581],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048, -0.0328, -0.0398,  ..., -0.1230, -0.0338, -0.0540],\n",
      "         [-0.0313, -0.0165, -0.0303,  ..., -0.0108, -0.0130,  0.0572],\n",
      "         [ 0.0318,  0.0936, -0.0242,  ..., -0.0092, -0.0293, -0.0198],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0018,  0.0138, -0.0391,  ..., -0.1326, -0.0346, -0.0599],\n",
      "         [-0.0319,  0.0423, -0.0309,  ..., -0.0110, -0.0139,  0.0428],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0022,  0.0010, -0.0395,  ..., -0.1353, -0.0355, -0.0426],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  3,  3,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-7.3975e-03, -8.2852e-02, -1.4884e-03,  ..., -6.3829e-03,\n",
      "          -1.0466e-02, -3.9004e-02],\n",
      "         [-3.8646e-03, -5.5491e-02, -3.8932e-03,  ..., -4.2135e-03,\n",
      "          -3.4598e-03, -3.6650e-02],\n",
      "         [-1.5683e-03, -1.5527e-01, -1.2072e-02,  ..., -4.4001e-03,\n",
      "          -2.7430e-02, -1.5692e-02],\n",
      "         ...,\n",
      "         [ 1.0174e-03, -4.9124e-02, -8.7450e-03,  ..., -5.2558e-03,\n",
      "          -4.0457e-02, -4.3958e-02],\n",
      "         [-1.7792e-03, -4.5033e-02, -1.2941e-04,  ..., -8.0573e-03,\n",
      "          -3.4964e-03,  1.8970e-02],\n",
      "         [-7.8229e-03, -1.5055e-01, -8.4579e-03,  ..., -3.5643e-03,\n",
      "          -5.0127e-03, -2.3331e-02]],\n",
      "\n",
      "        [[-1.0675e-02, -1.2392e-01, -6.2852e-03,  ..., -9.5399e-03,\n",
      "          -1.0075e-02, -5.1062e-02],\n",
      "         [-1.8588e-03, -9.4666e-02, -7.6274e-03,  ..., -6.1552e-03,\n",
      "          -5.1723e-03, -9.7669e-02],\n",
      "         [-1.4478e-01,  3.0142e-01, -2.1507e-02,  ..., -8.0970e-03,\n",
      "          -3.3909e-02,  5.7401e-02],\n",
      "         ...,\n",
      "         [ 9.3535e-04, -7.9481e-02, -1.1181e-02,  ..., -6.7251e-03,\n",
      "          -4.8307e-02, -4.9071e-02],\n",
      "         [-2.1633e-03, -8.2140e-02, -2.0246e-03,  ..., -1.0942e-02,\n",
      "          -4.4868e-03,  2.0216e-02],\n",
      "         [-7.6482e-03, -2.1224e-01, -1.0411e-02,  ..., -4.2587e-03,\n",
      "          -7.1796e-03,  2.2928e-02]],\n",
      "\n",
      "        [[-1.7701e-02, -1.1868e-03, -7.8037e-03,  ..., -1.0627e-02,\n",
      "          -1.1687e-02, -5.4735e-02],\n",
      "         [ 5.1892e-03, -2.4715e-01, -2.3890e-02,  ...,  6.0930e-04,\n",
      "          -1.5677e-03, -1.7524e-01],\n",
      "         [-1.2864e-01,  1.7751e-01, -2.4156e-02,  ..., -8.2198e-03,\n",
      "          -3.8166e-02,  1.1153e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0904e-02, -8.3984e-02, -1.5824e-02,  ..., -1.7389e-02,\n",
      "          -1.9942e-02,  7.0387e-03],\n",
      "         [-2.1240e-02, -2.3096e-01, -6.9069e-02,  ..., -1.5833e-03,\n",
      "          -6.6112e-03,  1.6019e-01],\n",
      "         [-1.5523e-01,  1.9937e-01, -2.6311e-02,  ..., -6.9511e-03,\n",
      "          -5.0151e-02,  1.5547e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.0474e-02, -1.2480e-01, -1.5737e-02,  ..., -1.7979e-02,\n",
      "          -2.1143e-02, -2.9826e-02],\n",
      "         [-2.0732e-02, -2.6622e-01, -7.2068e-02,  ..., -1.9322e-03,\n",
      "          -1.0069e-02,  9.1599e-02],\n",
      "         [-1.5321e-01,  1.8203e-01, -2.8947e-02,  ..., -8.5866e-03,\n",
      "          -5.4630e-02,  2.0566e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-9.0204e-03, -1.6462e-01, -1.6511e-02,  ..., -2.0131e-02,\n",
      "          -2.2530e-02, -7.4025e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0015, -0.1675, -0.0023,  ..., -0.0017, -0.0025, -0.0115],\n",
      "         [-0.0018, -0.0722, -0.0004,  ..., -0.0155, -0.0085, -0.0780],\n",
      "         [ 0.0071, -0.2287, -0.0178,  ..., -0.0278,  0.0398, -0.1224],\n",
      "         ...,\n",
      "         [-0.0010, -0.1499,  0.0394,  ..., -0.0140, -0.0047,  0.0096],\n",
      "         [ 0.0022, -0.1672, -0.0092,  ..., -0.0022, -0.0205, -0.0555],\n",
      "         [-0.0046, -0.2036, -0.0067,  ..., -0.0039,  0.0053, -0.0523]],\n",
      "\n",
      "        [[ 0.0131, -0.0785, -0.0036,  ..., -0.0030, -0.0077, -0.0266],\n",
      "         [-0.0007, -0.1138, -0.0018,  ..., -0.0233, -0.0136, -0.0327],\n",
      "         [ 0.0006, -0.1698, -0.0313,  ..., -0.0303,  0.0256, -0.0862],\n",
      "         ...,\n",
      "         [-0.0030, -0.0256,  0.0349,  ..., -0.0170, -0.0086,  0.0473],\n",
      "         [ 0.0024, -0.2172, -0.0111,  ..., -0.0035, -0.0288, -0.1010],\n",
      "         [-0.0205, -0.2543, -0.0093,  ..., -0.0067,  0.0085,  0.0256]],\n",
      "\n",
      "        [[ 0.0287,  0.0972, -0.0047,  ..., -0.0046, -0.0104, -0.0454],\n",
      "         [-0.0072, -0.0730, -0.0014,  ..., -0.0265, -0.0185,  0.0124],\n",
      "         [ 0.0007, -0.1404, -0.0307,  ..., -0.0313,  0.0242, -0.0140],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0355, -0.0854, -0.0108,  ..., -0.0095, -0.0175, -0.0136],\n",
      "         [-0.0044, -0.0831, -0.0048,  ..., -0.0342, -0.0241,  0.0654],\n",
      "         [ 0.0039, -0.1184, -0.0296,  ..., -0.0359,  0.0315, -0.1357],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0316, -0.1335, -0.0116,  ..., -0.0098, -0.0168, -0.0477],\n",
      "         [-0.0036, -0.0281, -0.0040,  ..., -0.0355, -0.0290,  0.1465],\n",
      "         [ 0.0049,  0.0732, -0.0373,  ..., -0.0360,  0.0410, -0.0490],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0305, -0.1131, -0.0122,  ..., -0.0104, -0.0186, -0.0488],\n",
      "         [-0.0409,  0.1154, -0.0040,  ..., -0.0344, -0.0326,  0.1912],\n",
      "         [ 0.0059, -0.0327, -0.0465,  ..., -0.0384,  0.0438, -0.0011],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 9, 9, 9, 9, 8, 8, 8, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0053, -0.0539, -0.0138,  ..., -0.0117, -0.0005, -0.0890],\n",
      "         [-0.0674, -0.0775, -0.0147,  ..., -0.0064, -0.0005, -0.0674],\n",
      "         [-0.0059,  0.1811, -0.0039,  ..., -0.0035, -0.0026, -0.0405],\n",
      "         ...,\n",
      "         [-0.0439, -0.0222, -0.0042,  ..., -0.0026, -0.0055, -0.0457],\n",
      "         [ 0.0016, -0.1053, -0.0071,  ..., -0.0074,  0.0077,  0.0178],\n",
      "         [-0.0394,  0.2538, -0.0194,  ..., -0.0084, -0.0197,  0.0334]],\n",
      "\n",
      "        [[ 0.0437, -0.1044, -0.0212,  ..., -0.0142, -0.0044, -0.0203],\n",
      "         [-0.0775, -0.0132, -0.0225,  ..., -0.0087,  0.0032, -0.1302],\n",
      "         [ 0.0048,  0.1020, -0.0080,  ..., -0.0045, -0.0056, -0.0846],\n",
      "         ...,\n",
      "         [-0.0359, -0.0248, -0.0065,  ..., -0.0064, -0.0047,  0.0460],\n",
      "         [-0.0014, -0.1840, -0.0098,  ..., -0.0092,  0.0095,  0.0122],\n",
      "         [-0.0396,  0.1935, -0.0241,  ..., -0.0109, -0.0332,  0.0465]],\n",
      "\n",
      "        [[ 0.0430,  0.0656, -0.0235,  ..., -0.0179, -0.0015,  0.0491],\n",
      "         [-0.0723, -0.0652, -0.0240,  ..., -0.0103,  0.0031, -0.1865],\n",
      "         [ 0.0096,  0.1471, -0.0096,  ..., -0.0051, -0.0056, -0.0359],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0558,  0.2658, -0.0360,  ..., -0.0259,  0.0019,  0.1755],\n",
      "         [-0.1107,  0.3159, -0.0353,  ..., -0.0246, -0.0007, -0.0845],\n",
      "         [ 0.0196,  0.2801, -0.0130,  ..., -0.0130, -0.0118, -0.0773],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0573,  0.1907, -0.0403,  ..., -0.0254,  0.0006,  0.1332],\n",
      "         [-0.1006,  0.2733, -0.0373,  ..., -0.0270, -0.0005, -0.0312],\n",
      "         [ 0.0222,  0.3393, -0.0133,  ..., -0.0145, -0.0147,  0.0007],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0572,  0.1188, -0.0451,  ..., -0.0249,  0.0017,  0.1722],\n",
      "         [-0.1534,  0.1710, -0.0405,  ..., -0.0317,  0.0004, -0.0022],\n",
      "         [ 0.0212,  0.3379, -0.0162,  ..., -0.0143, -0.0228, -0.0368],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([14, 64, 500])\n",
      "encoder_input_lengths:  tensor([14,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,\n",
      "         3,  3,  3,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-1.3668e-03,  3.2926e-01, -2.0091e-03,  ..., -2.7807e-03,\n",
      "          -1.5062e-02, -1.2564e-02],\n",
      "         [-3.9478e-04, -5.3112e-02, -5.4906e-03,  ..., -2.8143e-03,\n",
      "          -2.2220e-02, -8.2808e-03],\n",
      "         [ 4.9943e-03,  1.5126e-02, -4.0585e-03,  ..., -2.8546e-03,\n",
      "          -7.1161e-03, -4.9531e-02],\n",
      "         ...,\n",
      "         [ 6.9522e-03,  3.7746e-01, -1.0707e-02,  ..., -9.0168e-03,\n",
      "           1.6385e-03, -8.9840e-02],\n",
      "         [-8.2490e-03,  2.5392e-01, -8.6202e-04,  ..., -4.8806e-03,\n",
      "          -3.5789e-03,  1.0621e-01],\n",
      "         [-3.8609e-02, -9.2570e-02, -6.7345e-03,  ..., -1.7468e-02,\n",
      "          -8.4449e-03, -1.3959e-01]],\n",
      "\n",
      "        [[ 1.4692e-03,  6.5002e-02, -3.4939e-03,  ..., -6.5713e-03,\n",
      "          -2.3280e-02,  2.1815e-02],\n",
      "         [-7.9662e-03,  4.7156e-02, -3.8301e-02,  ..., -1.4690e-02,\n",
      "          -3.1287e-02,  8.1723e-02],\n",
      "         [ 3.3715e-03,  2.3153e-02, -5.7638e-03,  ..., -5.4530e-03,\n",
      "          -1.3575e-02, -6.0624e-02],\n",
      "         ...,\n",
      "         [-9.9258e-03,  4.2682e-01, -1.6519e-02,  ..., -2.1854e-02,\n",
      "           7.3048e-03, -4.7568e-02],\n",
      "         [ 2.2113e-03,  2.3869e-01, -1.5177e-03,  ..., -7.2983e-03,\n",
      "          -3.4732e-03,  1.1114e-01],\n",
      "         [-4.2174e-02, -2.1063e-01, -1.0452e-02,  ..., -2.7865e-02,\n",
      "          -8.5422e-03, -5.6680e-02]],\n",
      "\n",
      "        [[ 5.1660e-03, -1.0738e-03, -3.8951e-03,  ..., -9.8541e-03,\n",
      "          -2.1887e-02,  8.9656e-02],\n",
      "         [-8.5368e-03, -1.1679e-02, -5.4552e-02,  ..., -1.8726e-02,\n",
      "          -3.4781e-02,  5.0803e-02],\n",
      "         [ 1.0893e-02, -1.0937e-02, -8.5519e-03,  ..., -4.1844e-03,\n",
      "          -1.6558e-02, -6.1125e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6981e-02,  3.9569e-01, -1.0335e-02,  ..., -2.0432e-02,\n",
      "          -2.6252e-02,  2.5222e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.0437e-02,  3.0322e-01, -1.0527e-02,  ..., -2.0932e-02,\n",
      "          -2.7350e-02,  3.0738e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.0815e-02,  2.5445e-01, -1.0843e-02,  ..., -2.1389e-02,\n",
      "          -2.7691e-02,  2.6401e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([11, 64, 500])\n",
      "encoder_input_lengths:  tensor([11, 10,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,\n",
      "         7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n",
      "         3,  3,  3,  3,  3,  3,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-4.7379e-03, -1.5328e-01, -1.2028e-02,  ..., -8.0390e-03,\n",
      "          -2.1381e-02, -2.5258e-02],\n",
      "         [ 8.6858e-03, -8.3014e-02,  1.4192e-02,  ..., -1.3686e-02,\n",
      "          -6.7488e-03,  4.6104e-02],\n",
      "         [ 1.9768e-02,  3.2714e-01, -8.2483e-03,  ..., -5.7916e-03,\n",
      "           2.4847e-03,  5.6149e-03],\n",
      "         ...,\n",
      "         [ 4.9318e-03, -1.8898e-01, -3.4103e-03,  ..., -7.8439e-03,\n",
      "          -6.3918e-03,  2.0294e-02],\n",
      "         [-2.3237e-02,  1.1300e-01, -1.4256e-02,  ..., -8.5101e-03,\n",
      "           6.8598e-04, -7.9525e-02],\n",
      "         [ 9.7507e-03, -9.5350e-02, -1.0128e-03,  ..., -3.0376e-03,\n",
      "          -4.3365e-04, -3.1494e-02]],\n",
      "\n",
      "        [[-4.0014e-03, -1.6085e-01, -2.0609e-02,  ..., -7.6930e-03,\n",
      "          -2.3366e-02,  4.9953e-02],\n",
      "         [ 7.8762e-03, -2.1675e-01,  3.8269e-03,  ..., -2.3068e-02,\n",
      "           2.9459e-04,  7.6982e-02],\n",
      "         [ 3.8224e-02,  1.9374e-01, -1.1531e-02,  ..., -1.3334e-02,\n",
      "           4.0498e-03,  8.2967e-04],\n",
      "         ...,\n",
      "         [ 9.0009e-03, -2.0726e-01, -6.0185e-03,  ..., -1.1590e-02,\n",
      "          -5.8906e-03,  6.0137e-02],\n",
      "         [ 1.5928e-02,  1.7266e-01, -1.5270e-02,  ..., -1.5476e-02,\n",
      "           6.2987e-03, -2.0098e-03],\n",
      "         [ 2.1164e-02, -8.9599e-02, -2.9335e-03,  ..., -4.2961e-03,\n",
      "          -3.8434e-03, -2.7063e-02]],\n",
      "\n",
      "        [[-1.6078e-03, -4.4588e-02, -2.1735e-02,  ..., -9.5437e-03,\n",
      "          -2.4261e-02,  5.1351e-02],\n",
      "         [ 1.0389e-02, -3.8918e-02,  8.9413e-04,  ..., -2.5843e-02,\n",
      "           4.5035e-03,  7.4505e-02],\n",
      "         [ 4.3587e-02,  1.3519e-01, -1.2334e-02,  ..., -1.4215e-02,\n",
      "           2.3870e-03, -5.3607e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.0507e-02, -1.8827e-01, -3.4591e-02,  ..., -1.3438e-02,\n",
      "          -2.9424e-02, -1.0895e-01],\n",
      "         [ 2.1315e-02, -1.5485e-01, -1.8699e-02,  ..., -3.9260e-02,\n",
      "           1.4424e-02, -1.0904e-02],\n",
      "         [ 1.5228e-01,  1.5139e-01, -1.6711e-02,  ..., -3.8176e-02,\n",
      "           3.4757e-02,  3.0053e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.0991e-02, -2.3227e-01, -3.7043e-02,  ..., -1.4234e-02,\n",
      "          -2.7061e-02, -1.8148e-02],\n",
      "         [ 2.0381e-02, -1.2969e-01, -2.0162e-02,  ..., -4.1510e-02,\n",
      "           1.3974e-02, -1.5390e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.1088e-02, -2.1578e-01, -3.8868e-02,  ..., -1.4861e-02,\n",
      "          -2.7475e-02,  3.7735e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([12, 64, 500])\n",
      "encoder_input_lengths:  tensor([12,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,\n",
      "         7,  7,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 3.9257e-03, -2.1547e-02, -2.1111e-02,  ...,  9.5338e-04,\n",
      "          -1.9349e-03, -1.1501e-01],\n",
      "         [ 5.9135e-03, -1.0822e-01, -4.7134e-03,  ..., -2.1253e-03,\n",
      "           1.9007e-03, -8.9729e-03],\n",
      "         [ 1.1327e-02, -1.7072e-01, -7.2244e-03,  ..., -7.0745e-03,\n",
      "           1.0531e-02, -1.0503e-01],\n",
      "         ...,\n",
      "         [ 8.0272e-03, -1.2476e-02, -1.8173e-02,  ..., -1.3388e-02,\n",
      "          -3.7637e-02, -1.6965e-01],\n",
      "         [ 1.7052e-02,  4.2406e-02, -6.4311e-03,  ..., -3.0947e-02,\n",
      "           1.0538e-02, -1.1267e-01],\n",
      "         [ 1.2361e-04, -9.7442e-02, -1.3823e-02,  ..., -1.2982e-02,\n",
      "          -1.1932e-02, -9.1029e-02]],\n",
      "\n",
      "        [[ 5.9510e-03, -1.1882e-01, -2.2742e-02,  ...,  1.1588e-04,\n",
      "          -6.4586e-03, -1.3913e-01],\n",
      "         [ 4.8336e-03, -1.3485e-01, -5.6453e-03,  ..., -3.0174e-03,\n",
      "           1.8461e-03, -2.7864e-02],\n",
      "         [-1.2419e-02, -8.7340e-02, -1.1334e-02,  ..., -1.4683e-02,\n",
      "           1.9041e-02, -2.1791e-01],\n",
      "         ...,\n",
      "         [ 5.8513e-03,  1.6679e-02, -2.7032e-02,  ..., -2.2282e-02,\n",
      "          -3.9407e-02, -1.8876e-01],\n",
      "         [ 2.7594e-02,  1.0515e-01, -9.3875e-03,  ..., -3.7233e-02,\n",
      "           1.4171e-02, -1.4144e-01],\n",
      "         [-4.0071e-04, -1.4725e-01, -2.0215e-02,  ..., -1.6894e-02,\n",
      "          -2.1363e-02, -8.4585e-02]],\n",
      "\n",
      "        [[ 8.8512e-03, -1.3858e-01, -2.4355e-02,  ..., -1.0932e-03,\n",
      "          -2.4620e-03, -1.8600e-01],\n",
      "         [ 4.0768e-03, -5.5946e-02, -5.6436e-03,  ..., -8.0709e-03,\n",
      "          -2.6997e-04, -3.6875e-02],\n",
      "         [-9.5246e-03, -1.1235e-01, -1.2341e-02,  ..., -1.5231e-02,\n",
      "           1.6501e-02, -2.5294e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7260e-02, -1.0460e-01, -2.8532e-02,  ..., -4.5120e-03,\n",
      "          -9.5283e-03, -2.2029e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.6297e-03, -8.1012e-02, -2.8487e-02,  ..., -9.8961e-03,\n",
      "          -3.6868e-03, -1.6393e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.1592e-02, -1.1314e-01, -2.8559e-02,  ..., -1.1700e-02,\n",
      "          -5.1975e-03, -1.7701e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([16, 64, 500])\n",
      "encoder_input_lengths:  tensor([16, 11, 11, 10,  9,  9,  9,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  7,\n",
      "         7,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,\n",
      "         3,  3,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 0.0005, -0.0530, -0.0025,  ..., -0.0059,  0.0032, -0.0448],\n",
      "         [ 0.0163,  0.0274, -0.0063,  ..., -0.0047, -0.0075, -0.0268],\n",
      "         [-0.0018,  0.0757,  0.0076,  ..., -0.0025, -0.0047, -0.0982],\n",
      "         ...,\n",
      "         [ 0.0058, -0.2194,  0.0013,  ..., -0.0133, -0.0099, -0.2018],\n",
      "         [ 0.0309,  0.3876, -0.0454,  ..., -0.0289, -0.0033, -0.0374],\n",
      "         [-0.0005, -0.1505, -0.0068,  ..., -0.0029, -0.0121, -0.0553]],\n",
      "\n",
      "        [[ 0.0076, -0.1844, -0.0138,  ..., -0.0148,  0.0190, -0.1299],\n",
      "         [ 0.0202, -0.0223, -0.0073,  ..., -0.0054, -0.0081, -0.0959],\n",
      "         [-0.0050,  0.1578,  0.0063,  ..., -0.0032, -0.0063, -0.0679],\n",
      "         ...,\n",
      "         [ 0.0085, -0.0948,  0.0005,  ..., -0.0306, -0.0142, -0.1903],\n",
      "         [ 0.0360,  0.3988, -0.0573,  ..., -0.0395, -0.0090,  0.0550],\n",
      "         [ 0.0035, -0.1329, -0.0076,  ..., -0.0062, -0.0130,  0.0023]],\n",
      "\n",
      "        [[ 0.0094, -0.2549, -0.0176,  ..., -0.0164,  0.0213, -0.1030],\n",
      "         [ 0.0213, -0.0626, -0.0077,  ..., -0.0058, -0.0083, -0.1492],\n",
      "         [-0.0034,  0.1572,  0.0064,  ..., -0.0035, -0.0076, -0.0979],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0287, -0.3138, -0.0594,  ..., -0.0301,  0.0600, -0.0483],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0280, -0.3053, -0.0603,  ..., -0.0306,  0.0599, -0.0214],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0282, -0.2796, -0.0615,  ..., -0.0311,  0.0594, -0.0409],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-3.0921e-03,  1.0081e-01, -3.1767e-03,  ..., -3.8085e-03,\n",
      "          -6.4826e-03, -1.0284e-02],\n",
      "         [-4.1226e-03, -7.7869e-02, -2.0009e-02,  ..., -1.0135e-03,\n",
      "          -4.8143e-03,  4.6900e-03],\n",
      "         [-6.3415e-02, -6.4416e-02, -5.4113e-03,  ..., -6.5766e-03,\n",
      "           9.6102e-04, -1.0795e-02],\n",
      "         ...,\n",
      "         [-4.1314e-03, -2.2779e-01, -3.6145e-03,  ..., -5.3380e-03,\n",
      "           6.8817e-03, -7.3818e-02],\n",
      "         [-1.3435e-02, -8.5522e-02, -7.0617e-04,  ..., -9.0123e-03,\n",
      "          -5.6200e-03, -1.5398e-02],\n",
      "         [ 4.7496e-04, -1.5601e-01, -1.0655e-02,  ..., -1.1176e-02,\n",
      "          -7.4744e-03, -1.4223e-01]],\n",
      "\n",
      "        [[ 6.6396e-04,  1.9104e-01, -4.9843e-03,  ..., -6.5239e-03,\n",
      "          -6.5399e-03, -3.5674e-02],\n",
      "         [-3.2566e-03, -6.0088e-02, -2.6121e-02,  ...,  4.7886e-03,\n",
      "          -2.2138e-03, -3.8864e-02],\n",
      "         [-8.3048e-02,  3.6033e-02, -6.6159e-03,  ..., -1.0607e-02,\n",
      "           3.0671e-04,  2.9628e-02],\n",
      "         ...,\n",
      "         [-2.1448e-03, -1.6504e-01, -9.8509e-03,  ..., -1.3529e-02,\n",
      "           5.7418e-03, -1.3638e-01],\n",
      "         [-1.8895e-02, -7.6369e-02, -5.4901e-03,  ..., -1.0926e-02,\n",
      "          -1.1253e-02, -1.0260e-02],\n",
      "         [-5.4247e-03,  3.3594e-02, -1.1850e-02,  ..., -2.1501e-02,\n",
      "          -8.2845e-03, -3.6529e-02]],\n",
      "\n",
      "        [[ 5.4511e-03,  1.2862e-01, -5.8498e-03,  ..., -7.8679e-03,\n",
      "          -3.8710e-03, -7.6418e-02],\n",
      "         [-4.9071e-03,  9.5783e-02, -2.9943e-02,  ...,  1.6972e-03,\n",
      "          -2.8888e-03,  4.3714e-02],\n",
      "         [-1.0172e-01, -1.2486e-01, -7.6201e-03,  ..., -1.0594e-02,\n",
      "          -1.9497e-03, -2.0628e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7349e-02,  3.3586e-01, -9.7288e-03,  ..., -1.1558e-02,\n",
      "          -4.0562e-03, -5.9577e-02],\n",
      "         [-9.3972e-04, -7.7642e-02, -7.4387e-02,  ...,  1.7566e-02,\n",
      "          -1.6477e-02,  1.9262e-01],\n",
      "         [-2.0101e-01, -3.5151e-01, -1.4180e-02,  ..., -1.2352e-02,\n",
      "          -5.6567e-03, -7.5171e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.1628e-02,  3.3215e-01, -9.9451e-03,  ..., -1.2418e-02,\n",
      "          -1.8673e-03,  6.7409e-03],\n",
      "         [-4.4866e-04, -5.3244e-02, -7.6906e-02,  ...,  1.7906e-02,\n",
      "          -1.9919e-02,  1.8191e-01],\n",
      "         [-2.3216e-01, -3.0842e-01, -1.5138e-02,  ..., -1.2506e-02,\n",
      "          -6.5561e-03, -7.0996e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.6039e-02,  2.4945e-01, -1.1767e-02,  ..., -1.2741e-02,\n",
      "           3.4850e-04, -4.2111e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "Iteration: 60; Percent complete: 5.1%; Average loss: 0.6920\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[-1.6012e-03, -1.7484e-01, -3.1801e-03,  ..., -4.9211e-03,\n",
      "          -1.5266e-03, -4.9360e-02],\n",
      "         [-4.6109e-03,  5.6125e-02, -4.0476e-04,  ..., -3.1259e-03,\n",
      "          -4.8549e-03, -3.5082e-02],\n",
      "         [ 4.0979e-03,  4.2654e-02, -2.8791e-03,  ...,  7.2894e-05,\n",
      "          -5.3157e-03,  1.6600e-02],\n",
      "         ...,\n",
      "         [ 2.5044e-02, -5.8464e-02, -8.5883e-03,  ..., -6.7569e-03,\n",
      "           2.9600e-02, -9.2307e-02],\n",
      "         [ 9.1255e-03, -2.2459e-01, -1.2083e-02,  ..., -1.4253e-02,\n",
      "           4.8634e-03,  4.2002e-04],\n",
      "         [-2.4597e-02,  9.6871e-02, -1.2371e-02,  ..., -1.9283e-03,\n",
      "          -1.7899e-04, -8.1224e-02]],\n",
      "\n",
      "        [[ 7.1708e-03, -1.3989e-01, -4.4954e-03,  ..., -1.4848e-02,\n",
      "          -2.1780e-03, -7.6748e-02],\n",
      "         [-1.6165e-02,  8.3590e-02, -2.0304e-03,  ..., -7.2468e-03,\n",
      "          -2.4617e-02, -9.2353e-02],\n",
      "         [ 5.7659e-03, -7.3932e-02, -4.4784e-03,  ...,  2.3444e-03,\n",
      "          -1.8286e-02,  1.6342e-03],\n",
      "         ...,\n",
      "         [ 2.8289e-02, -9.6785e-02, -1.1555e-02,  ..., -1.0690e-02,\n",
      "           3.0317e-02, -5.0080e-02],\n",
      "         [ 5.9668e-03, -2.8212e-01, -1.8580e-02,  ..., -1.9945e-02,\n",
      "           1.7206e-02,  4.9974e-03],\n",
      "         [-2.1380e-01,  1.4826e-01, -1.9637e-02,  ..., -6.9200e-03,\n",
      "           1.6316e-02, -6.8501e-02]],\n",
      "\n",
      "        [[ 1.1204e-02, -1.1235e-01, -5.7084e-03,  ..., -2.0238e-02,\n",
      "          -1.9674e-03, -4.2237e-02],\n",
      "         [-2.3818e-02,  1.9002e-01, -6.1915e-04,  ..., -8.8271e-03,\n",
      "          -1.9210e-02, -1.1987e-01],\n",
      "         [ 7.1570e-03, -1.9522e-01, -5.5900e-03,  ...,  8.2535e-02,\n",
      "          -3.0053e-02, -2.5371e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5124e-02, -1.5373e-01, -7.7170e-03,  ..., -4.2615e-02,\n",
      "          -5.7867e-03,  6.5762e-03],\n",
      "         [-3.9719e-02,  4.3937e-02, -1.0273e-02,  ..., -1.1820e-02,\n",
      "          -3.3149e-02,  4.8338e-02],\n",
      "         [ 1.4212e-02, -2.1595e-01, -7.5604e-03,  ...,  1.3370e-01,\n",
      "          -5.5208e-02,  1.1892e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5782e-02, -8.6024e-02, -8.5961e-03,  ..., -4.6205e-02,\n",
      "          -1.1516e-02,  6.9271e-02],\n",
      "         [-4.6500e-02, -2.8223e-02, -1.3209e-02,  ..., -1.2303e-02,\n",
      "          -3.6101e-02,  8.8380e-02],\n",
      "         [ 1.6326e-02, -2.1459e-01, -7.2940e-03,  ...,  1.5878e-01,\n",
      "          -6.4801e-02, -3.4158e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.8522e-02, -5.2144e-02, -9.6416e-03,  ..., -6.6147e-02,\n",
      "          -7.1531e-03,  3.1194e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([10, 64, 500])\n",
      "encoder_input_lengths:  tensor([10,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,\n",
      "         5,  5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         3,  3,  3,  3,  3,  3,  2,  2,  2,  2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 4.1368e-03, -1.1404e-01,  4.2041e-03,  ..., -5.3095e-03,\n",
      "           1.1249e-03,  6.6127e-03],\n",
      "         [-1.1182e-02,  3.9496e-02, -3.0236e-02,  ..., -1.2669e-03,\n",
      "          -7.7814e-03,  5.9060e-02],\n",
      "         [ 1.3215e-03, -1.3965e-01,  8.6279e-04,  ..., -8.7738e-03,\n",
      "           9.3245e-03, -1.0074e-01],\n",
      "         ...,\n",
      "         [ 4.6734e-03, -2.8474e-02, -1.4575e-02,  ..., -5.9893e-03,\n",
      "          -1.5939e-02,  1.1867e-02],\n",
      "         [ 1.4581e-02,  5.6787e-01, -5.9064e-03,  ..., -9.9522e-03,\n",
      "          -8.8760e-03,  5.6029e-02],\n",
      "         [ 1.8916e-02, -1.3194e-01, -1.8522e-02,  ..., -1.5352e-02,\n",
      "          -4.5509e-02,  3.1667e-02]],\n",
      "\n",
      "        [[ 9.7539e-03, -1.2956e-01,  1.2404e-03,  ..., -8.0214e-03,\n",
      "           2.1337e-03,  3.0128e-02],\n",
      "         [ 2.6345e-03,  2.8730e-01, -5.1466e-02,  ..., -3.3774e-03,\n",
      "          -7.2720e-03,  7.0773e-02],\n",
      "         [ 3.7045e-03,  7.1354e-03, -1.7370e-03,  ..., -1.1517e-02,\n",
      "           8.5118e-03, -9.8708e-02],\n",
      "         ...,\n",
      "         [ 1.8995e-02, -2.5122e-01, -4.0489e-02,  ..., -1.8180e-02,\n",
      "          -3.4710e-02,  1.2969e-01],\n",
      "         [ 2.4747e-02,  7.4314e-01, -7.7828e-03,  ..., -1.2355e-02,\n",
      "          -8.3033e-03,  8.1571e-02],\n",
      "         [ 1.8561e-01,  8.8791e-02, -2.9558e-02,  ..., -2.0593e-02,\n",
      "          -4.8328e-02,  6.7569e-02]],\n",
      "\n",
      "        [[ 1.7079e-02, -1.7312e-01, -1.0379e-03,  ..., -1.0538e-02,\n",
      "          -1.8922e-03, -7.5298e-03],\n",
      "         [ 2.4216e-03,  4.4344e-02, -5.3296e-02,  ..., -3.7626e-03,\n",
      "          -1.0693e-02,  1.0191e-01],\n",
      "         [ 3.1881e-02,  3.3771e-01, -3.1699e-03,  ..., -1.3662e-02,\n",
      "          -7.5542e-03, -5.5857e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.5814e-02, -1.0713e-01, -1.0461e-02,  ..., -1.9302e-02,\n",
      "          -1.0312e-02, -4.2968e-02],\n",
      "         [ 1.5755e-02, -9.2956e-02, -6.6341e-02,  ..., -6.6955e-03,\n",
      "          -2.4945e-02,  1.7523e-01],\n",
      "         [ 6.4046e-02,  6.9377e-02, -4.2067e-03,  ..., -1.6981e-02,\n",
      "          -1.3264e-02, -2.2357e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.1258e-02, -1.0304e-01, -1.0726e-02,  ..., -2.0920e-02,\n",
      "          -1.0588e-02, -8.7712e-02],\n",
      "         [ 2.9264e-02,  1.4607e-01, -7.5024e-02,  ..., -7.5386e-03,\n",
      "          -2.6418e-02,  1.0804e-01],\n",
      "         [ 6.5659e-02,  5.4834e-02, -4.8344e-03,  ..., -1.7854e-02,\n",
      "          -1.5012e-02,  5.6713e-04],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.3636e-02, -8.0640e-02, -1.2236e-02,  ..., -2.4574e-02,\n",
      "          -1.0953e-02, -6.4044e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "encoder outputs shape:  torch.Size([9, 64, 500])\n",
      "encoder_input_lengths:  tensor([9, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "encoder outputs:  tensor([[[ 3.8326e-03, -5.3621e-02, -9.3766e-04,  ..., -2.3100e-03,\n",
      "          -8.5797e-03, -1.1232e-01],\n",
      "         [ 4.7184e-03, -1.8063e-01, -2.7269e-02,  ..., -1.0154e-02,\n",
      "          -4.3772e-02, -4.9351e-02],\n",
      "         [ 4.1089e-03, -1.8148e-01, -1.0751e-02,  ..., -2.1472e-04,\n",
      "           3.6149e-03, -4.4531e-02],\n",
      "         ...,\n",
      "         [ 1.9436e-02,  9.8446e-02, -3.8561e-03,  ..., -1.6754e-03,\n",
      "          -6.7729e-03, -4.0269e-02],\n",
      "         [-4.8517e-03, -1.8290e-01, -2.6497e-03,  ..., -3.8761e-03,\n",
      "          -1.2074e-02, -2.3156e-03],\n",
      "         [ 6.5944e-03, -2.6164e-01, -9.0963e-04,  ..., -4.5031e-03,\n",
      "           2.8952e-03, -2.1388e-02]],\n",
      "\n",
      "        [[-9.4156e-03,  2.2487e-02, -3.0114e-03,  ..., -2.7446e-03,\n",
      "          -1.1743e-02, -9.5808e-02],\n",
      "         [-4.8488e-02, -2.7265e-01, -3.9062e-02,  ..., -1.2353e-02,\n",
      "          -6.1937e-02,  2.5939e-03],\n",
      "         [ 6.6793e-03, -1.1821e-01, -1.3350e-02,  ...,  9.4111e-04,\n",
      "           1.3982e-03, -1.9159e-02],\n",
      "         ...,\n",
      "         [ 2.2738e-02,  5.1948e-02, -6.3861e-03,  ..., -2.8303e-03,\n",
      "          -9.6058e-03,  1.5747e-03],\n",
      "         [-1.0404e-02, -1.7151e-01, -6.1397e-03,  ..., -5.9072e-03,\n",
      "          -1.3242e-02,  5.9750e-03],\n",
      "         [ 7.9002e-03, -2.3744e-01, -2.5756e-03,  ..., -6.5082e-03,\n",
      "           2.6944e-03,  1.1430e-02]],\n",
      "\n",
      "        [[-1.8634e-02,  2.9914e-02, -3.9193e-03,  ..., -9.5970e-03,\n",
      "          -1.4884e-02, -1.7242e-02],\n",
      "         [-1.0627e-01,  1.8396e-01, -4.9033e-02,  ..., -1.4759e-02,\n",
      "          -7.0839e-02,  4.1922e-02],\n",
      "         [ 7.1793e-03, -1.0190e-01, -1.5643e-02,  ...,  2.0190e-03,\n",
      "           9.8082e-04,  2.9121e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3590e-02,  1.9930e-02, -1.1156e-02,  ...,  4.5041e-03,\n",
      "          -2.8822e-02,  5.8759e-02],\n",
      "         [-7.3996e-02,  4.5695e-01, -6.9018e-02,  ..., -1.6572e-02,\n",
      "          -8.8327e-02,  8.4814e-02],\n",
      "         [ 2.5915e-03, -1.9074e-01, -2.1633e-02,  ..., -9.0830e-04,\n",
      "           1.0086e-03, -3.8245e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.6977e-02, -1.0605e-01, -1.2933e-02,  ...,  4.7795e-03,\n",
      "          -3.2526e-02,  7.1559e-02],\n",
      "         [-1.2957e-02,  5.7152e-01, -7.0597e-02,  ..., -1.8206e-02,\n",
      "          -1.0274e-01,  8.3070e-02],\n",
      "         [ 3.7507e-03, -2.4412e-01, -2.2925e-02,  ...,  6.5761e-03,\n",
      "           9.8973e-04, -6.9419e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.0597e-02, -1.2514e-01, -1.5049e-02,  ...,  3.2943e-03,\n",
      "          -3.4021e-02,  5.4619e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-06ec1c7ca0cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting Training!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Will train for {} iterations\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m trainIters(voc, train_pairs, val_pairs, encoder, context_encoder, attack_clf,\n\u001b[0m\u001b[0;32m     55\u001b[0m            \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_encoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_clf_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m            n_iteration, batch_size, print_every, n_iter_per_epoch, clip)\n",
      "\u001b[1;32m<ipython-input-11-496f5fd7db12>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(voc, pairs, val_pairs, encoder, context_encoder, attack_clf, encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding, n_iteration, batch_size, print_every, validate_every, clip)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# Run a training iteration with batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         loss = train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, # input/output arguments\n\u001b[0m\u001b[0;32m    107\u001b[0m                      \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_clf\u001b[0m\u001b[1;33m,\u001b[0m                                                                    \u001b[1;31m# network arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                      \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_encoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_clf_optimizer\u001b[0m\u001b[1;33m,\u001b[0m                                      \u001b[1;31m# optimization arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-496f5fd7db12>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, encoder, context_encoder, attack_clf, encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, batch_size, clip, max_length)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Perform backpropatation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Clip gradients: gradients are modified in place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fix random state (affect native Python code only, does not affect PyTorch and hence does not guarantee reproducibility)\n",
    "random.seed(2019)\n",
    "\n",
    "# Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print(\"Loading saved parameters...\")\n",
    "if not os.path.isfile(os.path.join(save_dir, \"model.tar\")):\n",
    "    raise RuntimeError(\"Pretrained model not found. Have you run pretraining using train_generative_model.py?\")\n",
    "checkpoint = torch.load(os.path.join(save_dir, \"model.tar\"))\n",
    "# If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.\n",
    "# To do so, replace the previous line with the following:\n",
    "#checkpoint = torch.load(\"model.tar\", map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "context_sd = checkpoint['ctx']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoders, decoder, and classifier...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# Initialize utterance and context encoders\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "context_encoder = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_encoder.load_state_dict(context_sd)\n",
    "# Initialize classifier\n",
    "attack_clf = SingleTargetClf(hidden_size, dropout)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "context_encoder = context_encoder.to(device)\n",
    "attack_clf = attack_clf.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "# Compute the number of training iterations we will need in order to achieve the number of epochs specified in the settings at the start of the notebook\n",
    "n_iter_per_epoch = len(train_pairs) // batch_size + int(len(train_pairs) % batch_size == 1)\n",
    "n_iteration = n_iter_per_epoch * finetune_epochs\n",
    "\n",
    "# Put dropout layers in train mode\n",
    "encoder.train()\n",
    "context_encoder.train()\n",
    "attack_clf.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=labeled_learning_rate)\n",
    "context_encoder_optimizer = optim.Adam(context_encoder.parameters(), lr=labeled_learning_rate)\n",
    "attack_clf_optimizer = optim.Adam(attack_clf.parameters(), lr=labeled_learning_rate)\n",
    "\n",
    "# Run training iterations, validating after every epoch\n",
    "print(\"Starting Training!\")\n",
    "print(\"Will train for {} iterations\".format(n_iteration))\n",
    "trainIters(voc, train_pairs, val_pairs, encoder, context_encoder, attack_clf,\n",
    "           encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,\n",
    "           n_iteration, batch_size, print_every, n_iter_per_epoch, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\ewais\\Documents\\GitHub\\CRAFT\\saved_models\\wikiconv\n"
     ]
    }
   ],
   "source": [
    "print(save_dir)"
   ]
  },
  {
   "source": [
    "## Notes on training\n",
    "\n",
    "trainIters is the main training loop\n",
    "\n",
    "It looks like this will need to be implemented in LuongAttnDecoderRNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na5gjZGE-KA0"
   },
   "source": [
    "## Part 7: run test set evaluation\n",
    "\n",
    "Now that we have successfully fine-tuned the model, we run it on the test set so that we can evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2551GR65-Wm5",
    "outputId": "154d7581-37a7-48e7-c203-9d3a97c472ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n",
      "Iteration: 1; Percent complete: 1.4%\n",
      "Iteration: 2; Percent complete: 2.9%\n",
      "Iteration: 3; Percent complete: 4.3%\n",
      "Iteration: 4; Percent complete: 5.8%\n",
      "Iteration: 5; Percent complete: 7.2%\n",
      "Iteration: 6; Percent complete: 8.7%\n",
      "Iteration: 7; Percent complete: 10.1%\n",
      "Iteration: 8; Percent complete: 11.6%\n",
      "Iteration: 9; Percent complete: 13.0%\n",
      "Iteration: 10; Percent complete: 14.5%\n",
      "Iteration: 11; Percent complete: 15.9%\n",
      "Iteration: 12; Percent complete: 17.4%\n",
      "Iteration: 13; Percent complete: 18.8%\n",
      "Iteration: 14; Percent complete: 20.3%\n",
      "Iteration: 15; Percent complete: 21.7%\n",
      "Iteration: 16; Percent complete: 23.2%\n",
      "Iteration: 17; Percent complete: 24.6%\n",
      "Iteration: 18; Percent complete: 26.1%\n",
      "Iteration: 19; Percent complete: 27.5%\n",
      "Iteration: 20; Percent complete: 29.0%\n",
      "Iteration: 21; Percent complete: 30.4%\n",
      "Iteration: 22; Percent complete: 31.9%\n",
      "Iteration: 23; Percent complete: 33.3%\n",
      "Iteration: 24; Percent complete: 34.8%\n",
      "Iteration: 25; Percent complete: 36.2%\n",
      "Iteration: 26; Percent complete: 37.7%\n",
      "Iteration: 27; Percent complete: 39.1%\n",
      "Iteration: 28; Percent complete: 40.6%\n",
      "Iteration: 29; Percent complete: 42.0%\n",
      "Iteration: 30; Percent complete: 43.5%\n",
      "Iteration: 31; Percent complete: 44.9%\n",
      "Iteration: 32; Percent complete: 46.4%\n",
      "Iteration: 33; Percent complete: 47.8%\n",
      "Iteration: 34; Percent complete: 49.3%\n",
      "Iteration: 35; Percent complete: 50.7%\n",
      "Iteration: 36; Percent complete: 52.2%\n",
      "Iteration: 37; Percent complete: 53.6%\n",
      "Iteration: 38; Percent complete: 55.1%\n",
      "Iteration: 39; Percent complete: 56.5%\n",
      "Iteration: 40; Percent complete: 58.0%\n",
      "Iteration: 41; Percent complete: 59.4%\n",
      "Iteration: 42; Percent complete: 60.9%\n",
      "Iteration: 43; Percent complete: 62.3%\n",
      "Iteration: 44; Percent complete: 63.8%\n",
      "Iteration: 45; Percent complete: 65.2%\n",
      "Iteration: 46; Percent complete: 66.7%\n",
      "Iteration: 47; Percent complete: 68.1%\n",
      "Iteration: 48; Percent complete: 69.6%\n",
      "Iteration: 49; Percent complete: 71.0%\n",
      "Iteration: 50; Percent complete: 72.5%\n",
      "Iteration: 51; Percent complete: 73.9%\n",
      "Iteration: 52; Percent complete: 75.4%\n",
      "Iteration: 53; Percent complete: 76.8%\n",
      "Iteration: 54; Percent complete: 78.3%\n",
      "Iteration: 55; Percent complete: 79.7%\n",
      "Iteration: 56; Percent complete: 81.2%\n",
      "Iteration: 57; Percent complete: 82.6%\n",
      "Iteration: 58; Percent complete: 84.1%\n",
      "Iteration: 59; Percent complete: 85.5%\n",
      "Iteration: 60; Percent complete: 87.0%\n",
      "Iteration: 61; Percent complete: 88.4%\n",
      "Iteration: 62; Percent complete: 89.9%\n",
      "Iteration: 63; Percent complete: 91.3%\n",
      "Iteration: 64; Percent complete: 92.8%\n",
      "Iteration: 65; Percent complete: 94.2%\n",
      "Iteration: 66; Percent complete: 95.7%\n",
      "Iteration: 67; Percent complete: 97.1%\n",
      "Iteration: 68; Percent complete: 98.6%\n",
      "Iteration: 69; Percent complete: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Fix random state for reproducibility\n",
    "random.seed(2019)\n",
    "\n",
    "# Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print(\"Loading saved parameters...\")\n",
    "checkpoint = torch.load(os.path.join(save_dir, \"finetuned_model.tar\"))\n",
    "# If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.\n",
    "# To do so, replace the previous line with the following:\n",
    "#checkpoint = torch.load(\"model.tar\", map_location=torch.device('cpu'))\n",
    "encoder_sd = checkpoint['en']\n",
    "context_sd = checkpoint['ctx']\n",
    "attack_clf_sd = checkpoint['atk_clf']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoders, decoder, and classifier...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "# Initialize utterance and context encoders\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "context_encoder = ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "context_encoder.load_state_dict(context_sd)\n",
    "# Initialize classifier\n",
    "attack_clf = SingleTargetClf(hidden_size, dropout)\n",
    "attack_clf.load_state_dict(attack_clf_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "context_encoder = context_encoder.to(device)\n",
    "attack_clf = attack_clf.to(device)\n",
    "print('Models built and ready to go!')\n",
    "\n",
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "context_encoder.eval()\n",
    "attack_clf.eval()\n",
    "\n",
    "# Initialize the pipeline\n",
    "predictor = Predictor(encoder, context_encoder, attack_clf)\n",
    "\n",
    "# Run the pipeline!\n",
    "forecasts_df = evaluateDataset(test_pairs, encoder, context_encoder, predictor, voc, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "lVK-1NWHEy7l",
    "outputId": "8b208593-4f96-444f-ad6c-cb84c0ffd88b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191681310.17214.17214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193088419.20001.20001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.654389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191149920.17102.17102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192892110.19259.19259</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.597574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190192199.17060.17060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192890095.19227.19227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190192005.17004.17004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192885632.19156.19156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190191827.16918.16918</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192882222.19129.19129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190191097.16843.16843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192642615.19074.19074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190190570.16705.16705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203899060.13359.13359</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869198.3976.3976</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192640416.19036.19036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190189346.16645.16645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203898053.13222.13222</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390066809.29445.29445</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434001261.9906.9906</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.761429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prediction     score\n",
       "id                                         \n",
       "191681310.17214.17214         0.0  0.397591\n",
       "193088419.20001.20001         1.0  0.654389\n",
       "191149920.17102.17102         0.0  0.239742\n",
       "192892110.19259.19259         1.0  0.597574\n",
       "190192199.17060.17060         0.0  0.170675\n",
       "192890095.19227.19227         1.0  0.646455\n",
       "190192005.17004.17004         0.0  0.146115\n",
       "192885632.19156.19156         0.0  0.453823\n",
       "190191827.16918.16918         0.0  0.201450\n",
       "192882222.19129.19129         0.0  0.370547\n",
       "190191097.16843.16843         0.0  0.260660\n",
       "192642615.19074.19074         0.0  0.444873\n",
       "190190570.16705.16705         0.0  0.417208\n",
       "203899060.13359.13359         1.0  0.939331\n",
       "15869198.3976.3976            1.0  0.651795\n",
       "192640416.19036.19036         0.0  0.353072\n",
       "190189346.16645.16645         0.0  0.276299\n",
       "203898053.13222.13222         1.0  0.926877\n",
       "390066809.29445.29445         1.0  0.670856\n",
       "434001261.9906.9906           1.0  0.761429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some of the outputs as a sanity-check\n",
    "forecasts_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_EMZ7-SKtEP"
   },
   "source": [
    "## Part 8: merge predictions back into corpus and evaluate\n",
    "\n",
    "Now that the hard part is done, all that is left to do is to evaluate the predictions. Since the predictions are in no particular order, we will first merge each prediction back into the source corpus, and then evaluate each conversation according to the order of utterances within that conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Vnjmtu-QLDVo"
   },
   "outputs": [],
   "source": [
    "# We will add a metadata entry to each test-set utterance signifying whether it was FORECAST to be a derailment.\n",
    "# Note that there is an important subtlety in how this metadata field is to be interpreted - the forecast for a given\n",
    "# utterance is made BEFORE the model actually sees the utterance. That is, the forecast does not mean \"the model thinks\n",
    "# this utterance *is* a derailment\" but rather that \"based on the context of all preceding utterances, the model predicted,\n",
    "# prior to actually seeing this utterance, that this utterance *would be* a derailment\".\n",
    "for convo in corpus.iter_conversations():\n",
    "    # only consider test set conversations (we did not make predictions for the other ones)\n",
    "    if convo.meta['split'] == \"test\":\n",
    "        for utt in convo.iter_utterances():\n",
    "            if utt.id in forecasts_df.index:\n",
    "                utt.meta['forecast_score'] = forecasts_df.loc[utt.id].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FYxW_AuWszqX",
    "outputId": "d478288b-55ae-4bc9-cb8c-f294a80f3174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6488095238095238\n"
     ]
    }
   ],
   "source": [
    "# Finally, we can use the forecast-annotated corpus to compute the forecast accuracy.\n",
    "# Though we have an individual forecast per utterance, ground truth is at the conversation level:\n",
    "# either a conversation derails or it does not. Thus, forecast accuracy is computed as follows:\n",
    "#   - True positives are cases that actually derail, for which the model made at least one positive forecast ANYTIME prior to derailment\n",
    "#   - False positives are cases that don't derail but for which the model made at least one positive forecast\n",
    "#   - False negatives are cases that derail but for which the model made no positive forecasts prior to derailment\n",
    "#   - True negatives are cases that don't derail, for which the model made no positive forecasts\n",
    "# Note that by construction, the last comment of each conversation is the one marked as derailment, and that our earlier code was therefore\n",
    "# set up to not look at the last comment, meaning that all forecasts we obtained are forecasts made prior to derailment. This simplifies\n",
    "# the computation of forecast accuracy as we now do not need to explicitly consider when a forecast was made.\n",
    "\n",
    "conversational_forecasts_df = {\n",
    "    \"convo_id\": [],\n",
    "    \"label\": [],\n",
    "    \"score\": [],\n",
    "    \"prediction\": []\n",
    "}\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == \"test\":\n",
    "        conversational_forecasts_df['convo_id'].append(convo.id)\n",
    "        conversational_forecasts_df['label'].append(int(convo.meta[label_metadata]))\n",
    "        forecast_scores = [utt.meta['forecast_score'] for utt in convo.iter_utterances() if 'forecast_score' in utt.meta]\n",
    "        conversational_forecasts_df['score'] = np.max(forecast_scores)\n",
    "        conversational_forecasts_df['prediction'].append(int(np.max(forecast_scores) > forecast_thresh))\n",
    "\n",
    "conversational_forecasts_df = pd.DataFrame(conversational_forecasts_df).set_index(\"convo_id\")\n",
    "print((conversational_forecasts_df.label == conversational_forecasts_df.prediction).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "_49Yaz2FIo9S",
    "outputId": "d1ae7b87-6973-41a1-e7aa-806d57990c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.6233, recall = 0.7524\n",
      "False positive rate = 0.45476190476190476\n",
      "F1 = 0.6817691477885652\n"
     ]
    }
   ],
   "source": [
    "# in addition to accuracy, we can also consider applying other metrics at the conversation level, such as precision/recall\n",
    "def get_pr_stats(preds, labels):\n",
    "    tp = ((labels==1)&(preds==1)).sum()\n",
    "    fp = ((labels==0)&(preds==1)).sum()\n",
    "    tn = ((labels==0)&(preds==0)).sum()\n",
    "    fn = ((labels==1)&(preds==0)).sum()\n",
    "    print(\"Precision = {0:.4f}, recall = {1:.4f}\".format(tp / (tp + fp), tp / (tp + fn)))\n",
    "    print(\"False positive rate =\", fp / (fp + tn))\n",
    "    print(\"F1 =\", 2 / (((tp + fp) / tp) + ((tp + fn) / tp)))\n",
    "\n",
    "get_pr_stats(conversational_forecasts_df.prediction, conversational_forecasts_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzBiI0dsW7WZ"
   },
   "source": [
    "## Part 9: model analysis: how early is early warning?\n",
    "\n",
    "The goal of CRAFT is to forecast outcomes in advance, but how far in advance does it typically make its prediction? Following the paper, we measure this in two ways: the number of *comments* between the first prediction and the actual derailment, and how much *elapsed time* that gap actually translates to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8Qfvl9k8Xesh"
   },
   "outputs": [],
   "source": [
    "comments_until_derail = {} # store the \"number of comments until derailment\" metric for each conversation\n",
    "time_until_derail = {} # store the \"time until derailment\" metric for each conversation\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == \"test\" and convo.meta[label_metadata]:\n",
    "        # filter out the section header as usual\n",
    "        utts = [utt for utt in convo.iter_utterances() if not utt.meta['is_section_header']]\n",
    "        # by construction, the last comment is the one with the personal attack\n",
    "        derail_idx = len(utts) - 1\n",
    "        # now scan the utterances in order until we find the first derailment prediction (if any)\n",
    "        for idx in range(1, len(utts)):\n",
    "            if utts[idx].meta['forecast_score'] > forecast_thresh:\n",
    "                # recall that the forecast_score meta field specifies what CRAFT thought this comment would look like BEFORE it\n",
    "                # saw this comment. So the actual CRAFT forecast is made during the previous comment; we account for this by \n",
    "                # subtracting 1 from idx\n",
    "                comments_until_derail[convo.id] = derail_idx - (idx-1)\n",
    "                time_until_derail[convo.id] = utts[derail_idx].timestamp - utts[(idx-1)].timestamp\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IFXn4LrMhJ8W",
    "outputId": "26611644-8c44-4380-8897-b0de6eece0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 12 3.0 3.4082278481012658\n"
     ]
    }
   ],
   "source": [
    "# compute some quick statistics about the distribution of the \"number of comments until derailment\" metric\n",
    "comments_until_derail_vals = np.asarray(list(comments_until_derail.values()))\n",
    "print(np.min(comments_until_derail_vals), np.max(comments_until_derail_vals), np.median(comments_until_derail_vals), np.mean(comments_until_derail_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7cTdzAuLhuHF",
    "outputId": "85df20c5-62e1-4d2c-8736-8432a65f55ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 25575.071111111112 3.539861111111111 241.3298628691983\n"
     ]
    }
   ],
   "source": [
    "# compute some quick statistics about the distribution of the \"time until derailment\" metric\n",
    "# note that since timestamps are in seconds, we convert to hours by dividing by 3600, to make it more human readable\n",
    "time_until_derail_vals = np.asarray(list(time_until_derail.values())) / 3600\n",
    "print(np.min(time_until_derail_vals), np.max(time_until_derail_vals), np.median(time_until_derail_vals), np.mean(time_until_derail_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "_w3l6UxDiDAz",
    "outputId": "7de51fb0-dbb9-42f2-8d5f-18fcda28ab00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the distribution of \"number of comments until derailment\" as a histogram (reproducing Figure 4 from the paper)\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.hist(comments_until_derail_vals, bins=range(1, np.max(comments_until_derail_vals)), density=True)\n",
    "plt.xlim(1,10)\n",
    "plt.xticks(np.arange(1,10)+0.5, np.arange(1,10))\n",
    "plt.yticks(np.arange(0,0.25,0.05), np.arange(0,25,5))\n",
    "plt.xlabel(\"Number of comments elapsed\")\n",
    "plt.ylabel(\"% of conversations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CRAFT fine-tuning demo using ConvoKit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python386jvsc74a57bd01131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}